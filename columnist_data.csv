Title,Date,Text
Is Trump’s near-death experience part of God’s plan?,7-16-2024,"Extreme, unusual events — all it takes is one — can change the trajectory of individual lives and entire nations. Although we didn’t know it yet, America had just days ago two potential futures — one in which Donald Trump was shot and one in which he wasn’t. Trump’s history of pettiness, demagoguery and sheer narcissism is so long and consistent that it seems a fantasy that he might ever change and put his country over his own wants and desires. But it is worth fantasizing for a moment. Perhaps Trump is doing the same. Less than 24 hours after the bullet grazed his ear, he told reporters that he had a “brutal” speech ready for the Republican National Convention but “threw it out” in favor of something more unifying. Displaying an unusual level of self-awareness, he explained: “I think it would be very bad if I got up and started going wild about how horrible everybody is and how corrupt and crooked, even if it’s true.” Knowing what we know now, the Trump rally in Butler, Pa., is striking to watch. A moment before shots ring out, the former president turns his head. It’s a turn that changes American history. A brush with death has — at least temporarily — ushered in a more reflective Trump. Bluster is replaced by an appreciation of luck, chance and his own mortality: “If I only half-turn, it hits the back of the brain,” he said. “The other way goes right through [the skull]. ... The chances of my making a perfect turn are probably one-tenth of 1 percent. And his conclusion: “I’m not supposed to be here.” Stories of near-death experiences chastening sinners and pushing them toward the light are the stuff of legend. But
they are also the stuff of real, ordinary lives — of individuals who make a conscious choice to turn away from the past
and restructure their own narratives toward a better end.
Foiled assassination attempts are their own subgenre, and here the evidence is more mixed. Egyptian relatives of
mine noted the similarities between the attack on Trump and a plot on Egyptian strongman Gamal Abdel Nasser in
October 1954. A gunman fired at him during a speech but missed. Seconds later, Nasser was defiant and electrified
the crowd in one of the more emotional political moments caught on tape. “I will live for your sake and die for the
sake of your freedom and honor,” he said, his voice rising. “Let them kill me; it does not concern me so long as I have
instilled pride, honor and freedom in you.” Sadly, the aftermath did not quite follow in that spirit. Nasser ordered
one of the most extensive political crackdowns in Egypt’s history and nurtured a personality cult that would remain
until his death 16 years later.
In 2016, Turkish President Recep Tayyip Erdogan survived a dramatic coup attempt. The plotters came close to
killing him, firing on his location in the resort town of Marmaris, Turkey, shortly after he had left. Afterward,
Erdogan called the coup attempt a “gift from God.” He responded to the gift with escalating repression, leaning into
his authoritarian instincts with renewed vigor.
Failed assassination attempts on actual or would-be heads of state are, mercifully, less common in established
democracies. For a similarly close call in the United States, one must go back to March 30, 1981, when John
Hinckley Jr. shot and nearly killed President Ronald Reagan. “I was lucky,” Reagan recalled. “The bullet that hit me
bounced off a rib and lodged in my lung, an inch from my heart.”
Reagan, too, considered this part of God’s divine plan. On his hospital bed, Reagan, who wasn’t an especially devout
man, prayed to God for help but also “began to pray for his [shooter’s] soul and that he would find his way back into
the fold.” Back at the White House, Reagan told Cardinal Terence Cooke: “I have decided that whatever time I have
left is for Him.” His encounter with death also had implications for the policies he pursued in the twilight of the Cold
War. As he later recounted, “Perhaps having come so close to death made me feel I should do whatever I could in the
years God had given me to reduce the threat of nuclear war.”
Trump is not Reagan. He is, well, Trump. But if God is real — something that most Americans still believe — then
presumably no one is immune to his gifts. The question then remains: What will Trump choose to do with his? Not
known for speaking about the divine with real feeling or sincerity, he has been quick to praise God, saying that “it
was God alone who prevented the unthinkable from happening.” The Trump family is feeling “spiritual, in a way,”
according to a person close to them. Of course, a change of Trump’s heart would not mean he would pursue policies that Democrats like. He is still the
nominee of the Republican Party. But it could mean that he campaigns and then governs — in the now more likely
event that he wins — in a manner that is less authoritarian. It could mean that when presented with an opportunity
to escalate tensions, he might choose instead to tamp them down. As it happens, this would also be in his selfinterest, a way to redeem is tarnished legacy.
If this sounds like a fantasy, perhaps it is. But fantasies sometimes come true. Fortunately for Trump — and perhaps
for us — God works in mysterious ways."
Trump has changed what it means to be evangelical,6-17-2024,"Despite an effort to overthrow an election and a bevy of criminal charges, Donald Trump has managed to solidify and even expand his support among core demographics. It remains the eternal Trump question: Who are his supporters and why are they so devoted to him?

Sign up for Shifts, an illustrated newsletter series about the future of work
The voters most loyal to the former president are White evangelicals. More than 80 percent backed him in the 2020 elections. And this has long presented a puzzle: How can people who prize moral rectitude and personal witness to Jesus so faithfully support the most secular president in American history, someone who seems by his behavior at best indifferent to Christianity?

Part of the answer is that Trump has been able to change the meaning of “evangelical.” This is no small feat.

It is easy to forget it now, but evangelicals initially were skeptical of Trump. During the 2016 Republican primaries, Sen. Ted Cruz (Tex.) was the preferred choice of churchgoing evangelicals, while Trump’s strongest support came from evangelicals with lower levels of church attendance. During the primary campaign, when one influential Christian magazine surveyed 100 evangelical leaders, not a single one said they planned to vote for Trump.

ADVERTISING


But Trump’s awkward relationship with evangelicals grew stronger. At first, it was transactional, a question of power. He was the Republican candidate, and the vast majority of White evangelicals were Republicans. He promised them policy victories and delivered on appointing the staunchly conservative Supreme Court justices who would overturn Roe v. Wade. And it wasn’t just that. As American culture became more secular and progressive on social issues, White evangelicals perceived themselves as under attack. Trump said he would protect them. He would fight not just for their preferred policies but for their very identities.


Follow Shadi Hamid

Follow
After evangelicals embraced Trump, something odd happened. As other Christian denominations hemorrhaged members, evangelicals saw their ranks grow; from 2016 to 2020, their share of the White adult population increased to 29 percent, from 25 percent, according to the Pew Research Center. The catch was many of these new evangelicals didn’t go to church. They became evangelicals because of what it meant politically, most of all because it was a way to signal support for Donald Trump. Among White Trump supporters who were not evangelicals in 2016, 16 percent began to identify as evangelical by 2020, suggesting again that politics rather than religion was the driving factor.
The idea of evangelicals who don’t go to church was once unusual. Now, it is surprisingly common. In 2008, only 16 percent of evangelicals said they never or seldom attended church. By 2020, 27 percent did.

Evangelicalism, in short, has become about shared political convictions. In one survey of Christian attitudes, for example, 43 percent of evangelicals said they did not believe in the divinity of Christ. But it gets even more bizarre. According to the 2022 Cooperative Election Study, 14 percent of Muslims (and 12 percent of Hindus and 5 percent of Jews) described themselves as “born-again” or evangelical Christians. This is not a joke.

If we look more closely at the numbers, what’s happening becomes clearer — and it’s fascinating. About three times more Republican Muslims and Republican Jews identify as “evangelical” than their Democratic counterparts, according to an analysis of the data by political scientist Ryan Burge. In an America that is rapidly secularizing — in just two decades, church membership has plummeted to under 50 percent, from about 70 percent — partisan commitments are replacing religious affiliation as people’s overarching source of identity.

This has unsettling implications for U.S. politics and the presidential campaign to come. It means we will see more intense political polarization around religion. Now that White evangelicals are so disproportionally and unapologetically Trump-supporting, the share of Democrats who view Christianity negatively is likely to remain high or perhaps even increase.


Democrats have had many opportunities to stem these shifts. They could have done more — and still can — but haven’t. In the pre-Trump era, Democratic presidential candidates took seriously the task of reaching out to devout Christians and presenting their party as hospitable to people of faith. The Hillary Clinton campaign, on the other hand, made a conscious decision to de-prioritize outreach to evangelicals. As Michael Wear, Barack Obama’s faith outreach director in 2012, put it, “The simple difference between Obama’s two presidential campaigns and Clinton’s 2016 campaign is that Obama asked for the votes of White evangelicals and Clinton did not.”

The transformation of American evangelicals has been a long time coming. In 1990, 40 percent of White evangelicals were Democrats. Today, this share is closer to 15 percent. As Burge told me, Democrats don’t want to alienate the rising number of nonreligious Americans who make up their ranks, so “they don’t talk about religion very much, or in a compelling way. And they sort of just ceded the ground.” This is the ground that Trump took up — a perfectly imperfect vessel for an uncertain age.

Americans are becoming less religious, but more of them are becoming evangelicals — or at least claiming the label as a badge of partisan identity. Trump’s ability to turn out evangelicals, both religious and nonreligious — including the growing ranks of Muslim, Jewish and Hindu “evangelicals” — to the same overwhelming degree that he did in 2020 could very well decide a close race. Religion matters, even when it’s not really about religion."
How Israel and the United States suppress democracy in the Middle East,5-13-2024,"The Middle East has a way of confounding American leaders and undermining legacies. Just eight days before Hamas’s Oct. 7 assault on Israel, national security adviser Jake Sullivan noted with satisfaction that “the Middle East region is quieter today than it has been in two decades.” Two weeks before the fall of Egyptian strongman Hosni Mubarak in the early days of the Arab Spring, Secretary of State Hillary Clinton declared, “Our assessment is that the Egyptian government is stable.” Perhaps most infamously, on New Year’s Eve in 1977, President Jimmy Carter called the Shah Mohammad Reza Pahlavi’s dictatorship in Iran an “island of stability.” Nine days later, the first small rally in the Iranian Revolution took place. The rallies didn’t stay small for long.

Apparently, the lesson must be relearned at regular intervals. The Middle East never stays quiet. Yet the illusion that it can leads American presidents along misguided, even dangerous paths. At the start of President Biden’s tenure, Gaza had been quiet. The Middle East as a whole had been (relatively) quiet. But its problems were festering.

Sign up for Democracy, Refreshed, a newsletter series on how to renovate the republic.
Successive U.S. administrations have longed to pivot to Asia. They have viewed the Middle East as a distraction, a mess to be contained so that the adults in the room can focus on things that matter more. President Barack Obama was known to privately joke, “All I need in the Middle East is a few smart autocrats.” He also wondered out loud why everyone couldn’t just “be like the Scandinavians.”


Scandinavians, of course, don’t live under repressive regimes, backed and armed with billions of dollars’ worth of U.S. economic and military aid. The question of why the Middle East is so dysfunctional, despite considerable American attention and investment, is a complicated one, immortalized in the titular prompt of Bernard Lewis’s “What Went Wrong?”


Follow Shadi Hamid

Follow
In the early, heady days of the Arab Spring, things finally seemed to be going right. For decades, something known as “linkage theory” — which asserts that the Arab-Israeli conflict must be resolved for the region to progress on other fronts — had dominated discussions about the Middle East. The promise of the Arab uprisings seemed to confirm the absurdity of focusing on Israel’s role. Protesters might have cared about Israel, but they cared more about their own governments, and apparently they could topple them, with or without regional peace.

Back then, I, too, thought Israel didn’t matter much. But I was wrong.


Today, Israel stands at the center of a region the United States helped form. The decision to elevate Israel’s security interests above almost everything else, however well-intentioned, has distorted American policy. Even though it is the region’s only established democracy, Israel is a staunch opponent of democracy in the rest of the Middle East.

The reason for this is simple enough: Arab populations tend to be doggedly anti-Israel. If they were to vote, they would elect leaders who reflected their sentiments. Elected governments that were independent, strong and proud — not American client states, in other words — would have to take a stronger position in support of Palestinian rights and statehood. Compare this with the Middle East’s current situation. Despite the death toll and sheer destruction in Gaza, Arab regimes have restricted public dissent. They have tried their best to keep things quiet — there’s that word again. For Israel, this is a virtue.

That Israel prefers autocrats over democrats has been a source of tension with the United States. Most of the more than 20 senior George W. Bush and Obama administration officials I interviewed for my book “The Problem of Democracy” recounted Israeli officials’ irritation whenever the United States would flirt with taking a more forthright pro-democracy stance in the region. Elliott Abrams, a deputy national security adviser under Bush, described the tenor of disagreement during the time of Bush’s so-called Freedom Agenda, from 2003 to 2005: “It was mockery behind our backs. They’d say, ‘You don’t understand at all. You know nothing about Arabs.’ … Because their argument was, ‘You will see who wins. The bad guys are gonna win. The Islamists are going to win victory after victory if you open these systems up.’”
A senior member of the Obama White House, referring to Egyptian Gen. Abdel Fatah El-Sisi’s coup against a democratically elected Islamist government in 2013, said “the strongest lobbying I got for going easier on Sisi was from Israel.”

If you privilege Israel’s dominance in the region above other considerations, then the price — the indefinite subjugation of hundreds of millions of Arabs — might be worth it. If you’re an Israeli, after the horrors of Oct. 7, it might even be a trivial consideration. For most of us, however, a moral and strategic reckoning is overdue.

The promise of authoritarian stability is false. Authoritarian regimes only seem stable — until they’re not. They are fierce but brittle, and that brittleness becomes obvious only after the fact. Michael McFaul, former U.S. ambassador to Russia, captures this dynamic well when he says, “The longer a democratic regime survives, the less likely it will collapse. … The longer an autocracy survives, the more likely it will collapse.”

Like administrations before it, Biden’s conflates quiet with stability. While stability suggests consistency and predictability, quiet is what it sounds like before a storm. After the storm passes, it will be up to anyone who cares about the Middle East — and the many who don’t — to resist the temptation to repeat old mistakes. If the status quo seems untenable, it’s probably because it is.


"
Why it matters that some Democrats voted against aid for Israel,4-21-2024,"Americans have increasingly turned against Israel’s war in Gaza. For the first time since Hamas’s Oct. 7 attack, a majority of Americans said in March that they disapproved of Israel’s military actions. Opposition to the war is most pronounced among Democrats, with 75 percent disapproving.

Sign up for Shifts, an illustrated newsletter series about the future of work
President Biden appears to share some of these misgivings; he has criticized Israel’s bombing campaign as “indiscriminate.” Reports of his conversations with Israeli Prime Minister Benjamin Netanyahu show a president at his wit’s end, irritated and even angry at his counterpart’s intransigence. But his criticisms have been made mostly in private settings, and there have been no major changes in policy. Biden has refused to put conditions on military aid to Israel. The Democratic Party leadership has largely followed suit.

The latest test in the relationship came in Saturday’s congressional vote on a stand-alone bill to provide Israel with billions of dollars in military assistance. This was the first time the House voted on a “clean” Israel bill that wasn’t bundled with Ukraine aid or poison pills such as funding cuts to the IRS. Thirty-seven of the 213 Democratic members of the House voted against the legislation. In one way, this was a lot. Voting against Israel aid was once exorbitantly risky; it no longer is. On the other hand, for a war as brutal and unpopular as this one, 37 seems like a low number.


No matter how you look at it, one conclusion is inescapable: There is a divide at the heart of the Democratic Party. Its standard-bearer, Joe Biden, finds himself at cross purposes with tens of millions of his own supporters.


Follow Shadi Hamid

Follow
In the days leading up to the vote, a group of Democratic members of Congress worked to marshal support for a “no” vote, in the hope that a strong showing might push Biden to reconsider his strategy. I spoke with four of them — Reps. Pramila Jayapal (Wash.), Ro Khanna (Calif.), Joaquin Castro (Tex.) and Becca Balint (Vt.). Castro called it “one of those defining votes about who we are as a nation.” Jayapal compared it with lopsided congressional votes in support of the Iraq and Afghanistan wars. “In the moment, it is very difficult to stop these wars and change policy,” she said, “and afterwards, we all say, oh, we shouldn’t have done that.” Each conveyed growing frustration but also a guarded optimism that the mainstream view was shifting in their favor. In a CBS News poll conducted earlier this month, only 32 percent of Democrats said the United States should send weapons and military supplies to Israel.

The “no” votes weren’t meant to express opposition to aid for Israel altogether. The problem, rather, is that the bill fails to put any conditions on that aid. It allows the secretary of state to waive “any congressional notification requirement applicable” to the $3.5 billion in foreign military financing grants — one of those peculiar provisions by which the legislative branch abdicates its own oversight powers. It also rewards the Netanyahu government with enhanced and exceptional privileges, enabling Israel to use the money to purchase arms from its own domestic industry as well as to buy U.S. weapons below “fair market value.”


One of the great puzzles of recent months has been the Biden administration’s refusal to use its considerable leverage with Israel. Conditioning aid to an ally is no small thing. But allies shouldn’t get a blank check to do whatever they want with American weapons. For months, Netanyahu has been resisting or ignoring Biden’s counsel on the need to drastically ramp up humanitarian aid, a matter made more urgent with Gaza on the brink of famine. Netanyahu’s postwar vision — one that calls for a large “buffer zone” and indefinite security operations in Gazan territory — is also dramatically at odds with America’s and, for that matter, everyone else’s.

For Americans, myself included, the question lingers: If we’re not willing to use our leverage now, is there any circumstance in which we would? Or should support for Israel, as opposed to other countries, be unconditional? As Jayapal put it, “It’s not just a matter of huffing and puffing.” Presumably, at some point, the Biden administration has to do something differently if it wants different results.

In my conversations with them, Jayapal, Khanna, Castro and Balint each emphasized the important distinction between providing defensive and offensive weapons to Israel. Their concern is the latter, the weapons of war that are used to destroy Gaza and kill Palestinian civilians in such large numbers. Of course, Israel, like any nation, has a right to defend itself. But this right is never unlimited or absolute. As Khanna noted, he has been a supporter of Israel’s Iron Dome air defense system and voted in the past for the $3.8 billion annual aid package to Israel. Balint, the first Jewish House member to come out in support of a cease-fire, describes herself as pro-Israel. “I have been a lifelong supporter of offensive and defensive measures for Israel to protect itself,” she said, “but there has to be a point at which we say, I am a supporter of Israel, I am the grandchild of someone who was murdered in the Holocaust, and I can also stand strong with what I believe are the majority of Americans.”


These arguments are compelling. But so far they have not been enough. Khanna, a rising star in the party, pointed to a “complete disconnect” between Washington and ordinary Democrats when it comes to Israel. There is, of course, something to be said for posterity, for setting a marker in moments when political courage is called for, however futile the cause. If rank-and-file Democrats continue to register their discontent in the months to come, the Biden administration might feel compelled to bend, not out of principle but for the more practical reason that a party leadership cannot afford to ignore its members on such a charged issue.


"
How can one suicide protest be heroic and another crazy?,2-29-2024,"Aaron Bushnell, an active-duty member of the U.S. Air Force, lit himself on fire in front of the Israeli Embassy in D.C. He died of his wounds hours later.

We are a divided country, not least over the war in Gaza. And so it seems unavoidable that we would look at the same facts — a man burning while shouting “Free Palestine” — and interpret them in very different ways. Some of the early reactions on Feb. 25 to Bushnell’s suicide were dismissive, even indignant. Why would he do something so silly — or crazy?

Sign up for Shifts, an illustrated newsletter series about the future of work
Michael Starr of the Jerusalem Post attributed the suicide protest to a “state of hysteria,” while journalist Mark Joseph Stern patronizingly intoned that “people suffering mental illness deserve empathy and respect, but it is wildly irresponsible to praise them for using a political justification to take their own life.” Mental illness was assumed without evidence.


The rush to pathologize Bushnell’s act suggests a double standard. After a 26-year-old Tunisian street vendor, Mohamed Bouazizi, self-immolated on Dec. 17, 2010 — the start of the Arab Spring — I don’t recall anyone wondering whether he was mentally ill. President Barack Obama hailed him as a hero, comparing him to America’s own Boston Tea Party patriots and civil rights icon Rosa Parks. We knew little of Bouazizi’s political views or his family life, and few cared to ask. His death was rarely described as a suicide in Western media. After all, his cause was just, and it became more just because of the revolutions it spawned.


Follow Shadi Hamid

Follow
What made one act noble and another unhinged? How do we judge what is reasonable and what isn’t? Unlike Bouazizi, who was reacting to the confiscation of his goods and police abuse, Bushnell appears to have thought carefully about his actions, alerting news outlets to his impending protest hours before. As he doused himself, he acknowledged the “extreme” nature of what he was about to do. And indeed it was. As philosopher Michael Cholbi dryly notes in his book on suicide, “killing oneself is hard.” The vast majority of attempts fail. Self-immolation, in contrast, has a fatality rate of more than 70 percent, according to one study.

Bushnell’s politics were extreme. Many if not most of us would find his various views, which he posted regularly on Reddit, to be absurd, silly and reprehensible. He dabbled in the kind of dorm-room Fanonism that saw the world through the simplified lens of colonized and colonizer. He believed it wasn’t his place, as an American White man of privilege, to question how Palestinians and other oppressed groups respond to their oppression, even if it means resorting to violence.


For some of Bushnell’s detractors, this privilege was a source of irritation in the other direction. One critic pointed out that where Bouazizi was protesting his own government, the 25-year-old Bushnell was concerning himself with a “distant ethno-religious conflict.” He had no familial connection to the region. Why should he feel so intensely about other people’s problems?

This gets at a fundamental divide over how Americans interpret the war in Gaza. It’s not just another foreign conflict in which tens of thousands have been killed. It’s not “distant.” The United States is Israel’s chief military patron, providing the emergency weapons and supplies needed to prosecute its war. What’s more, documents suggest that the U.S. Air Force might have has provided intelligence for offensive targeting in Israel’s massive aerial bombardment of Gaza. The United States is directly implicated in a way it isn’t in other conflicts.

Bushnell didn’t perceive the conflict as distant. He said:


“I’m an active duty member of the United States Air Force. And I will no longer be complicit in genocide. I’m about to engage in an extreme act of protest, but compared to what people have been experiencing in Palestine at the hands of their colonizers, it’s not extreme at all. This is what our ruling class has decided will be normal.”

One doesn’t have to like Bushnell’s reasoning — or his use of the term “genocide” — to comprehend his perspective. To understand is not to justify. To cite a relatively frivolous analogy, the political philosopher Santiago Ramos recently noted that “To explain why your uncle voted Trump in 2020 is not the same as voting for Trump yourself.” To think in this way requires what author Robert Wright calls “cognitive empathy,” a conscious effort to adopt the perspective of other people, even people you think are bad.

Based on the information we have, rather than speculation about a dead man’s mental state, Bushnell was increasingly despairing of the United States’ role in a war that has killed some 30,000 Palestinians, most of them women and children. An exhaustive Post investigation concluded that Israel’s war in Gaza has been one of the most destructive — possibly the most destructive — of the 21st century: Israel has “destroy[ed] more buildings, in far less time, than were destroyed during the Syrian regime’s battle for Aleppo from 2013 to 2016 and the U.S.-led campaign to defeat the Islamic State in Mosul, Iraq, and Raqqa, Syria, in 2017.”

It might be unreasonable or even crazy to think of doing what Bushnell did, but it is not unreasonable that Bushnell — and millions of other Americans — have felt a growing sense of powerlessness over their government’s facilitation of the mass killing of a largely defenseless people. That, too, is unreasonable. It is worse than unreasonable"
Is polyamory the future?,2-14-2024,"Everyone seems to be talking about polyamory. But are they practicing it? Journalists have lately devoted considerable attention to the topic, including a New Yorker feature suggestively titled “How did polyamory become so popular?”

Sign up for Shifts, an illustrated newsletter series about the future of work
Is it really popular? Or are people only saying it is? A self-fulfilling prophecy might be at work: Polyamory becomes more widespread because we think it’s already widespread. Norms around sexuality change because we think they’ve changed — even if they haven’t.

Nontraditional sexual relationships, of course, are as old as time itself. In the 1960s and ’70s, a generation of Americans became acquainted with “free love” only to settle into monogamous relationships when they got older. “Polyamory” entered the lexicon with 1997’s “The Ethical Slut,” a book now considered a landmark in the poly community. More than mere “open relationships,” polyamory entails multiple loving, emotionally intimate, and often long-term partnerships with the full consent of the other partners, known as “metamours.”


Strictly speaking, the practice is not terribly popular, even though Americans say they are growing more open to it. In one of the few surveys that asked about polyamory specifically, only 10.7 percent of respondents said they had engaged in polyamory at some point in their lives; 16.8 percent said they would like to try. About 4 to 5 percent reported currently being in a consensually non-monogamous relationship, suggesting that the number engaging specifically in polyamory is even less than that.


Follow Shadi Hamid

Follow
Yet interest in polyamory has increased significantly since 2021. The dating site Tinder reports that, in 2023, 41 percent of Gen Z users were open to or seeking non-monogamous relationships, and 26 percent were open to “hierarchical polyamory” — an arrangement with one primary partner taking priority over secondary or tertiary metamours.

This data raises the question of how social trends get started in the first place. If enough people think something is popular, influencers in film, television, media and the arts will reflect and then further normalize it. Peacock has begun streaming a polyamorous dating reality show called “Couple to Throuple.” Prestige television subplots have featured polyamory, most notably HBO’s 2021 remake of Ingmar Bergman’s 1973 classic “Scenes From a Marriage.” And as goes art so goes the academy, which is always a couple years behind because of the interminable process of peer review. A meta-review of 209 studies on consensual non-monogamy found 90 in the first 3½ years of the 2020s. Only 10 were published in the 1970s, three in the ’80s and none in the ’90s.


With polyamory today, there appears to be a social contagion effect in which the prevalence of a behavior becomes artificially inflated. As lived experience, polyamory is difficult and often unsustainable for most mere mortals. Having one partner requires planning. Having multiple partners requires even more, which is why accounts of “polycules” always seem to involve a lot of work, making shared Google calendars an essential tool in the arsenal of love. As scholars of polyamory have noted, both men and women — but particularly men — must be willing to “unlearn monogamy.”

Yet, unsurprisingly, it is men who tend to be most enthusiastic about polyamory, though perhaps they idealize it for what it could be rather than what it actually is. Men are twice as likely as women to have engaged in polyamory and three times as likely to have expressed the desire. This might be a result of nature or nurture or both, but it is true regardless. Seen in this light, polyamory offers both license and a patina of legitimacy to the exploitative sexual desires of some men.

The polyamorous among us tend to brush off such concerns, since they do not see intimacy as a scarce resource. If love and sex are satisfying, why not have more of it? The authors of “The Ethical Slut” note that “sluts share their sexuality the way philanthropists share their money: because they have a lot of it to share, because it makes them happy to share it, because sharing makes the world a better place.”


But even if love were infinite, time isn’t. And just as time is limited, so, too, is the human condition, which the polyamorous think they can circumvent. Take, for example, the idea of “compersion” — feeling joy at your partner’s sexual activity with someone else. This is essential to the poly enterprise. Yet jealousy, like love, is a natural human emotion: If you love someone, how realistic is it that you will want to “share” that person with someone else?

It is no accident, then, that those who try polyamory often come away disillusioned. Only about 30 percent say they would do it again, with many citing as obstacles possessiveness and “difficult to navigate” emotional aspects. If polyamory trickles down into mass consciousness, more people might find the courage to explore it, but a growing number might also find their relationships and family structures challenged by these complications of boundless love. One can imagine a spouse reluctantly saying yes to a request for an open marriage out of a desire to be open-minded or, worse, fear that refusal will push their partner into infidelity.

Polyamory might never reach genuine popularity, but it doesn’t need to be popular to challenge who we are and what we believe about love. Unfortunately, such challenges aren’t necessarily good.


"
The peculiar moderation of Donald Trump,1-25-2024,"In the final days of his campaign, Ron DeSantis was reduced to hoping he might win the four delegates awarded by the U.S. Virgin Islands. It was a precipitous fall from grace. Not so long ago, the Florida governor seemed a genuine contender, the rare Republican who could challenge Donald Trump’s iron grip on the party. But it turned out he could not, for reasons both simple and complicated.

Sign up for Shifts, an illustrated newsletter series about the future of work
The country’s past five presidents — Joe Biden, Trump, Barack Obama, George W. Bush and Bill Clinton — could all claim some mix of charisma, charm and folksiness. They were candidates you could conceivably enjoy getting a beer with. But this was not anyone’s idea of the stiff and robotic DeSantis, who often appeared at a loss when compelled to make conversation with voters.

It was a reminder that, for all the ideological charge of the Trump era, some things wouldn’t change: In a presidential system, personality matters. Competence, while nice in theory, wasn’t nearly as appealing in practice. Trump didn’t pretend to be competent. But he was entertaining, unencumbered and unusually funny.

ADVERTISING


Yet what has made Trump truly unique is the paradoxical nature of his political orientation. To even call it an orientation might overstate matters, since it suggests coherence where there is none. Trumpism manages to be extreme without being dogmatic. Its ideological nimbleness might, at times, even be mistaken for moderation — or more precisely “unhinged moderation,” to use writer Matthew Yglesias’s memorable term.


Follow Shadi Hamid

Follow
Though the GOP could conceivably support something like the Muslim ban again — to say nothing of believing the 2020 election was stolen — it has moved to the center on economic issues. The party that longed to privatize Social Security no longer exists. The small government ambitions of former House speaker and onetime Republican wunderkind Paul D. Ryan still elicit rote mentions. But under Trump, politicians who might once have cared about ballooning deficits pushed through two of the largest stimulus packages in U.S. history.

After the election was supposedly stolen by Biden — something more than 60 percent of Republicans still claim — this Trump-ified version of the GOP worked with Democrats to pass major legislation, including a historic $1.2 trillion infrastructure bill and the $280 billion Chips and Science Act to boost domestic semiconductor manufacturing and research. It was still an unhinged party, to be sure, but one that was more functional than anyone had reason to expect.Even on culture war issues, Trump’s ideological intensity tends to vary according to his mood. After DeSantis doubled down on fighting “wokeness” as his signature issue, Trump mocked him, saying, “I don’t like the term woke because I hear woke, woke, woke, you know, it’s like just a term they use. Half the people can’t even define it. They don’t know what it is.” Just hours after saying this, though, he went back to using the word himself and made no apparent attempt to define it.

This is not a weakness. It’s a strength. In a time when U.S. politics revolves around the intangibles of “who we are” rather than the policies we support, Trump’s authenticity — his honesty about being dishonest and his unapologetic prioritization of self over country — appeals to tens of millions of Americans. This is also what makes Trump uniquely dangerous. Just as he is not guided by ideology, he is also not limited by it. He has no evident belief in ideas, beyond the idea of himself and his own greatness.

This twisted authenticity and indifference to any greater cause or vision — combined with his charisma and comedic timing — is a sort of superpower. And there’s some hope in this. For better and worse, Trump is a once-in-a-lifetime political talent. It’s hard to imagine a confluence of events that would produce anyone comparable in the foreseeable future. This, at least, is a relief.




"
The dilemmas of living in a post-religious world,1-9-2024,"Was 2023 a “good” year? I suppose it depends on what we mean by the word. A good year must be part of a good life, yet the question of what makes a life good, meaningful and whole is an increasingly challenging one — implicating as it does all the big categories: religion, family, love and politics. What makes it harder is that these categories increasingly blend together, for better and worse.

Sign up for Shifts, an illustrated newsletter series about the future of work
Over the holidays, I was home in Pennsylvania with my parents and brother. Visiting the place where I grew up, along with the unhurried pace of the days, lends itself to a certain kind of remembrance. You can let your memories unspool with help from the people there, and better view the sweep of life. Some families avoid talking about the past, or of emotions that either indict or favor it.


Follow Shadi Hamid

Follow
Our family is different. We like remembering, and we like thought experiments. Could my brother and I have turned out differently? Could we have ended up more religious? What would have happened had I gotten married in, say, my 20s? Presumably, the rest of my life would have turned out differently. Marriage — if it’s with the right person, a big if — is associated with higher levels of life satisfaction. And if it’s with someone who shares your religious practice, it can also make you more religious (which in turn can also make you happier).


As my parents have grown older, they have had more time to consider how they raised my brother and me, and whether they found the right balance of strictness and latitude. It was an experiment for them and so many others in how to raise children who could become American while staying recognizably Muslim — and to do this in a society that was rapidly secularizing. As I get older, influenced no doubt by my parents’ worries, I wonder what alternative versions of me might have looked like, and whether I would have liked them.

I can imagine being both more religious and religiously conservative, but I suspect it would have required an upbringing that was less encouraging of education, ambition and intellectual curiosity. It doesn’t work this way for everyone, but I have often felt a certain tension between the comfort of religious rules and ritual and the excitement and wide-openness that come with the removal of constraint. I got older. The more I learned, the more I knew. And the more I knew, the more I had doubts about what I had known before.

This trade-off might have been worth it, but it was a trade-off nonetheless. Once you are exposed to the secular world — a world where personal autonomy and experience eclipse tradition — it becomes harder to return, even if you wish to. Modern liberalism is alluring, even if it might not always be good for us. As political scientist Patrick Deneen notes in “Why Liberalism Failed,” by dismantling traditional structures, liberalism encourages “privatism.” The individual becomes society’s most important unit, and the state’s role is somehow both reduced and expanded to the task of removing limitations on the individual’s ability to pursue their personal desires. This ability — fairly novel in human history — can prove overwhelming.


As the hold of religion weakens, it becomes harder to understand whether our choices have been the “right” ones. Our standards and judgments no longer refer to traditions; they become self-referential. This sense of endless choice injects into our lives an undercurrent of nearly perpetual panic, of never knowing whether we’re living as we should. Yet we become so used to our freedom to choose that we insist on retaining it regardless of the consequences.

In other words, we are trapped. If spiritual or religious traditions have largely disappeared from our lives, we can work consciously and deliberately to reintroduce them or strengthen the ones that we have held on to. I hope to do some of this in 2024. Constraints can be liberating. But no matter what we choose, we make a choice. This is a weight but also a blessing. Because in the end, the choice is ours alone.


"
Republicans say they believe in free speech. Except when it comes to Israel.,2-11-2023,"Cancel culture is back. The difference this time is that the targets are on the left. Republican officials and right-wing commentators are working overtime to criminalize and punish pro-Palestinian speech they disagree with, indiscriminately charging anyone who is insufficiently supportive of Israel’s war in Gaza with antisemitism. In this expanded understanding of the word, something as simple — and moral — as support for basic Palestinian rights is suspect.

Sign up for Shifts, an illustrated newsletter series about the future of work
When the current conflict began, there was understandable outrage over the pro-Palestinian advocates’ unwillingness to condemn Hamas’s grisly attacks on Israeli civilians. Dozens of student groups issued reprehensible statements excusing Hamas and blaming Israelis for their own deaths. These incidents were then used — and continue to be used — to more broadly delegitimize pro-Palestinian sentiments. Republican officials have released a stream of congressional resolutions and public statements that conflate support for the Palestinian cause with support for Hamas. In October, Sen. Marco Rubio (R-Fla.) and his co-sponsors introduced a resolution that lumped Hamas’s “full-throated Jew hatred” with what they called “the subtle anti-Semitism that holds the State of Israel to a different standard than any other nation.”

These efforts are intensifying. Sen. Tom Cotton (R-Ark.) recently called to suspend a CIA official for posting a picture of the Palestinian flag, comparing it to waving a Nazi flag during World War II. And in a charged congressional hearing last week, Rep. Elise Stefanik (R-N.Y.) grilled the president of Harvard University, Claudine Gay, about antisemitism on campus. In an exchange that went viral, Stefanik zeroed in on students’ use of the word “intifada” and claimed it was tantamount to a call for genocide against Jews. Unfortunately, Gay did not challenge the premise of Stefanik’s question.


“Intifada,” which means “uprising” or “rebellion” in Arabic, came into popular use in the late 1980s during the first Palestinian intifada, which included mass protests, general strikes and economic boycotts against the Israeli occupation. Some uprisings have been violent, but this doesn’t mean the word entails violence. This would be akin to claiming that activists who call for “revolution” are endorsing terrorism because the Russian and French revolutions involved prolonged reigns of terror.


Follow Shadi Hamid

Follow
But lost in Republican grandstanding is perhaps the most far-reaching effort yet to punish pro-Palestinian speech — a seemingly innocuous bill in Congress to establish a commission to investigate antisemitism in the United States. The legislation uses verbatim the International Holocaust Remembrance Alliance’s definition of antisemitism as “a certain perception of Jews, which may be expressed as hatred toward Jews.”

The bill doesn’t specify what constitutes “a certain perception of Jews” and neglects to mention the alliance’s own elaboration, which includes the “targeting of the state of Israel, conceived as a Jewish collectivity” and “applying double standards” to Israel as examples of potential antisemitism.


Under this reasoning, the commission will have broad powers to investigate any criticism of Israel that could be deemed unfair or overly exacting — including calls for a cease-fire or citing Israel’s disregard for Palestinian civilians in its targeting. As the Foundation for Middle East Peace’s Lara Friedman, who monitors legislative activity on the Israeli-Palestinian conflict, put it, “The GOP wants to formally open an era of modern McCarthyism, with criticism of Israel [and] fake concern about antisemitism as hooks to target progressive Americans.”

There’s no need to speculate about intentions. Leading Republicans have already made clear that something as unobjectionable as posting a Palestinian flag is beyond the pale. I have been on the receiving end of such attacks myself. Sen. Ted Cruz (Tex.) found time to tweet that I was “shilling” for Hamas because I said the Israeli military wasn’t prioritizing precision in its Gaza campaign.

I fully grant that for some pro-Israel voices, asking Israel to halt military operations — or using Arabic words — might be offensive. But being offensive is not the same as being antisemitic. To conflate the two is to weaponize antisemitism for partisan and ideological purposes. Because antisemitism is a growing problem — with incidents increasing across the West — devaluing its meaning is dangerous. It’s also an affront to free expression.


The irony should not be lost on anyone. For years, Republican officials have portrayed themselves as free-speech champions when it came to hard conversations on gender identity and race. They had legitimate reason to wave the cancel-culture flag. In their book, “The Canceling of the American Mind,” Greg Lukianoff and Rikki Schlott note that, in 2022, 72 percent of conservative college professors feared they would lose their jobs or reputations for expressing unpopular opinions and that 45 percent of liberal professors admitted to being willing to discriminate against conservatives in faculty searches. This makes it all the more disheartening that conservatives are now canceling people they disapprove of — on and off campus.

There is a better way. The fight for truth must be fought in the push and pull of unfettered debate. Sometimes, these debates will be uncomfortable and, yes, offensive. That’s life. This standard applies to everyone: Black people, Hispanics, Jews and Muslim Americans like me. Islamophobic sentiments, as much as I dislike them, are protected speech, too, and I’d counsel Muslim students to resist complaining to college administrators when they hear something that offends their own sense of identity and belonging. They should instead toughen up and learn to argue effectively in a free, contentious debate. This isn’t rocket science. It requires applying free-speech principles with moral clarity and consistency. If our principles can’t survive the toughest topics — and surely the Israeli-Palestinian conflict is one — then what use are they?


"
Why Arab Americans don’t want to vote for Biden in 2024,11-29-2023,"Even before the Israel-Gaza war began, Arab and Muslim Americans were losing faith in the Democratic Party — for reasons that had little to do with foreign policy. They had become increasingly skeptical of the party’s leftward turn on cultural and social issues; lessons with LGBTQ+ themes in public schools had become a particular flash point. Those debates now seem small and fleeting.

Sign up for Shifts, an illustrated newsletter series about the future of work
In times of actual war, mere culture war is a luxury. Over the Thanksgiving break, disillusion about the Biden administration’s embrace of Israel during its bombardment of Gaza was the mood music for my dinner-table conversations with friends and family members, four of whom are Arab Americans. All four said they would not vote for President Biden in 2024, after having done so in 2020.

Four people are just four people, of course, but these vote-or-don’t-vote conversations are widespread. According to an October survey of Arab Americans, only 17 percent plan to vote for Biden, down from 35 percent in April and 59 percent in 2020. And for the first time since polling firm Zogby Strategies started tracking them in 1996, more Arab Americans now identify as Republicans (32 percent) than Democrats (20 percent). Sixty-seven percent of respondents rate Biden’s response to the Israel-Gaza war negatively.


When I shared about my Thanksgiving conversations on X, the post garnered 7 million views. Hundreds of outraged replies came from liberals and other Trump opponents, many pointing out that Donald Trump wants to deport us. I suspect that patronizing arguments asking Arab Americans to suck it up and vote Biden regardless of his actual policies are unlikely to be effective. Their votes must be fought for. Trump’s unique danger doesn’t absolve Democrats of their responsibility to make an affirmative case for their candidate.


Follow Shadi Hamid

Follow
Casting a vote is an intensely personal act, and not just for Arab Americans, who are too often assumed to be emotionally blinded by the Palestinian cause. To expect anyone at the ballot box to calmly calculate a straightforward cost-benefit analysis ignores much of what is known about voter behavior. Political scientists Christopher Achen and Larry Bartels have found that the “most important factor in voters’ judgments [is] their social and psychological attachments to groups.” In other words, all politics is identity politics.

Everyone has a personal threshold beyond which they cannot, as a matter of conscience, vote for a particular candidate, even if they agree with that candidate on most other issues. If Biden woke up one day to say he thought women shouldn’t have a right to abortion, it wouldn’t be surprising if some liberals felt unable to lend him their unqualified support.

For better and worse, I have a contrarian instinct, so I reminded my sample of Arab Americans that Trump would be less sympathetic to Palestinians than Biden is. They said they understood the risk but needed some way to register their disgust. They mentioned Biden’s now-infamous remarks in which he questioned whether dead Palestinians were, in fact, dead. “I have no notion that the Palestinians are telling the truth about how many people are killed,” the president said. “I’m sure innocents have been killed, and it’s the price of waging a war.”

Stripped of dignity in this life, Palestinians would be denied it in death. It was rhetoric, perhaps, but it captured a decades-long frustration: American politicians on all sides seem either unwilling or unable to view Palestinians as full-fledged human beings. As former Obama administration official Barnett Rubin put it recently, “Sometimes self-respect outweighs self-interest. It would be humiliating to vote for Biden after he cheered on, funded, and armed people who slaughtered 15,000 of their fellow Arabs.”

In every presidential election, millions of Americans decide on principle not to vote for either of the two main candidates. That’s democracy.

ADVERTISING


If the 2024 election is close, Arab and Muslim Americans could be numerous enough to make a difference. Political scientist Youssef Chouhoud estimates that for every 10 percent of Middle Eastern and Muslim voters in Michigan who abstain, Biden will experience a net loss of about 11,000 votes, although in an interview Chouhoud reminded me that doing quantitative analysis on these communities is “so tough.” If Arab and Muslim voters abstain in unusually large numbers, others might follow suit. Note that 70 percent of young voters of all ethnicities disapprove of Biden’s handling of the war.

In the months ahead, a critical factor will be whether fallout from the war — and the devaluing of Palestinian lives — will continue to spill into everyday American life. In what is being investigated as a hate crime, three Palestinian Americans were shot in Vermont. Many of the Arab Americans who say they won’t vote for Biden also report discrimination and growing fears for their personal safety. Fortunately, for Democrats, the election isn’t being held today. In politics, a year is a long time. But memories are long, too.


"
A cease-fire in Gaza isn’t a fantasy. Here’s how it could work.,11-8-2023,"The destruction in Gaza has reached staggering levels. More than 4,000 children have died — equivalent to 600,000 children as a share of the U.S. population. It is not sufficient to say war is tragic, although it is. It is true that Israel doesn’t deliberately aim to kill civilians. But for the Palestinians who must mourn their dead, are they supposed to find solace in the notion that Israel didn’t intentionally target their loved ones, when the outcome is the same?

Sign up for Shifts, an illustrated newsletter series about the future of work
What might a plausible cease-fire look like in practice? The specifics matter. Any proposal must take seriously Israel’s legitimate security needs. First, Hamas must agree to release hostages and commit to halting rocket fire into Israel. In exchange, Israel would agree to stop its bombardment of Gaza as well as any ground incursions into Gazan territory.

Once this first step is taken, a cease-fire would allow for further negotiations on what comes next. These talks should be led by the United States, with the active support of governments in communication with Hamas — namely Qatar and Turkey. These countries should demand that Hamas offload its governing responsibilities in Gaza to the Palestinian Authority.


While it will be challenging to iron out the specifics of such an arrangement, some rough outlines can be sketched. Just as it is unrealistic to ask Israel to accept an unconditional cease-fire, so, too, is the notion that Hamas can be “eradicated.” Unlike al-Qaeda or the Islamic State, both of which often relied on foreign fighters, Hamas members and their families are Palestinian. Truly eliminating the organization — one with hundreds of thousands of supporters and sympathizers — would require mass killing on an unprecedented scale.


Follow Shadi Hamid

Follow
But if Hamas members won’t disappear, what happens to them? Any intra-Palestinian negotiations should include a path for low- and mid-level Hamas cadres, as well as members of the group’s political leadership, to be incorporated within any future governing structure. Without one, the Palestinian Authority will continue to suffer from a major legitimacy deficit. Under any such “reconciliation” agreement between Palestinian factions, armed groups would need to demobilize and integrate their military forces within those of the Palestinian Authority. Elections would need to be held within a reasonable time and, in order to participate, members of Hamas and other militants would need to commit to pursuing any political aims through the ballot box.

All of this might sound like a fantasy. But ambitious and imaginative proposals often begin as fantasies. One must start somewhere, after all.


And there is precedent. In previous Egyptian-brokered Palestinian reconciliation agreements, including the 2014 Shati Agreement and the 2017 Fatah-Hamas Agreement, Hamas agreed to subject itself to the authority of a consensus government that would abide by previous agreements with Israel. Of course, after the horrific attacks against Israeli civilians on Oct. 7, there is no reason to take Hamas at its word. Compliance would need to be closely monitored. But a cease-fire is not a peace deal. If elements of Hamas were to renege on an intra-Palestinian agreement and resume rocket fire or armed maneuvers inside of Israel, then the Israel Defense Forces would have the right to resume military action against targets in Gaza.

This is not a time for repeating old mantras or hoping that Israel, through the goodness of its own heart, might agree to a cease-fire because it is the right thing to do for Palestinians. Israel, like any state, will prioritize its own citizens. In other words, we might wish it were otherwise, but Israel is not uniquely malevolent for caring less about Palestinians.

At the same time, Palestinians would need reason to believe that new governance arrangements in Gaza would not be the end of the story. A return to the status quo ante, including a continuation of an Israeli blockade, would create the conditions for future radicalization and fatally undermine the legitimacy of any authority in Gaza. Palestinians need to be shown — by the Biden administration and by Israel — that an independent state incorporating Gaza, the West Bank and East Jerusalem is possible, not just in word but in deed.


Future U.S. military aid to Israel must be made contingent on it committing in good faith to this path. The Israeli government could not merely say that it accepts Palestine’s right to exist (although that would be nice). It would need to take concrete and tangible measures toward the establishment of a Palestinian state, including by entering into direct and unconditional negotiations with the Palestinian Authority.

The United States must use its leverage to bring Israel to the table. The alternative is a return to prewar conditions in Gaza and the West Bank that is dangerous for Palestinians and Israelis alike. In such an environment of hopelessness, Palestinians would likely lose faith and again gravitate toward supporting armed insurrection.

To be sure, any prospect of peace between Israel and the Palestinians remains far off. But the lack of a clear vision for exactly how to achieve it shouldn’t stand in the way of doing what can be done today. Now and not later, a cease-fire is necessary. Fortunately, it is also possible.


"
Reducing Hamas’s terrorism to a problem of ‘evil’ is a mistake,10-31-2023,"Terrorism doesn’t fall from the sky. Terror is a tactic. It is a choice. Hamas’s grisly assault on Israel must be analyzed with this in mind. If we ignore this, we make it more likely that other violent organizations will take Hamas’s place even if the group is neutralized or somehow eliminated.

Sign up for Shifts, an illustrated newsletter series about the future of work
This is already happening. In the West Bank, the stronghold of Hamas’s opponents, support for militancy appears to be deepening, including among Palestinian Authority President Mahmoud Abbas’s “moderate” Fatah faction. This shouldn’t come as a surprise. While the world looked away, something frightening was building. According to one July poll, 60 to 75 percent of Palestinians in Gaza and the West Bank had positive views of Islamic Jihad and the Lions’ Den — groups just as or even more radical than Hamas. And in a more recent September survey, 54 percent of Palestinians said they supported armed attacks against Israeli civilians.

There are two ways to look at this. One is to say that something is inherently wrong with Palestinians — a view often expressed by both the Israeli and American right — or even that Palestinians, by supporting groups that are evil, are complicit in that evil. This perspective has dangerous implications: It means downplaying distinctions between combatants and civilians (as many Israeli officials have repeatedly done) and seeing all Palestinians as enemies to be destroyed.


The other way to interpret the survey results is to acknowledge a truth about all people: They’re complicated. In the July poll, half of Gazans agreed that “Hamas should stop calling for Israel’s destruction and instead accept a permanent two-state solution based on the 1967 borders.” But it is possible for Palestinians to support a two-state solution that would allow Israel to exist as a Jewish state while also supporting armed attacks against and inside Israel.


Follow Shadi Hamid

Follow
It’s more useful to ask how Palestinian attitudes toward violence have evolved. As journalist Peter Beinart recently noted, at the height of the Oslo accords in 1996 — when a settlement seemed possible — Palestinian support for the peace process reached 80 percent while support for violence dropped to around 20 percent. Clearly, Palestinians, like any group, are capable of supporting both violence and nonviolence, depending on the circumstances.

Unfortunately, officials in the United States and Israel, and in European capitals, have either not been paying attention or simply haven’t cared enough. For instance, in the original version of a new Foreign Affairs article, published after Hamas’s attacks but written before them, Jake Sullivan, President Biden’s national security adviser, wrote, “In the face of serious frictions, we have de-escalated crises in Gaza and restored direct diplomacy between the parties after years of its absence.” The Biden administration was effectively ignoring Gaza. But it was also ignoring the West Bank, doubling down instead on the Trump administration-brokered Abraham Accords between Israel and “pro-American” Arab dictators. Palestinians were not part of the equation.


The United States and Europe treated the plight of Gazans as a tragedy, while acting as if nothing could be done about it. Meanwhile, successive Israeli governments expanded settlements deep into what was meant to be a future Palestinian state. As a matter of policy, Prime Minister Benjamin Netanyahu worked to prevent reconciliation efforts between the dueling authorities in Gaza and the West Bank. According to this “separation policy,” Netanyahu used Hamas’s dominance in Gaza to justify the claim that Israel had no “partner for peace.”

In 2018, as Gaza’s plight became frozen in place, Palestinian activists launched the Great Return March along the border with Israel — one of the largest unarmed mass mobilizations since the Gaza blockade began in 2007. Israeli forces responded with violence, including the firing of live ammunition and use of snipers. Over the course of the months-long protests, about 150 Palestinians were killed. The lesson that many Palestinians took from this — and from the apparent futility of the boycott, divestment and sanctions (BDS) movement — was that nonviolence doesn’t work.

This is not to say that Hamas wouldn’t have committed its gruesome killings had political circumstances turned out differently. There is no way of knowing. But it would also be a mistake to dismiss Hamas’s terrorism as mere “evil.” As the philosopher John Gray notes, “A campaign of mass murder is never simply an expression of psychopathic aggression.” To describe the things we can’t comprehend as evil is a cop-out. It allows us to believe something is wrong with “them” but not with us. And, paradoxically, it exposes an unwillingness to take terrorists seriously, reducing them to “crazy” or “irrational” adversaries. They usually aren’t.


As has been the case with groups as seemingly unhinged as al-Qaeda and the Islamic State, there has been a method to the madness, one that we ignore at our peril. As my Post colleague Damir Marusic recently wrote of Hamas, “Creating a catastrophe … was an act of breathtaking cynicism. It was a hijacking of the Palestinian cause.” Through spectacular violence and brutality, Hamas seized the initiative and demonstrated its own relevance. In a context of dramatic upheaval — think of the French or Russian revolutions — moderation, proportion and restraint never win the day. It’s unclear why anyone would expect them to win the day in Palestine.

The good news is that evil, however banal, can be fought. Hamas does not equal the Palestinian people. To believe that would be to accept Hamas’s claims at face value. Palestinians have diverse and often conflicting perspectives, and they have agency. As powerful as they are, the United States and Israel have agency, too. Millions of Palestinians can and must be incentivized away from violence. They once believed in a two-state solution, and for good reason: They could see progress, however halting, in their own lives. In recent years, however, they have seen only a series of dead ends.

That same alarming September poll contained notes of hope. A plurality in both Gaza and the West Bank said Palestinians’ first goal should be “Israeli withdrawal to the 1967 borders and the establishment of a Palestinian state in the West Bank and the Gaza Strip with East Jerusalem as its capital.” Right now, a growing number of Palestinians see revolutionary violence as the best way to achieve that goal — and they’re probably wrong about this.


When the fighting stops, the United States, Israel and the international community must give Palestinians reasons to think otherwise. A nonviolent path to an independent Palestinian state must be made unmistakably clear. If such a path doesn’t appear, then defeat of Hamas on the battlefield will be a Pyrrhic victory. Because its ideas — and its belief in the power of violence — will remain, perhaps more alive than ever.

"
"In the Israeli-Palestinian debate, you might be wrong. So be humble.",10-16-2023,"Days before Hamas launched its assault on Israel and brutally massacred hundreds of civilians, I half-joked to a friend that “no one cares about the Middle East anymore.” I said this as a lament. I spoke too soon. About a week before Hamas’s attack, U.S. national security adviser Jake Sullivan boasted to an audience that under the Biden administration’s watch, “the Middle East region is quieter today than it has been in two decades.” He also spoke too soon.

Sign up for Shifts, an illustrated newsletter series about the future of work
The Middle East never stays quiet. If the deeper sources of violent conflict in the region are left to fester, any peace and quiet will pass as quickly as it came. A dose of humility is in order.

By chance, as Israel intensified its bombardment of Gaza, I found myself at a summit on “intellectual humility” hosted by the John Templeton Foundation. It felt self-indulgent to discuss a philosophical concept with seemingly little relevance to the conflict. When it came to life and death, did any of this really matter? But what I found was that it did.

Intellectual humility is a trait and a practice that allows one to accept their own limitations. Even if we think we are right, it entails holding open the possibility that we might be wrong. But on a deeper level, humility involves the recognition that the truth itself is more complicated than it might first appear.

The search for truth, even if one finds it, should not involve rigidity. We are all a product of our environments. When it comes to Israel and Palestine in particular, we bring our own preconceptions to any debate — our own selective read of history and our own developed sense of injustice. This is not about a disagreement over facts; it’s about how to interpret them. My hope is that more Americans will understand this, considering how much we disagree with one another over our own founding as a nation.


Follow Shadi Hamid

Follow
For their part, pro-Palestinian activists tend to emphasize an original set of injustices that occurred in 1948 when Israel was created — namely, the expulsion of Palestinians from their land and homes — and then the subsequent injustice of a never-ending occupation that began in 1967. Because these are the original sins, everything else can seem like a distraction from the core grievance. Even for Palestinian opponents of Hamas — and there are many — Hamas might be vile, but it is more a symptom of the conflict than a cause.


In a beautiful 2003 valediction for Palestinian American academic Edward Said, Christopher Hitchens reminded readers of his estranged friend’s memorable description of the Palestinians as “victims of the victims,” a phrase as evocative as it is tragic. While performative victimization and trauma-sharing have become faddish in elite American circles, among Palestinians, victimization is very much real and deeply felt.

But victimization isn’t a competition. Why must one form of suffering negate another? It should be possible to acknowledge two things at once. We can — and must — condemn Hamas’s heinous acts against Israeli civilians while refusing to forget that Israel has been a perpetrator of a brutal occupation against Palestinians. Some will condemn this as “bothsidesism,” but there are, quite literally, two primary parties to the Israeli-Palestinian conflict, each with competing — and, sadly, irreconcilable — narratives. How could it be otherwise?

Talking about atrocities after the fact is a minefield. In a time of war, doing it well requires precisely the kind of presumptive generosity toward the other “side” that war itself militates against. Intellectual humility is difficult, but it should be easier for the powerful, because while they have more to lose, they are less likely to lose it.


Today, the Israeli government enjoys the preponderance of power. It must use this power in accordance with the “laws of war,” as President Biden recently said. There is no ethical case for brutalizing the people of Gaza, and it is morally indefensible of Israeli President Isaac Herzog to suggest that there are no innocent civilians in Gaza and that the “entire nation” is responsible.

If the powerful carry certain obligations, what can be said of the weak? The co-authors of “The Puzzle of Humility and Disparity” argue that “humility seems to be an inappropriate response for the oppressed toward their oppressors.” For many of us on the left, there is something distasteful about focusing our finite supply of moral outrage on, for example, the college students who signed on to reprehensible statements excusing Hamas’s murder of innocents.

But this distaste for punching down, while understandable, invites its own dangers. That members of marginalized groups have no moral agency is a pernicious idea (and one that goes against the founding doctrines of Islam). And while it is true that the actions of the Israeli government and the Biden administration are infinitely more consequential than the ridiculous things college students say, morality is not a luxury afforded solely to the strong.


Morality cannot be situational. We are all products of structures beyond our control, but this does not mean we are prisoners to them. The oppressed cannot simply shift moral responsibility onto their oppressors and be done with it. However terrible their circumstances, individuals always retain the ability to make choices.

In a struggle between protagonists with legitimate — and competing — grievances, is moral consistency too much to expect? Yes, it almost certainly is. But asking for it doesn’t hurt. Intellectual humility, as quaint as the idea might seem, demands nothing less.


"
"For religious American Muslims, hostility from the right and disdain from the left",7-25-2019,"It is an odd time to be a Muslim in America, in part because it depends on which America you happen to live in. Here, too, there are two Americas.

On the one hand, this is a sort of golden age for American Muslims and their place in public life. Sometimes it seems like Muslims are everywhere, even though they’re not. They star in their own television shows; they headline the White House correspondents' dinner ; they win Academy Awards; they become Snapchat sensations. Some of it is more subtle but striking nonetheless: If you live in a semi-hip urban setting, it’s not unusual to see a headscarf-wearing woman in an ad flanked by a rainbow coalition of other diverse Americans.


(Pegasus)
This can make it easy to forget the other reality that exists alongside the liberal pop-culture embrace of Muslims. The increase in anti-Muslim bigotry and other forms of discrimination against Muslims is well documented. But even if you don’t experience it or see it, you know Islamophobia exists, because it is there on social media. It is also in our president’s rhetoric. It is inescapable.


According to polling by University of Maryland professor Shibley Telhami, favorable views of Islam actually increased during the 2016 presidential campaign, but this increase came entirely from Democrats and independents. Among Republicans, favorable attitudes toward Muslims, as people, and Islam, as a religion, remained worryingly low (at around 40 percent and 25 percent, respectively). This is the America that the lawyer and writer Asma T. Uddin is most concerned with in her book “When Islam Is Not a Religion.” The title comes from the growing movement to paint Islam as a political ideology rather than a religion. If Islam is not a religion, Uddin writes, then it cannot claim the protections that U.S. law grants to religious expression. This, in effect, is how many Christian conservatives reconcile the seemingly contradictory positions of advocating for religious freedom for themselves but not for Muslims. In the process, the free exercise of religion, protected and guaranteed by the First Amendment, becomes yet another victim of partisan polarization.

That such an argument about Islam would come from Christian conservatives is somewhat ironic. After all, the notion that religion should remain private and personal is precisely the argument that secular liberals employ against Christians when it comes to issues like abortion and baking cakes for same-sex weddings. Conservatives bristle, rightly, at the idea that their faith commitments should not influence their politics. Why, then, would they insist that American Muslims become the very thing — in effect good, docile secularists — that they refuse to be?

Uddin is at her best and most passionate when discussing how this strain of anti-Muslim sentiment has affected her as an observant Muslim who shares some of the concerns of Christian conservatives regarding secular intolerance of sincerely held religious conviction. She was part of the legal team representing Hobby Lobby, the arts-and-crafts company that refused to provide certain contraceptives to employees as mandated by the Affordable Care Act. She worries that Muslims have become too closely tied to the Democratic Party, noting for example that “the Right’s tribal opposition to the political Left multiplies the Right’s hostility toward Muslim religious rights.”


Throughout the book, Uddin reserves most of her criticism for Republicans and conservatives, since they are the ones imperiling, indirectly or directly, the safety and security of Muslims through the rhetorical delegitimization of Islam, along with practical measures like opposition to mosque construction in local communities. But she also points to the occasionally awkward embrace between Muslims and the left and wonders whether that awkwardness might one day reveal deeper tensions. Many Muslims (including myself) are relieved that at least one of the two major parties is taking it upon itself to defend Muslims during a period of uncertainty. But there is, at the same time, an undercurrent of growing discomfort among avowedly conservative Muslims. Will Muslims who openly criticize the left’s stances on gender, abortion and gay rights still have a place in the Democratic Party?

As a conservative Muslim friend once told me: “I can sense the disdain from the Democratic Party towards my faith, even as they don a cape against Islamophobia. The underlying view Democrats have [about] anyone seriously religious is that they’re, at best, silly and gullible, and at worst, dangerous.” Uddin cites the infamous example of Sen. Dianne Feinstein (D-Calif.) telling appeals court nominee Amy Coney Barrett, a practicing Catholic, that “the dogma lives loudly within you.” It is difficult to imagine Feinstein saying this to a Muslim judicial nominee, but it is an affront to American traditions of religious liberty all the same and one that could be easily turned against conservative Muslims in due time.

What seems to be a book about the place of Muslims (and the anti-Muslim sentiment they are subjected to) in the Trump era is actually something different: It builds into a stirring defense of religious freedom, which, try as we might, is inseparable from human freedom. As Uddin writes: “It’s not our beliefs that religious liberty protects — it protects us, the humans who hold those beliefs. Put another way, religious liberty protects believers, not beliefs.”


It shouldn’t matter, then, whether someone is religious or not, since most Americans believe in something strongly enough for them to hope that the government will not interfere in those beliefs. These beliefs, and those who believe them, seem to be in growing conflict with each other. Americans no longer share the same starting premises, if they ever did, on what it means to live well. We’re perhaps more aware of it today because our fellow citizens — angry, impatient and increasingly educated — are more willing to express their “uncivil” opinions and have access to social media platforms where they can do precisely that. Uddin’s careful, fair and often quite powerful account offers up religion not as a source of our divides but as a window into how we might better manage them. Like all debates around autonomy and choice, the debate over religious freedom — and the place of Muslims in American public life — is one that speaks to a fundamental question, perhaps the fundamental question of the Trump era: how to live together with deep difference, not in spite of it.

"
Tunisia’s tough lesson for Mohammed bin Salman,11-18-2018,"The notion of a Tunisian “model” is a convenience for Western observers who still hope that all is not lost from the once heady optimism of the Arab Spring. It offers, however, little solace to Tunisians themselves, who sense — correctly — that their democracy remains imperfect. Tunisians, who haven’t lived under the sheer brutality of Egyptian dictatorship or the collapsing state structures of Yemen, aren’t comparing themselves to those countries; they are comparing themselves — rightfully — to what they wish they could be.

In our conversations with young Tunisians, we have often pointed out that Tunisia, unlike its neighbors, is at least relatively democratic. Our claims are often met with skepticism. The Tunisian rapper DJ Costa told one of us that: “We don’t have democracy in Tunisia. It’s like a man whose skin is dirty. For months he hasn’t washed himself, and then, one day, he puts on nice, expensive clothes. But you know him, who he really is.”


Well, who is he? Tunisia’s democracy is indeed struggling. It is failing to improve the economy and reduce corruption, overreacting to terrorist attacks and postponing important but potentially polarizing decisions. But Tunisia nonetheless continues to stand out in ways that, for the region at least, are unusual. That hundreds of Tunisians came out to protest the visit of Saudi Crown Prince Mohammed bin Salman isn’t necessarily surprising. But the images still were striking considering how much rarer such protests — or protests, in general — have become in the Arab world after the Arab Spring turned dark.


Follow Shadi Hamid

Follow
Under democracy, Tunisians enjoy the freedom to protest Mohammed bin Salman for Saudi Arabia’s assassination of the journalist Jamal Khashoggi, its devastating war in Yemen and its crackdown on women activists. Rule of law, meanwhile, isn’t just a nice idea but something real and practiced. The Tunisian Journalists’ Syndicate filed a lawsuit urging Tunisia to refer Mohammed bin Salman to the International Criminal Court. An independent judiciary responded by beginning an investigation. And perhaps most importantly, Tunisians could do all of this without fear of government retribution.

These events are a small but powerful reminder of what Tunisia, despite its flaws and its struggles, can still teach us. It may not be a model, but it is, and can continue to be, an inspiration. And this is why — merely by existing — Tunisia represents both an exception and a threat to a new but ever-authoritarian Middle East. It’s no mistake that the only Arab Spring democracy is the one where people are protesting Mohammed bin Salman. Tunisia is the near-opposite of Saudi Arabia.


The Saudis’ killing of Khashoggi was the culmination of a long list of sins and offenses, each of which have now come under greater scrutiny.

Critics have focused on the Yemen war and understandably so. The humanitarian catastrophe unfolding there is perhaps the most egregious example of MBS’s recklessness. Yet Saudi Arabia’s increasingly destructive impact on the rest of the region predates MBS. From 2011, the Saudi authorities worked tirelessly to strengthen dictatorships in the wake of the Arab Spring. Saudi Arabia intervened militarily to crush the uprising in Bahrain, and provided billions to shore up the monarchies in Morocco, Jordan and Oman. In his new book “Into the Hands of the Soldiers,” New York Times journalist David Kirkpatrick provides new and damning details on just how instrumental Saudi Arabia and the United Arab Emirates were in fomenting the 2013 military coup that ended Egypt’s democratic experiment. In Egypt, they had a willing partner of the military general Abdel Fatah al-Sissi. In Tunisia they thankfully did not, and have — so far — been unable to push Tunisia off its democratic path despite considerable economic and diplomatic pressure.

Today, Tunisia offers lessons not just to its neighbors but also to the United States and Europe on how to deal with strongmen such as Mohammed bin Salman — not with business-as-usual, but with criticism, accountability and a faith that justice, however slow and uneven, can be done.
"
Will we be forced into a religious test? The dangerous questions Muslims are facing.,1-28-2017,"There is panic at the airport. Some of the stories, after President Trump issued his executive order targeting Muslim immigrants, remind me of what I saw in the Middle East. No one has been killed, of course. But when an Iraqi who risked his life an interpreter for the Army arrives in New York only to be denied entry, it has the hallmarks of a different world, one he probably thought he had left behind: the fear of not knowing; the manipulation of law; the capriciousness of strongmen in midflight; and families divided in the name of politics.

The executive order may, in fact, be illegal, causing considerable confusion over what it means for the hundreds of thousands of legal U.S. residents from the seven Muslim countries listed. The legal debate and challenges will probably be with us for some time, maybe for the long remainder of Trump’s tenure. The president’s decree, though, is just as frightening — perhaps even more so — for what it tells us about a young presidency and how the office intends to use its power in its flurry of seemingly manic energy and activity.

With several notable exceptions, such as Defense Secretary James Mattis, a worryingly large number of Trump advisers and appointees share what, at best, can be described as a suspicion of not just Islam but Muslims. The executive order underscores the new administration’s fixation on what it views not as a terrorist threat but a civilizational one in which the very act of being Muslim is grounds for scrutiny.

ADVERTISING


The president’s order prioritizes “refugee claims made by individuals on the basis of religious-based persecution,” which is understandable enough, because Muslims and Christians alike (and Muslims more so) are targets of groups like the Islamic State.


Follow Shadi Hamid

Follow
One clause, however, imposes a religious test, almost overwhelming in its starkness: “The religion of the individual [must be] a minority religion in the individual’s country of nationality.” In other words, they cannot be Muslim regardless of the level of persecution they face. As Reza Aslan, an author who is Muslim, writes: “A Christian fleeing discrimination in Yemen would be given entry, but a Shia facing death and starvation would not.”

Islam, at least to some in Trump’s inner circle, is not considered a religion. As national security adviser Michael Flynn has said: “Islam is a political ideology masked behind a religion, using religion as an advantage against us. Islam is a political ideology. Sharia, the law of Islam, OK? Sharia is the law. Just like our Constitution is our law.” Since Muslims wouldn’t know how to pray, fast or give charity (zakat) without “sharia,” then any Muslim who observes any aspect of their faith or partakes in any ritual might have dual loyalties, to the clashing legal traditions of Flynn’s imagination.

Trump’s early moves are not just an attack on some of the most vulnerable refugees, but on Islam as an overarching ideological threat. It is easy to see echoes of Trump surrogate and former House speaker Newt Gingrich’s July remarks, which at the time may have seemed like musings of a man who would never again be close to the centers of American power.

“We should frankly test every person here who is of a Muslim background, and if they believe in sharia, they should be deported,” Gingrich said. It wasn’t clear whether Gingrich had in mind citizens and noncitizens alike or just the latter, but even the most charitable reading was sufficiently ominous.

I did not come of political age during the Cold War, so perhaps the language of ideological tests shouldn’t be as surprising as I found it while parsing the text of the executive order.


This is noteworthy: “The United States cannot, and should not, admit those who do not support the Constitution, or those who would place violent ideologies over American law.” What constitutes “supporting” the Constitution, especially considering that our own president has an ambivalent relationship with many of its amendments, including the first? How is that to be judged?

Ideological tests are something that American Muslims, including my family and I, are safe from. But I shudder to think that my parents, upon entering the United States as immigrants decades ago, would have been “tested” for sufficient adherence to the Constitution by an administration that already held them in suspicion. Would they have been asked to disavow aspects of their own religion, culture or identity?

Trump’s actions didn’t just begin with his presidency. They began when Trump, the candidate, propelled Muslims to the center of his agenda. For the first time, in my own country, I felt like an object of analysis.


I remember when Trump first proposed his Muslim immigration ban in December 2015 and hearing it discussed endlessly on television. Everything seemed to be about “us.”

I was no longer just who I happened to be but a member of a group that was being debated and dissected as a potential threat. We had become a problem, and all problems need to be resolved. In the coming four or eight years or perhaps longer, we will find out what, exactly, that means.

"
There’s no ‘good’ or ‘bad’ America,11-18-2016,"Are people who believe in deplorable things themselves “deplorable”? Donald Trump voters, whether they intended to or not, empowered racists. Many hold misogynistic and Islamophobic views, even if they might like to believe that they don’t. But this should not — it cannot — have much bearing on whether someone is “good” or “bad” in an absolute sense.

To prioritize one’s tribe or family to the exclusion of others has long been a universal condition. The nature of this in-group identity is malleable and can morph from ethnic to religious to nationalist identities. Whatever its form, however, it remains a potent force, steeped as it is in those most natural of sentiments — fear and the will to survive. As anthropologist Scott Atran writes: “Across most of human history and cultures, violence against other groups was considered a moral virtue.” Today we know that the desire to exclude shouldn’t be the norm, but that doesn’t make it any less a part of who we are.

America’s working class has its own culture. And they will fight to keep it.

Until Donald Trump’s victory shattered the idea, liberals — many of whom didn’t know a single Trump voter — could content themselves with the remarkable progress of the Obama era: gay marriage, universal health care and the growing willingness to confront the realities of sexual assault and police brutality. Maybe we were fundamentally good people. But, as the philosopher John Gray writes: “Sooner or later anyone who believes in human goodness is bound to reinvent the idea of evil in a cruder form.”


The “arc of history” is supposed to bend toward justice, leaving those that resist it enemies of both history and progress. Evil comes to be seen as something that is outside of us, which must not merely be fought but excised entirely. When someone writes that there is no such thing as a “good” Trump voter, the sentiment is understandable, fitting as it does within the modern liberal conception of progress. But it fundamentally misunderstands the very nature of good and evil.


Follow Shadi Hamid

Follow
For me, the more useful question isn’t why Trump voters voted for him, but, rather, why they wouldn’t. It seems self-evident that minorities would generally vote for the party that goes out of its way to consider — and protect — the rights of minorities. In a period of “existential” politics, that’s naturally what takes precedence over other concerns. Why would whites, or at least a large percentage of them, act any differently?

It has become common to assume a permanent Democratic majority in due time, as a result of irreversible demographic trends. In cruder terms, it amounts to longing for immigration and minority birth rates to erode white majorities on both the national and state levels. But this has profound implications, since it “practically compels whites to behave electorally like a minority constituency.” In this respect, white nationalism or white identity politics overlap with racism, but they are not quite the same thing.

Advertisement

After all, if I was a member of the so-called “white working class” rather than an American Muslim, I can’t be sure I wouldn’t have voted for Trump. This may make me a flawed person or even, as some would have it, a “racist.” But it would also make me rational, voting if not in my economic self-interest then at least in my emotional self-interest.

States are a relic of the past. It’s time to get rid of them.

There is, of course, another way of seeing this — one that in many ways is easier and more pure. It would certainly feel good to think I’m morally superior to Trump supporters.  I could take refuge in outright disdain for those who haven’t seen the light.

But it is unclear what this kind of purity and certainty — the self-satisfaction of knowing that we were right, despite everything — can really do for us. It leaves us without a path forward. It is also contrary to most of what we know about human nature: Good and bad have never been separate or easily distinguishable categories. They are endlessly intertwined.

Advertisement

That Americans increasingly insist on separating people into good and bad suggests an unwillingness to understand — much less empathize with — those who threaten our conception of America, whatever that happens to be. I could try to explain what I think our nation is, but I can no longer be sure if tens of millions of my fellow citizens would agree. But I cannot simply take solace in the fact that soon there will be more non-whites and therefore more people who share my ideology. This is a recipe for more conflict, not less.

Well before Brexit and the rise of Trump, Bulgarian political scientist Ivan Krastev wrote that “threatened majorities — those who have everything and who fear everything — have emerged as the major force in European politics.” They feel threatened in the United States as well; the only difference, perhaps, is that they do not have everything but still fear everything. Yet as demographics inexorably shift, both the perception and reality of this “threat” will only grow. Unless something changes, American politics will continue to collapse along ethnic lines. The task ahead of us comes down to preventing what, for now, seems sadly inevitable.
"
What a caliphate really is — and how the Islamic State is not one,10-28-2016,"For the first time in nearly a century, the caliphate — or at least a caliphate — has become something tangible, but also something brutal and frightening. In a brilliant stroke of ideological appropriation, the Islamic State took an idea that had animated the Muslim world for nearly 14 centuries and made it its own. In so doing, it also managed to taint an idea that hundreds of millions of Muslims continue to look to with considerable longing.

Even before the Islamic State dominated our headlines, the specter of a caliphate had become an easy stand-in for anti-Muslim posturing on the American and European far right. The Muslims were, once again, coming.


In the appropriately titled “Caliphate: The History of an Idea,” British historian Hugh Kennedy takes it upon himself to recover the caliphate’s meaning, and he succeeds with welcome doses of erudition, accuracy and, when necessary, empathy.

Most Muslims, myself included, grow up with at least pieces of this history. We come to know the “righteously guided” caliphs with a kind of intimacy that belies the passing of time. The prophet Muhammad succeeded in founding a new religious community and a fledgling state. Abu Bakr, Omar, Uthman and Ali, the close companions of the prophet, founded an empire. To be caliph meant to be “a successor of the Prophet of God.” Meanwhile, the concept of the caliphate, Kennedy tells us in the book’s rather inviting first page, “offers an idea of leadership which is about the just ordering of Muslim society according to the will of God.”


""Caliphate: The History of an Idea,"" by Hugh Kennedy (Basic)
Like the similarly abused sharia — which includes but goes beyond Islamic law — the caliphate was a diverse and complex thing, evolving according to the demands of time and place. Far from a harsh and imposing Islamic dystopia, the caliphate, at least in its Abbasid heyday from 750 to 945, was the site of scientific advances and a flourishing intellectual culture. One of Kennedy’s most useful contributions is to subtly unpack the puzzle of how an order governed and guided by God’s law could also be characterized not just by heterodox philosophical inquiry but also by Islamically prohibited behaviors such as wine drinking. Caliphal courts flowed with it, and poets valorized it. The great Abbasid-era love poet, Abu Nuwas, who died in 814, “celebrates gay sex with unconcealed enthusiasm” (although some have explained such appreciations, in retrospect, as metaphorical).

Read: Five myths about sharia

A caliphate where even caliphs drank and where young boys were admired for their beauty is probably a difficult one to absorb for today’s observers, Muslim and non-Muslim alike. In the premodern era, however, the distinction between private and public spheres was quite different. From the standpoint of rulers and clerics (if not God), Islamic law wasn’t just, or even primarily, about the punishment of individual sin. As a historian of early modern Iran, Rudi Matthee, writes in “The Pursuit of Pleasure,” “Because public deviance affects fellow believers and ultimately undermines Islam itself as a communal faith, Islam requires its followers to comply with the rules of the public sphere.”


Un-Islamic behavior, as long as it was conducted in private, wasn't a threat to the overarching moral culture and legal structure. An Islam that was already dominant had less need to dominate. It also couldn't dominate, at least not in the private realm, because the premodern state was simply incapable of monitoring the minutiae of everyday life. Importantly, this was an era of Muslim confidence, a theme Kennedy captures in page after page of vivid detail. A more confident culture could more easily accommodate private indulgences (it also probably helped that there was no social media or elections, so subjects of the caliphate had no way to froth in outrage over naughty pictures of royals getting drunk).


Follow Shadi Hamid

Follow
Human agency was probably a more viable notion 1,000 years ago as well. “In the history-writing” of the Abbasid period, Kennedy writes, “direct divine intervention in the course of human affairs was rarely invoked.” For anyone who has spent time in the Middle East, where God is used to casually evoke resignation, hopelessness and the inability to make meetings on time, this may come as quite the surprise.

It is useful to know what the caliphate actually means, but can things that happened so long ago really tell us much about present predicaments? Again, Kennedy, being the unimposing historian that he is, takes care not to overstate his case. Yet, the very fact that so many will be interested in reading this book is itself evidence that the events of 14 centuries ago have direct bearing on the modern Middle East’s most vexing questions of war, politics and the state. As Kennedy writes in his introduction: “History has a power for this tradition which we do not find elsewhere. No one in Britain looks to the Anglo-Saxon Chronicle . . . and uses it as a way of justifying political behavior today.”


The evolution of the Sunni-Shiite split is also captured with considerable insight. The book’s treatment will serve as a rejoinder to anyone who presumes to think the divide is just about politics and power. Of course it is, in part. But what becomes clear throughout Kennedy’s carefully plotted chronicle is that the very notion that religion and politics are separate categories is a fiction we too often superimpose on the past. What ends up making the sectarian divide so potent is that the religious becomes political and the political religious. In this case, the question, left unanswered, is what God said — or intended — about the passing on of power after the death of the prophet.

The caliphate, in its Abbasid, Andalusian and Shiite Fatamid expressions, was a glorious thing to be sure. But each of these empires was taxed by periods of internecine strife, rebellion and despotism, driven by profound disagreements over the nature of succession and the exact nature of the caliphal office. Even in the time of the righteously guided caliphs, the prophet’s companions turned against one another in what amounted to Islam’s first civil war. Despite the darker undercurrents, these periods are all treated as golden ages by some or many Muslims (even the Islamic State somehow salutes the Abbasids, skipping over their more hedonistic proclivities). It says something that Muslims, at least in their historical memory, have willed the caliphate to be something it never actually was — and perhaps something it never can be.

"
Does ISIS really have nothing to do with Islam? Islamic apologetics carry serious risks.,11-18-2015,"Every time the Islamic State commits yet another attack or atrocity, Muslims, particularly Western Muslims, shudder. Attacks like the ones in Paris mean another round of demands that Muslims condemn the acts, as if we should presume guilt, or perhaps some indirect taint.

The impulse to separate Islam from the sins and crimes of the Islamic State, also known as ISIS, is understandable, and it often includes statements such as ISIS has “nothing to do with Islam” or that ISIS is merely “using Islam” as a pretext. The sentiment is usually well-intentioned. We live in an age of growing anti-Muslim bigotry, where mainstream politicians now feel license to say things that might have once been unimaginable.

To protect Islam – and, by extension, Muslims – from any association with extremists and extremism is a worthy cause.

ADVERTISING


But saying something for the right reasons doesn’t necessarily make it right. An overwhelming majority of Muslims oppose ISIS and its ideology. But that’s not quite the same as saying that ISIS has nothing to do with Islam, when it very clearly has something to do with it.


Follow Shadi Hamid

Follow
If you actually look at ISIS’s approach to governance, it would be difficult – impossible, really – to conclude that it is just making things up as it goes along and then giving it an Islamic luster only after the fact.

[Why the question of Christian vs. Muslim refugees has become so incredibly divisive]

It is tempting, for example, to look at the role of former Saddam-era Baathist party officers in the organization’s senior ranks and leap to the conclusion that religion can’t matter all that much. Yet many younger Baathists came up through Saddam Hussein’s late-period Islamization initiative, and, in any case, just because someone starts as a Baathist – or any other kind of secular nationalist – doesn’t mean they can’t, at some later point, “get” religion.


There is a role for Islamic apologetics – if defending Islam rather than analyzing it is your objective. I am a Muslim myself, and it’s impossible for me to believe that a just God could ever sanction the behavior of groups like ISIS.

But if the goal is to understand ISIS, then I, and other analysts who happen to be Muslim, would be better served by cordoning off our personal assumptions and preferences. What Islam should be and what Islam is actually understood to be by Muslims (including extremist Muslims) are very different things.

For scholars of Islamist movements and Islam’s role in politics, Muslim and non-Muslim alike, there should be one overarching objective: to understand and to explain, rather than to make judgments about which interpretations of Islam are correct, or who is or isn’t a “true” Muslim.


[Analysis: After the Paris attacks, here’s how to think about the relationship between ISIS and Islam]

In addition to being a Muslim, I am an American, as well as a small-l liberal. I have written about how, even if we personally believe liberalism is the best available ideological framework for ordering society, that should not be allowed to distort our understanding of mainstream Islamist movements such as, say, the Muslim Brotherhood and its analogues across the region.

It makes little sense to compare Islamists to some liberal ideal, when they are a product of very different contexts than our own.

The “is ISIS Islamic?” debate can seem circular and exhausting. But it’s an important one nonetheless. Islamic apologetics lead us down a path of diminishing the role of religion in politics. If the past few years of Middle Eastern turmoil have made anything clear, it’s that, for Islamists of various stripes – mainstream or extremist – religion matters.


Often, religion matters a great deal. It inspires supporters to action; it affects the willingness to die (and, in the case of ISIS, the willingness to kill); it influences strategic calculations and even battlefield decisions. Insisting otherwise isn’t even effective at countering Islamophobia, since, to the unpersuaded, claims that Islam and ISIS are unrelated sound entirely divorced from reality.

[In light of the Paris attacks, is it time to eradicate religion?]

Instead, we can and should have a debate – hopefully a nuanced, informed one – about how religious motivations and political context (such as civil wars or governance deficits) interact in the case of ISIS and other religiously influenced movements. It is tough to have that discussion when the starting premise is to disregard the importance of religion as an explanatory factor.


The analytical approach I’m proposing comes with its own risks. Underscoring the power of religion in general, and Islam in particular, may provide fodder for bigots who might latch on to our statements and misuse them for their own ends.

In the end, though, it’s not my job to make Islam look good, or to argue that Islam “is a religion of peace,” when the reality is more complicated. We have to be faithful to our findings and conclusions, even if – or perhaps particularly when – they make us most uncomfortable.


"
"Attention, Muslims: Don’t boycott the president!",7-21-2014,"The American Muslim community, suffering from an accumulated six years of disappointment with President Obama’s policies, is roiled by an increasingly charged debate. After the high point of the 2009 Cairo speech, the administration has angered Muslims on surveillance and civil liberties, its failures on the peace process, inaction on Syria and a general aimlessness (or worse) on the Arab Spring. Things seemed to come to a head with an attempted boycott of the White House’s annual Ramadan iftar, or breaking of the fast, with community leaders. Muslims, lacking a strong lobbying presence in Washington, may feel particularly disadvantaged, but the dilemma is a universal one: Are changes in policy more likely to come about as a result of working “within the system,” or through a more oppositional, protest-oriented politics? In his response to the boycott calls, Rep. Keith Ellison, one of the two Muslims in Congress, looked back to the civil rights movement for guidance. “The leaders of the Montgomery Bus boycott and the United Farm Workers’ boycotts didn’t have the opportunity to speak directly to the White House about the issues affecting their communities,” Ellison said in a statement. “Boycotting was one of the few tools on the table at that time.” The iftar wasn’t just a photo-op. Attendees had the opportunity to discuss a variety of sensitive issues with Obama and his team, and several of them took full advantage. According to various accounts, the discussions appear to have been tense. Then the iftar itself became a problem. Obama, in what seemed like a head-scratching use of a religious celebration, emphasized Israel’s right to defend itself, while offering no criticism of Israel’s disproportionate use of force. Given the setting — this wasn’t exactly a news briefing, and many attendees had already mulled a boycott — it provoked outrage throughout the Arab- and Muslim-American communities. It seemed like a deliberate slight: Either Obama knew it would anger his audience and went ahead anyway, or didn’t, and neither reflected well on the president. On Twitter and Facebook, the iftar attendees were branded as sell-outs and traitors to the cause, or, worse, “house Muslims.” Why didn’t Muslim leaders walk out to register their disapproval, many asked. Advertisement Everyone who was at the #WhiteHouseIftar should wear a scarlet “T”, for traitor. Seriously I’m baffled. — Rayan (@rayanqab) July 14, 2014 Luckily, none did. It would have been a classic act of self-destruction. Feeling morally satisfied is one thing, but it would have looked terrible to those outside the community, suggesting Muslims were unwilling to listen to, much less accept, alternative viewpoints. It would have also set a troubling precedent, especially with an administration that has been uniquely disappointing on an array of Middle East conflicts, including in Syria, Iraq and Egypt. If we started now, there would be no end to “walking out.” Since the Arab Spring began, the Syrian regime and Egyptian authorities have been more brutal to their own people than Israel has been to Palestinians under occupation. But, of course, Palestine, in a way that the others aren’t, is the open wound of the Muslim community — and one that unites people who otherwise can’t agree on much at all. Even here, though, cracks have emerged in recent weeks. Rabia Chaudry, a fellow with the Truman National Security Project, launched the debate with an article in Time magazine that filled the Facebook pages of politically active Muslims. She had taken part in a fellowship program, funded by the Shalom Hartman Institute, which invites Muslims “to experience how Jews understand Judaism, Israel, and themselves.” Chaudry, who always saw herself as “proudly anti-Zionist,” spoke positively of the experience. “After a year,” she wrote, “we built the trust necessary for a needed exchange of admissions. The Muslim fellows understood Jewish fear and the Jews’ deep desire for a homeland after thousands of years of being a mistrusted minority.” What followed was a volley of responses, clarifications and attacks (for a taste, see here, here and here). Chaudry and the other participants were attacked for, among other things, “breaking BDS” — the Boycott, Divestment and Sanctions movement — by working side by side with a Zionist organization. (It wasn’t clear why American Muslims were under any obligation to respect BDS rules, if they didn’t, in fact, agree with the BDS line.) But since the overwhelming majority of Jews are “Zionists,” in that they believe Jews should have a homeland where they are a majority, a ban on dialogue with Zionists means a ban on dialogue with the very population whose agreement will be needed for any future peace. And the BDS movement will become increasingly relevant – and contentious – the more time passes without a two-state peace deal. Yet it’s very problematic to use BDS as a litmus test for American Muslims to prove their activist bona fides. All too often, BDS goes hand-in-hand with calls for a one-state solution. For example, the original BDS demands do not include any mention of West Bank and Gaza borders or U.N. Resolution 242, long the bedrock of the two-state solution, and refer to the Israeli occupation of Palestine rather than the territories acquired through force in 1967. Dismantling the Jewish state is an example of correcting a previous wrong with another wrong (unless, of course, Israelis somehow decided, through the democratic process, to change the very nature of their state). And even if a one-state solution were “right,” it is completely impractical. There is no historical precedent for a people voluntarily merging into a new state where they become the minority. Because the one-state option is so impractical – and Washington tries to focus on what can actually get done – it discourages engagement with government. Discussing a binational solution with even the most open-minded members of Obama’s national security team is a non-starter. Again, it is an old debate about how change happens, and perhaps the only answer is to accept that Muslims, like any other community, can, should and will have conflicting views on any number of issues, including Palestine. But, as a believer in the importance of engaging with policymakers, I worry that the oppositional approach – strengthened by the slight of the Muslim community at the White House iftar and the slow deterioration of U.S. policy toward the region more generally – is growing ever more attractive."
"In Egypt, one coup leads to another",7-12-2013,"It may be one of the most remarkable political rants ever caught on television. On the day before Egypt's coup, opposition activist Ehab al-Khouli launched into a vociferous diatribe when asked about Mohamed Morsi's last public speech as president.

“This ‘former’ president is addicted to his throne,” he screamed, gesturing wildly. “This man is a liar and a deceiver.” He gasped for breath and doubled over, coughing, as the talk show host pleaded with him to calm down. But he continued — beating the table, jumping out of his chair — for nearly four minutes.

Al-Khouli, in rather stark form, captured the anger and frustration of the millions of Egyptians who took to the streets on June 30. For many, democracy was not simply a matter of faith, or even of principle, but a means to something else: a sense of dignity, the promise of economic benefit, or the freedom to dress and think as they wish. Their sense that democracy had failed to bring real gains set in motion the breakdown of political order, the return of the generals and the overthrow of Egypt’s first democratically elected president.


The problem with coups is that, far from resolving conflicts, they threaten to exacerbate them. Soon after Morsi was ousted, the Egyptian military shut down several Islamist television stations and ordered the arrests of hundreds of Muslim Brotherhood members. The repression escalated this past week, with soldiers gunning down more than 50 Morsi supporters and the new military-appointed president issuing a constitutional decree granting himself nearly unlimited power.


Follow Shadi Hamid

Follow
Although a six-month timeline has been set for elections, these events paint a dark picture of what’s to come. With the country divided over the legitimacy of its leaders, repression is almost inevitable as a way to enforce the new order.

There is little doubt that Morsi was an incredibly disappointing president, narrow in vision and incompetent in execution. He should have realized that the greatest threat to a young democracy comes from those who believe they have no stake in the political system. These are the spoilers and they must be brought in. This requires magnanimity. Even if you are “right” — even if you win five successive elections, as the Muslim Brotherhood did — you can, and should, offer more concessions. And, to the extent possible, you should mean it.


Yet, under Morsi, a political process was in place that at least allowed the opposition to challenge his decisions, win a plurality in parliamentary elections and perhaps even form a government. In other words, there was the possibility of change from within the system.

Whether that possibility exists today is very much in doubt. One part of the country considers Adly Mansour the legitimate head of state while another considers Morsi the rightful president. The coup and subsequent crackdown have pushed millions of Morsi supporters outside the political order. It will be difficult for them to participate in a process they do not acknowledge. Yes, democracy is more than the ballot box. But the turmoil in Egypt underlines the importance of taking elections more seriously as the foundation of a democratic order.

If all it takes are massive crowds in the streets to bring down an elected leader, the very notion of democratic legitimacy will find itself under attack by a permanent revolution of sorts. As one Morsi partisan reasoned just a day before the coup, ""It's fine. If [Morsi] goes down, we'll bring down the president they elect.""

Advertisement

This is in a way its own crude form of democracy, with voting booths replaced by city squares and wide boulevards, and the act of counting votes replaced by the sheer mass of bodies. Political competition is reduced to a war of crowds and, inevitably, inflated protest counts. The 33 million cited by anti-Morsi protesters is not just a product of over-exuberance and a lack of spatial perception, but represents a pure, unmediated populism that appropriates “the people,” and their will, for ultimately divisive ends.

The case for procedural democracy may sound boring and staid. It is not the stuff of political fashion. I remember seeing my Egyptian and Tunisian friends voting for the first time in 2011, showing off stained index fingers. It felt good, but it could not compare to the rush of revolt. It was perhaps the historian Eric Hobsbawm who captured the feeling most colorfully. ""Next to sex,"" he wrote in his 2002 autobiography, ""the activity combining bodily experience and intense emotion to the highest degree is the participation in a mass demonstration at a time of great public exaltation.""

There is little glamour to be had in following electoral procedures, building political parties and organizing voters who may have lost faith in politicians. But all of these things are essential, and without them there is no real way to practice politics.

If and when Egypt has another round of free, fair and inclusive elections, the outcome will need to be respected rather than discarded as it was in the five successive polls over the course of 2011 and 2012. Democracy, at its very essence, is not about winning — anyone can do that — but learning how to lose."
"In Egypt, trying to reaffirm faith in their revolution",11-25-2011,"As Tahrir Square was beginning to erupt this past Sunday, I was talking with a parliamentary candidate affiliated with the Muslim Brotherhood's new political party. For nearly two hours, in a cafe in the posh Cairo neighborhood of Zamalek, we discussed the elections slated for this Monday, Egypt's first since the fall of President Hosni Mubarak in February. He explained the Muslim Brotherhood's get-out-the-vote strategy and his own campaign activities. Tahrir did not come up once.

Just a few days later, Egypt was transformed.

The renewed unrest started last Saturday, when the military, for reasons that remain unclear, decided to forcefully disperse a small group of peaceful protesters encamped in the square. For a growing number of politicized Egyptians, the ruling military council, initially lauded for forcing Mubarak out, has become the reviled symbol of a revolution gone awry. It had woefully mismanaged the transition, falling back on the autocratic ways of the past. The appointment Friday of 78-year-old Kamal el-Ganzouri as prime minister did little to change that view.


As the protests intensified, Cairo seemed to contain two distinct worlds operating in parallel: the world of Western-style campaigning, with microtargeting, door-to-door meet-and-greets and mass rallies, and the world of adamant, angry street protests. They had similar goals — the end of military rule, for example — but very different ideas of how to achieve them.


Follow Shadi Hamid

Follow
These protests, with fierce street battles and more than 40 killed, felt different from the ""first revolution"" earlier this year. They didn't seem to be political, in the normal sense of the word. At first there weren't clear political demands. Many of the protesters went to the square in large part to defend it against the brutality of the security forces. In this respect, the demonstrations were about solidarity as much as a desire to oust the ruling military council. Other protesters, meanwhile, were there for spiritual reasons, to recapture something, a feeling perhaps, that had been lost since those euphoric days in January and February.

A year ago, the nation witnessed its most fraudulent elections in history, with the ruling National Democratic Party winning 209 out of 211 seats in the first round. Less than two months later, Egypt had its revolt. Ordinary Egyptians no longer felt like waiting. They had lost faith in what was left of a discredited political process.


Nine months later, this same loss of faith is evident among the crowds in Tahrir. They do not trust the political parties — in fact, they have prevented numerous politicians from entering the square, shouting them down when they tried. Many simply don’t believe that the revolution’s goals can be achieved through the ballot box. In the elections scheduled for Monday, “revolutionary” candidates are likely to win only a small percentage of the vote, if they even manage to clear the parliamentary threshold.

Meanwhile, the Muslim Brotherhood, after more than 80 years, remains Egypt’s largest and most powerful political movement. It is almost certain to win a sizable plurality in the elections. For all the talk of its violent past and ideological rigidity, the Brotherhood is thoroughly — and, for many of its younger members, disappointingly — pragmatic. Its gospel is patience and discipline, something it learned the hard way in the prisons of President Gamal Abdel Nasser. The Brotherhood refers to this period as the mihna, or inquisition. It actively supported Nasser’s 1952 “revolution” — really just a military coup — but he quickly turned against the Brotherhood, banning the organization, and imprisoning and even executing many of its leaders.

From 2006 until the eve of Egypt’s revolution, Islamists were being crushed by the Mubarak regime, bringing back memories of the mihna. Yet, oddly, they didn’t seem angry. Muslim Brotherhood leaders would often tell me in calm, confident tones: “We aren’t in a rush. It’s a matter of time.”


The Brotherhood, along with nearly all of the country’s political elites, believed for decades that change was possible through the political process, however flawed. Sure, Egypt had an authoritarian regime, but the repression was never total. Through influential professional associations and the parliament, the Brotherhood, along with various liberal and leftist parties, hoped to effect gradual but meaningful change.

This model, however, failed. Revolution, something that no one had really thought possible, somehow came to Cairo, fueled by Tunisia's spontaneous uprising the month before.

It is ironic that in the new Egypt, the Brotherhood and its Freedom and Justice Party are the ones who speak the language of politics. Driven by the fading but still-powerful memories of the Jan. 25 revolution, it is the masses of Tahrir who speak the language of faith — faith in an ideal that may be well out of reach.


This contrast raises the question: What was Egypt’s revolution actually about? For some, it was about freedom and democracy. Once there was a democratic process, Egyptians could work through elected representatives to bring about social and economic change. This change, by its very nature, would be slow and uneven.

For others, probably the majority, Egypt’s revolution was also about a word — “dignity” — that is even more powerful in Arabic. When Egyptians use the word “karama,” there is something almost mystical about it. All the humiliation they’ve suffered, and all the hopes they manage to hold on to, fall under karama. In a revolution about dignity, though, tangible results are hard to come by and even harder to measure.

Through their actions in Tahrir Square this past week — in the pitched battles with security forces, in facing down tear gas and live ammunition — the protesters have defended their dignity and, in the process, reaffirmed the ideals of the revolution. The legitimacy of their ongoing uprising, which is far from complete, doesn’t come from an elected parliament of notables and politicians, but from the street. In this respect, the Egyptian and Arab revolutions of the past year have more in common with the Occupy Wall Street movement and like-minded protests in Greece and Italy than they do with, for example, the revolutions that spread through Eastern Europe nearly a decade ago.


On Tuesday morning, before the Tahrir crowds swelled into the tens of thousands, I sat down with Dina Zakaria, a leading member of the Brotherhood’s Freedom and Justice Party. I immediately brought up Tahrir; as many as 30 people had died by then. She had a pained look on her face, and I could tell she was struggling with the Brotherhood’s decision not to join the protesters. “I thought to myself, how can we abandon the people in the square?” she said. “I can’t bear to see people still being killed.”

She continued: “But at the same time, does this movement stay in the street, or should it be expressed through institutions? I think the right choice is through institutions.”

For decades, Egypt’s Islamists tried to work within the confines of the old regime. Patience and pragmatism might make for good politics, but, on the eve of Egypt’s landmark elections, it is an open question whether they’re good for the country’s stillborn democracy.

Advertisement

After a week of polarization, unrest and bloodshed, that question is even more difficult to answer. I had come to Egypt to write about the country’s first elections after the revolution. On Friday, while protesters were gathering peacefully in Tahrir, I visited a pro-military rally in the district of Abbassiya. I tried to engage the demonstrators in conversation, but several participants, suspicious of my American-accented Arabic, wondered aloud if I might be a spy. I was soon shouted down and ushered out of the area.

The cabdriver who picked me up was of the same mind. As we talked politics, he asked me where I was from and seemed suspicious. Suddenly, as we passed the Zamalek police station, he stopped the car, grabbed me and told the guards that I was up to no good. My cabdriver was attempting a citizen’s arrest. Fortunately, it failed. But the driver had wanted to take things into his own hands. He, too, had little patience for institutions. The street, it appears, has its own logic.

"
"Sometimes, Consensus Can Be Ruinous",3-18-2023,"The U.S. invasion of Iraq was the most consequential political event of the past two decades. But it doesn’t feel that way. It has the faint whiff of youthful indiscretion, an episode that many Americans would rather forget. I was 19. The tenor of that time in American life—after the September 11 attacks—seems ever more foreign to me. Instead of the chaotic information overload of the current moment, in which consensus appears impossible, the early 2000s were a time of conformity, authority, and security. When I think about why even the mere idea of consensus makes me anxious to this day, I keep coming back to what happened 20 long years ago. Consensus can be nice, but it can also be dangerous.
Once American ground troops were engaged in Afghanistan, risking their lives fighting the Taliban, any criticism of the war effort invited charges of disloyalty. That was the “good war.” I was a freshman in college on 9/11. Just a year later, in the lead-up to the Iraq invasion, I became active in the anti-war movement. Grappling with my own identity as an American Muslim in an environment rife with Islamophobia, I wanted somewhere to belong—a safe space, so to speak. And I found it. For the first and probably last time, I organized a die-in. I also helped organize a “tent-in” with a group of friends and fellow travelers, a motley crew of socialists, anarchists, and ordinary students who found themselves stupefied by a war that seemed self-evidently absurd. In the weeks before the war began—and then for the entire duration of the invasion—we protested by setting up camp in Georgetown University’s free-expression zone, the ironically named Red Square. In practice, at least one person was expected to sleep in the tents on any given night, which translated into a continuous presence of more than 2,000 hours.
David Frum: The Iraq War reconsidered
We failed. Obviously, we were just college students, naive and not yet cynical. But there were many of us. On February 15 and 16, 2003—a weekend of coordinated anti-war demonstrations around the globe—more than 6 million people filled the streets in hundreds of cities. As Patrick Tyler put it in The New York Times, “There may still be two superpowers on the planet: the United States and world public opinion.” It was an odd thought, that the people, united, could stop a terrible thing from happening.
When President George W. Bush infamously declared in May 2003—less than a month after Baghdad fell to U.S. forces—that the mission had been accomplished, an extended period of confusion and reckoning set in. After the apathy and triumphalism ushered in by the Cold War’s end, mass mobilization was back. But what was the point of people power if government officials couldn’t be bothered to listen? They had already decided. A relatively small number of so-called neoconservatives, many of whom had run in the same rarified intellectual circles, were committed to a marriage of overwhelming power and maximalist purpose. As the Lebanese American scholar Fouad Ajami described it:
A reforming zeal must thus be loaded up with the baggage and the gear. No great apologies ought to be made for America’s “unilateralism.” The region can live with and use that unilateralism. The considerable power now at America’s disposal can be used by one and all as a justification for going along with American goals.
Like most utopians, they may have been well-meaning in their fervor. A true believer himself, George W. Bush had admirable views about democracy’s universality, for which he deserves some credit. He excoriated critics for suggesting that Arabs weren’t ready for democracy; this was nothing more than “cultural condescension,” he said. He was right. In a November 2003 speech marking the 20th anniversary of the National Endowment for Democracy, he asked, “Are millions of men and women and children condemned by history or culture to live in despotism? Are they alone never to know freedom, and never even to have a choice in the matter? I, for one, do not believe it.”
But the stated justification for invading Iraq was not that Saddam Hussein was a dictator. After all, America’s closest allies in the region were dictatorships too. As senior administration officials told the United Nations and Congress, military action was necessary because Saddam’s regime had weapons of mass destruction and was therefore a mortal threat to the Middle East. Others who might have otherwise been skeptical about the indiscriminate use of American power—including prominent Democrats such as John Kerry and Hillary Clinton—fell in line. In October 2002, 39 percent of Democrats in the House supported the Authorization for Use of Military Force Against Iraq Resolution. Remarkably, 58 percent of Senate Democrats voted in favor. It was the worst and perhaps most tragic example of “bipartisan cooperation” in recent American history.
Their hearts weren’t necessarily in it, but Senate Democrats were an ambitious bunch. For anyone who aspired to higher office, being on the wrong side of the right war was a risky proposition. With the wounds of September 11 still smarting, vengeance was in the air. In mainstream media outlets, passionate anti-war voices—before the war, rather than after—were difficult to find. I mostly got my daily dose of anti-war news and coverage from small leftist websites. I even wrote for one such publication: It was (and still is) called CounterPunch, a wholly appropriate description of both the futility and pluckiness of the endeavor.
A sizable minority of Americans had their reservations about this new culture of patriotic deference, but they were on the defensive from the very start. The post-9/11 consensus was a tragedy upon a tragedy, exemplified by a 98–1 Senate vote for the PATRIOT Act just 44 days after the attacks. “National unity” is usually an aspiration not met. Here, it seemed within reach.
Melvyn P. Leffler: What really took America to war in Iraq
This was bipartisan cooperation at its best but also its worst. At more than 130 pages, the PATRIOT Act—a suitably Orwellian acronym for “Providing Appropriate Tools Required to Intercept and Obstruct Terrorism”—ushered in a perpetually overreaching national-security state and a litany of civil-rights abuses that disproportionately affected Arab and Muslim communities. As the ACLU described it, “While most Americans think it was created to catch terrorists, the Patriot Act actually turns regular citizens into suspects.” Under an expansive surveillance regime, the FBI issued about 192,000 “national security letters” from 2003 to 2006, which allowed it to access the private information of American citizens without a warrant.
This is what unity, consensus, and cooperation made possible in the fog of war. For those Americans today who lament polarization and long for a return to the politics of consensus, be careful what you wish for. In 2001, within a sprawling, unwieldy democracy of 285 million people, what could “consensus” even mean? As the Belgian political theorist Chantal Mouffe has written, “All forms of consensus are by necessity based on acts of exclusion.” The post-9/11 consensus was artificial, guided and reinforced from above. It was also fleeting. When the Bush administration’s hold on the public imagination weakened, Americans returned to their natural boisterousness and distrust of politicians and institutions alike. This is a good thing.
When it comes to wars of choice—which is to say, most wars—Americans should disagree among themselves, and they should express those disagreements forcefully. A democratized news landscape, like democracy itself, can be messy. But that messiness is essential. A certain kind of chaos is precisely what allows for a vibrant exchange of contending and conflicting views. In a democracy, the majority still rules. At the same time, embattled minorities need avenues—and encouragement—to register their dissent, in the hope of convincing enough of their fellow citizens that they are right. Because sometimes they are. And the Iraq War was one of those times.
"
You’re Better Off Not Knowing,3-13-2023,"For many Americans, these claims sound self-evidently true: Information is good; knowledge is power; awareness of social ills is the mark of the responsible citizen. But what if they aren’t correct? Recent studies on the link between political awareness and individual well-being have gestured toward a liberating, if dark, alternative. Sometimes—perhaps even most of the time—it is better not to know.
Like taking a drug, learning about politics and following the news can become addictive, yet Americans are encouraged to do more of it, lest we become uninformed. Unless you have a job that requires you to know things, however, it’s unclear what the news—good or bad—actually does for you, beyond making you aware of things you have no real control over. Most of the things we could know are a distraction from the most important things that we already know: family, faith, friendship, and community. If our time on Earth is finite—on average, we have only about 4,000 weeks—we should choose wisely what to do with it.
What the writer Sarah Haider calls “information addiction” is nothing short of an epidemic. In a quite literal sense, politics is making Americans sick. But the sole way to contract the illness is by seeking out the news and consuming large amounts of it. And that’s a choice. Haider chose differently, deciding to go news free for six months in late 2021 and early 2022. Having missed out on stories that were speculative, overhyped, or irrelevant, she reported being “saner, happier, and (surprisingly) more informed.” But does it make sense for other Americans, perhaps millions of them, to completely rethink their relationship to political information and knowledge? In a 2022 study, the political scientist Kevin Smith estimated that between 50 million and 85 million Americans suffer from politically induced fatigue, insomnia, loss of temper, and impulse-control problems. Moreover, 40 percent of his sample of American adults reported that politics was a “significant source of stress” in their lives, while 5 percent—which would translate to roughly 12 million people—reported suicidal thoughts due to politics.
And the problem is especially bad for young people. Last month, the CDC reported that depression and suicidal ideation are at their highest levels on record, with one in three teenage girls having seriously considered suicide. Boys aren’t faring particularly well either. Some observers insist that smartphones are the culprit, but smartphones are ubiquitous in all advanced democracies. In another study, politically induced mental and physical symptoms appear to be more pronounced among not just the young, but specifically those who are politically engaged and left-leaning. Young conservatives, despite presumably also owning phones, experience significantly lower levels of dissatisfaction.
Conor Friedersdorf: The trouble with boys and men
In the United States, the combination of being young, engaged, and liberal has become associated with anxiety, unhappiness, and even despair. If you’re a progressive, wanting your kids to be progressive is obviously understandable. It might be good for the world, but it might not be good for their health. The co-authors of a study on the politics of depression argue that since around 2010, left-leaning adolescents may have “experienced alienation within a growing conservative political climate such that their mental health suffered in comparison to that of their conservative peers whose hegemonic views were flourishing.”
According to this line of thinking, liberals, because of their liberalism, have good reason to be depressed. After all, life is bad, America is bad, and the world is bad. As The Washington Post’s Taylor Lorenz recently put it on Twitter, “We’re living in a late stage capitalist hellscape.” But this is not true, at least not the hellscape part. Despite claims to the contrary, the United States is not experiencing civil war, nor is it under a dictatorship. It is a democracy, and one of the wealthiest that has ever existed. Although far from ideal, the American safety net has grown more rather than less generous, as measured by public social spending as a percentage of GDP. Unemployment is at its lowest rate since the 1950s. Child poverty, according to one comprehensive analysis, has declined by 59 percent in the past three decades.
Meanwhile, on cultural questions, the 2010s and ’20s have witnessed one of the most striking progressive shifts in American history. Conservative views are not hegemonic. In major cities and mainstream institutions, the cultural left has established a dominance that would have been unimaginable decades ago. New norms around social justice—or, more pejoratively, “wokeness”—now prevail in the medical profession, in the U.S. government bureaucracy, and in universities. What my colleague Helen Lewis calls “woke capitalism” has spread through corporations that might have otherwise been indifferent to justice, social or otherwise. The rapid acceptance of gay marriage has been nothing short of remarkable. Progress comes gradually and then suddenly. In an influential 2021 essay, the writer Richard Hanania laid out an exhaustive case for why “almost every major institution in America that is not explicitly conservative leans left.”
Helen Lewis: Cancel culture and the problem of woke capitalism
If this is true, why aren’t young conservatives more depressed? Hanania suggests that it’s because they care less about politics. But it’s also likely a question of demographics. On college campuses and in major cities, conservatives tend to be a minority. So they have little choice but to acclimate themselves to a liberal environment and learn to interact with those who are different from them. A 2021 Generation Lab/Axios survey of college students found that only 5 percent of Republicans would not work for “someone who voted for the opposing presidential candidate,” compared with 30 percent of Democrats. Meanwhile, 71 percent of Democrats say they would not date someone who voted for the other candidate, compared with only 31 percent of Republicans.
While progressive cultural norms face growing pushback, not just from conservatives but from otherwise left-leaning communities of color, progressives can take solace and pride in having won most of the great cultural battles of the 21st century so far. Despite these myriad successes and victories, however, young progressives—who are more likely to closely follow the news and care about it—have developed a habit of thinking catastrophically. The old media adage “If it bleeds, it leads” has now been repurposed for the era of equity and inclusion: Injustices are systemic, the thinking goes, and beyond the agency or control of mere individuals. White supremacy is embedded everywhere, not just in our institutions but in our language.
Read: Why Democrats are losing Hispanic voters
For people who view the world in these terms, being depressed is evidence of virtue. In the study on the politics of depression, for example, the co-authors note that “liberalism frequently signals a relatively greater awareness of social disparities that may be damaging to mental wellbeing, especially among less privileged groups who are the targets of societal neglect.” Meanwhile, the authors of a 2023 article in the Journal of Personality and Social Psychology lament the implications of their own findings that knowledge of daily political events contributes to “worse psychological and physical well-being.” They offer the cautionary note that “although it is natural to want to feel better in the face of stress, feeling better can come with both benefits and costs.” Apparently, the cost of feeling better is that people may experience “less motivation to take political action” and may “divert their attention away from the injustice, thereby minimizing their likelihood of taking to the street.”
Such arguments are morally questionable, at best. Catastrophic thinking and negativity bias should not be encouraged, even if they lead to more just social outcomes. After all, how just can outcomes be if they come at the cost of the mental health of tens of millions of Americans who have been taught to expect the worst? As the writer Matthew Yglesias recently argued, “Mentally processing ambiguous events with a negative spin is just what depression is.” He adds that “our educational institutions have increasingly created an environment where students are objectively incentivized to cultivate their own fragility as a power move.”
However difficult it may be, Americans need to find ways to disengage from the constant assault of politics. In a culture where everything is “problematic” even if it’s not, the drumbeat of everyday political events too easily arouses worry, anger, and hopelessness. Indeed, focusing on supposed catastrophes, including those far out into the future, can have even more profound effects that are at once odd and unnatural. Remarkably, The New York Times’ Ezra Klein observed last year that the question he’s been asked more than any other in his public engagements is: “Should I have kids, given the climate crisis they will face?” This is the platonic ideal of catastrophic thinking. Klein’s interlocutors, among other things, are probably reading too much news.
If there were a way to consume the news without catastrophizing it, then that could be one path forward. But progressives in particular have trouble doing so. For them, to be aware of the ills of the world is to feel compelled to speak and act—or at least to feel. If we can’t all go news free—which is difficult in the world as it is—we can, at the very least, establish a truce with the news. Information and knowledge can be—and often are—quite great. But they are not unqualified goods. Sometimes ignorance is, in fact, bliss.
"
Americans Should Not Be Tempted by China’s COVID Policies,11-11-2022,"The human capacity to transcend the past and even the present is powerful. Three years after a devastating coronavirus pandemic took hold, nearly every country has dropped restrictions and mostly resumed normal life. The one country where COVID has never seemed to end, however, is China.
After the country’s largest protests in decades, Chinese officials are finally rolling back some of their harshest “zero COVID” pandemic regulations. But China’s COVID regime still remains one of the world’s most restrictive, with officials retaining the ability to enforce lockdowns in designated “high-risk areas.” The adoption of zero-COVID measures and now their abrupt reversal have revived a debate over whether autocracies like China are more effective at governance than democracies like America.
No American should be tempted by this false equivalence. China’s pandemic strategy has been woefully misguided from the start, illustrating the many dangers of one-man rule and an all-encompassing surveillance state.
The authoritarian bargain in China has long been clear: Citizens forsake their freedom in return for economic gains through cheap labor. Because dictatorships, by definition, do not enjoy democratic legitimacy, their legitimacy relies almost entirely on performance—what political scientists call “output legitimacy.” The problem with this sort of legitimacy is that it can easily be undone by unusual circumstances and external shocks. China’s strict measures may have succeeded in containing COVID early on, but its draconian policies ever since have tested the limits of the populace’s patience. The once-formidable Chinese economy has ground to a halt, crippling businesses and sending youth unemployment to record highs. As a frustrated protester in the city of Chongqing put it: “There is only one disease in the world, that is, being unfree and poor, and now we have both.”
Read: China’s COVID wave is coming
In the beginning, many observers hailed China as a model of pandemic management. As cases of the virus piled up and the United States dithered in March and April of 2020, China moved rapidly, building “instant hospitals” from scratch in days, introducing door-to-door health checks, and enforcing city-wide quarantines. The World Health Organization offered its “deepest congratulations” to China in the fall of 2020 “for having reached such a successful outcome.” The prestigious journal Lancet Infectious Diseases appeared to take some pleasure in contrasting China’s pandemic management with America’s under the Trump administration.
China’s early approach no doubt saved many lives. But over time, as much of the world moved past COVID, China intensified its zero-tolerance strategy, to the extent that citizens in one border city were prohibited from leaving their homes for 119 days earlier this year. Yet after a recent Washington Post article pointed out a flaw in China’s zero-COVID policy—few people in the country have developed natural immunity to the virus—some in the media came to China’s defense. To this day, even critiques of China’s COVID policy seem unable to jettison the narrative that China’s model was preferable to the alternatives. A recent New York Times article, for example, read:
After the initial outbreak of Covid in 2020, China’s economy bounced back quickly. While the rest of the world remained in lockdown, China’s hard-line approach to keeping the coronavirus in check worked well and its economy roared to life. In particular, exports were a bright spot as Chinese factories manufactured many of the products that the rest of the world bought online during isolation.
For those who allowed themselves to be tempted by the Chinese model, the question is why. It was a model that could only be imposed by brute force and by effectively shutting an entire country off from the rest of the world, a very difficult thing to do unless you happened to live on a remote island.
Despite their faults, democracies are morally and politically superior to autocracies, however efficient, strong, or “benevolent” the latter appear to be. Appearances are deceiving. In China, there were no pesky voters, checks and balances, bureaucratic constraints, or fractious debates over “following the science” to worry about. There was no polarization. But that’s because polarization is possible only when citizens can express contrasting opinions in public. It might be unfashionable to say so, but the United States is better not in spite of its democracy, but because of it.
It’s true that autocracies are often more efficient than their democratic counterparts. If the only relevant metric were getting things done without delay, the Chinese government is undoubtedly impressive. But efficiency, like all things, comes at a cost, and sometimes the cost is quite high. Similarly, authoritarian states might produce better policy outcomes in the short run. The problem with autocrats, though, is that even if they make “good” decisions for a particular stretch of time, their good judgment never seems to last. In reality, the “benevolent dictator” is rare. As an idea, it belongs more in speculative fiction than it does in political analysis. Because any mere mortal is prone to error, bias, and delusion, it is only a matter of time before a single leader—without an electorate to counter his or her excesses—begins making unwise, even destructive, choices. And then there is no obvious way to undo the damage, because there is no mechanism through which to censure, constrain, or remove the leader.
Read: Change may be coming in China
When it comes to democracy and its inherent slowness, the flaws are themselves the feature. As I argue in The Problem of Democracy, democracies have the virtue—albeit also the vulnerability—of being better than they seem. Many democracies, however imperfect in the moment, become more appealing in the future. The political theorist David Runciman writes that to understand American democracy, one must “learn not to take it at face value,” because it usually ends up working despite looking like it shouldn’t. China offers an essential counterpoint. Under Chinese autocracy, things weren’t better than they seemed; they were worse.
In 2015, the political scientist Daniel Bell published a book, The China Model, which trumpeted China’s political system as a viable and even appealing alternative to Western democracy. At the time, the notion that China hadn’t merely risen but was fated to continue rising indefinitely was still a popular, if somewhat lazy, trope. Bell’s more far-reaching argument was that East Asian “meritocracy,” however undemocratic, allowed qualified leaders to prioritize the community’s long-term interest while eschewing the more fleeting whims and passions of the masses. The book came out just as the prospect of Donald Trump running the U.S. government was looking more plausible. Four years of democratic chaos at home, including during the COVID outbreak, made authoritarian competence abroad seem both pleasant and predictable.
In practice, however, the Chinese “model” quickly went to work disproving its own premises. On the night of Joe Biden’s electoral victory in 2020, Xi Jinping reportedly told the president-elect that “autocracies will run the world.” Now it’s worth asking whether autocracies can even run their own countries.
"
Can Democracy Exist Without Liberalism?,10-19-2022,"I never expected to look back on the George W. Bush era as a time of relative innocence for the United States. My country changed much more quickly than I could have imagined. In the early days after 9/11, I was still in college. The nation, in a show of bipartisan unity, was on a war footing that produced some of our darkest moments, darker even than what the Donald Trump era would bring. Dissent was rare. To doubt the wisdom of the war in Afghanistan, the passage of the Patriot Act, or the invasion of Iraq was to find oneself in a lonely place.
Book jacket of The Problem of Democracy
This article is adapted from Hamid’s recent book.
As the Bush administration became obsessed with Iraq and preoccupied with transforming the Middle East, any unity of purpose quickly crumbled. But as dispiriting as that time was, our country’s divides weren’t yet existential. They largely revolved around the destructive policies of the Bush administration—policies that could be reversed. And many of them were. Election outcomes were respected. The president had a loyal opposition. Both parties were still broadly located within the classical liberal tradition, with its respect for individual freedoms and minority rights. For all his faults, Bush was a good man, albeit one who ended up supporting terrible things. We were all Americans, and we wanted the best for our country, even if we disagreed on how to bring that about.
Ben Rhodes: The 9/11 era is over
Those years seem quaint in retrospect. A 2006 essay titled “Limits to Democracy,” written by the late conservative philosopher Roger Scruton, underscores how different that era was. President Bush had propelled the question of democracy to the center of public debate, but we were debating democracy in the Middle East, not our own. Were Arabs “ready” for self-government? Was Islam compatible with democracy?
Like most Western thinkers writing at the time, Scruton didn’t really seem to understand Islam. But his essay highlights the fundamental challenge of democratic politics: how, or whether, people can respect election outcomes not to their liking. He contrasts the United States with those pesky Muslim-majority countries that can never quite seem to get their act together. He writes,
The American norm … is wholly unlike that [of highly sectarian countries]. People vote Democrat and find themselves ruled by Republicans. And they accept this—unhappy, perhaps, but acknowledging a duty of obedience and a common loyalty that is far more important than any electoral differences of opinion.
Upon re-reading this passage not long ago, I chuckled at the irony. For Scruton, the ability to be unhappy but still obliging when one’s adversary wins an election is “the precondition of democracy as we know it.” In this sense, the other party, as lousy as it might be, is still merely an opponent rather than an enemy to be vanquished. But according to this metric, the United States no longer meets a key prerequisite of democracy.
The United States has certain advantages when it comes to containing the mutual antagonism of its two parties: strong institutions, democratic norms, and a long history of democratic practice. Well-established, consolidated democracies rarely break down. The United States has also enjoyed the benefits of a democratic culture. Americans believed in small-d democracy and were committed to it. This was who we were. Culture can be overwhelming in its power, both mystical and mystifying. Its judgments, the author Michael Brendan Dougherty has written, are “so familiar that [culture] exists like a voice in your head. And yet it is impossible to explain exactly how this happens.”
Despite their power, however, cultures can change as well as crumble. Today, Americans are doubting both their own democracy and the democratic idea itself. If a country can have a democratic culture in 2006 and then not have one in 2022, is it really a culture? Culture is sticky; it shouldn’t change so easily in just half a generation. I don’t believe that democracy is an aberration in human history, with an arc bending back toward authoritarianism. But I do think we will move toward a shared realization that existential politics is no longer, if it ever was, primarily a Middle Eastern problem. It is a democratic problem. It is the problem of democracy.
Francis Fukuyama: More proof that this really is the end of history
For those of us who care about the democratic idea, this is likely to be the political question for some time to come, and perhaps even for the rest of our lives. Not all problems have solutions, and to think that they should might be a bigger problem. There is a certain kind of wisdom in acknowledging the imperfection of otherwise great ideas, and democracy is a great idea.
This might seem like an odd time to sing the praises of democracy. As the Belgian historian David Van Reybrouck put it in his book Against Elections: “There is something strange going on with democracy. Everyone seems to want it but no one believes in it any longer.” Fears that its staying power is declining have intensified, including in the United States.
The two core components of liberal democracy—liberalism and democracy—have been diverging for some time. For most of the modern era, the two concepts went hand in hand, at least in the West. The liberal tradition, which emerged after Europe exhausted itself with wars of religion, is eloquently captured in documents such as the Bill of Rights. Meanwhile, democracy, while requiring some minimal protection of rights to allow for fair and meaningful competition, is more concerned with the preferences of majorities as expressed through regular elections. Democracies must be responsive to what voters actually vote for. This is what makes democracy great. It is also what makes democracy frightening. No one knows with certainty what will happen in an election before it happens.
In the suggestively titled The People vs. Democracy, the political scientist and Atlantic contributor Yascha Mounk captures one of the more intriguing aspects of the current moment:
On the one hand, the preferences of the people are increasingly illiberal: voters are growing impatient with independent institutions and less and less willing to tolerate the rights of ethnic and religious minorities. On the other hand, elites are taking hold of the political system and making it increasingly unresponsive: the powerful are less and less willing to cede to the views of the people.
The divergence of democracy from liberalism has become more obvious of late, and not only in the might-be democracies of the Middle East. In an ever-growing number of established democracies, such as Italy, Sweden, France, Poland, India, Israel, and Brazil, illiberal right-wing parties have made massive gains and even assumed power through democratic means. Their commitment to minority rights and equality before the law has been questionable and at times actively hostile.
The ascendance of liberal democracy during the Cold War and its seeming triumph after the fall of communism made it easy to forget that liberalism and democracy are founded on different conceptions of human needs and wants. Whether the United States should emphasize liberal values—individual autonomy, gender equality, minority-rights protections, and sexual freedom—or electoral democracy hinges on perceptions of what is universal across time and place and what is not.
Before liberalism and democracy began to diverge in the West, they were diverging elsewhere. Muslim-majority countries in the Middle East as well as Southeast Asia have been laboratories of illiberalism. They were ahead of their time, offering a dark preview of a world in which culture, identity, and religion (“who we are”) replaced economic concerns (“what works”) as the fulcrum of political conflict. This is what made the trajectory of the Arab Spring so frustrating for many American observers. This was a world where the most important wars were culture wars. President Trump and his former advisers may not have realized it, but when they complained about the “deep state,” they were importing a concept born in the Middle East.
Unfortunately, I represent the side that lost a great debate over whether democracy in the Middle East was possible and desirable. Periodic conflagrations aside, Americans have lost interest in the region. So, too, have American politicians. President Barack Obama was perhaps the perfect encapsulation of a particular kind of evolution. Briefly, he allowed himself the possibility that the Arab Spring held the promise of better things. But as the Arab Spring turned dark, so, too, did Obama.
From the April 2016 issue: The Obama doctrine
The Atlantic’s Jeffrey Goldberg reported in 2016 that Obama was known to privately joke, “All I need in the Middle East is a few smart autocrats.” Obama wondered out loud why people in the Middle East couldn’t just “be like the Scandinavians.” He fretted that a growing number of Indonesian women were donning headscarves. In his interviews with Goldberg, he put the blame on Muslims for not being sufficiently peaceful. Muslims, he said, need to “undergo a vigorous discussion within their community about how Islam works as part of a peaceful, modern society.” He spoke of a “reformation that would help people adapt their religious doctrines to modernity.” In one State of the Union address, he said discord in the Middle East was “rooted in conflicts that date back millennia.”
Taken together, these statements betray a particular kind of fatalism toward a people, a culture, and a religion. Too many Muslims, it seemed, were intent on defying history’s arc. Like Roger Scruton before him, Obama found himself irritated by a region and its stubborn resistance to change. Fatalism and resignation are understandable. But a justified modesty about democracy’s prospects does not require giving up on the democratic idea.
If liberalism and democracy were intertwined at home, Americans might fairly assume that they would go together abroad. If liberal values derived from the dignity of the human person, then they had universal applicability. This universalism—transcending culture and geography—made the liberal idea both inspiring and consistent with America’s self-conception. As Theodore Roosevelt once put it: “Our chief usefulness to humanity rests on combining power with high purpose.” That purpose had more to do with Enlightenment liberalism and liberty than with popular democracy. The Founders certainly had their reservations about the latter. As John Adams described it: “There never was a democracy yet that did not commit suicide.” Democracies, James Madison declared, are “as short in their lives as they have been violent in their deaths.”
More than a century later, Franklin D. Roosevelt didn’t wax poetic about the four prerequisites of democracy; he spoke instead of the “four freedoms.” For John F. Kennedy, the “magic power” on our side was “the desire of every person to be free.” Democracy was part of the equation, to be sure, but it wasn’t the primary thrust. And without liberalism tempering it, democracy could be a problem—and one best avoided in underdeveloped foreign societies and cultures.
I am a liberal myself, albeit the kind who is critical of what liberalism has recently become. I would not be comfortable living under a democratically elected Islamist government—or, for that matter, a democratically elected Catholic integralist government. But I am also aware that my own liberalism is contingent—a product of being born in the United States at a certain moment in history. If my parents hadn’t decided to immigrate and if I had had my formative cultural and political experiences in a religiously conservative society, I would have been shaped by those experiences instead.
From the May 2022 issue: There is no liberal world order
As a value system as well as a set of premises about the primacy of reason over revelation, liberalism speaks to the most basic questions of who we are and who we are meant to be. In this sense, it can’t but clash with Islam—a religion that, in its various iterations, has jealously guarded its jurisdiction over such ultimate questions for the better part of 14 centuries. Liberalism also requires liberals, and they simply aren’t numerous enough in the Middle East. That may yet change, but as the allure of classical liberal ideas wanes in the very places where liberalism was born, I struggle to imagine a scenario in which a majority of Egyptians, Jordanians, or Algerians decide to become Western-style liberals, after having not been for so long.
Assessing the appeal of liberal ideas, or the lack thereof, is crucial. Even in the world’s most advanced democracies, post-liberal movements are gaining strength. If democracy is part of a package that includes within it unrelated premises about the nature of progress and the human person, then it is less likely to be accepted in societies where those premises are not shared. And, as it turns out, the world has more of these societies than we might like to admit.
Democracy as a system and a set of procedures—as a way of regulating politics without predetermining its outcomes—allows voters to decide their own course and determine what values are most important to them. Democracy allows for peaceful transfer of power, even—or particularly—in ideologically polarized contexts. As a set of mechanisms for conflict regulation, it contributes to long-term, if not short-term, stability. Democracy also offers predictability, because the losers of elections have the chance to fight another day. I call this approach “democratic minimalism” because it accepts democracy for what it is rather than what it might, or might not, become.
To try to compel people to become liberals is the mark of hubris—bound to be either ineffective, unrealistic, or both. After all, a liberalism not freely chosen is self-negating. Democratic minimalism, by contrast, is more modest, while still retaining the mark of ambition. In politics, one has friends and enemies. The challenge—not just in the Middle East but in the United States and seemingly everywhere else—is accepting this natural state of enmity and transforming it into something more manageable. That might not sound like a lot to aspire to, but it may be enough.
"
The Reason Iran Turned Out to Be So Repressive,10-4-2022,"The Islamic Republic of Iran has survived longer than anyone had a right to expect. Today great revolutions are rare, because revolutions require the unflinching belief that another world is possible. In 1979, when clerics took power in Tehran, another world was possible. This is the world that Iranians still live in. A large—and apparently growing—number of them don’t seem to like it. After a 22-year-old woman named Mahsa Amini died in police custody on September 16 after being arrested for wearing her headscarf improperly, anti-government protests spread across the country, just as they seemingly do every few years.
Kim Ghattas: A whole generation revolts against the Iranian regime
Forty-three years after its founding, the Islamic Republic sputters along as yet another repressive, sclerotic regime. What makes the Iranian system different—exceptional, even—is the arc of its tragedy and the unusual role played by an entirely novel theological doctrine. In the beginning, the Islamic revolution was popular. Otherwise, it wouldn’t have succeeded. The aggressive secularization under the shah in the 1960s and ’70s had been discredited, and millions of Iranians turned to Islamic symbols, concepts, and leaders for inspiration. If the shah’s Westernization project was the problem, then perhaps Islam could be the solution. And yet that solution took a peculiar form, one that foreordained today’s discontent: Iran’s new rulers created a system far more intrusive than clerics of previous centuries could have ever imagined.
If one could sum up the original intent of Ayatollah Ruhollah Khomeini’s revolution, it was, quite simply, to preserve Islam. In his most influential treatise, Islamic Government, published in 1970, Khomeini wrote, “The preservation of Islam is even more important than prayer”—an odd if maddeningly vague claim. In practice, however, this meant something quite specific. For Khomeini, Islam could be “preserved” only through Islamic government. And this, in turn, was possible only if jurists—that is, clerics specializing in Islamic jurisprudence—led the government as guardians of Islam.
The reason this Islamic regime can seem so un-Islamic—merciless and absolutist—is because it did something without precedent in Islamic history. What came to be known as wilayat al-faqih, or “guardianship of the jurist,” married clerical and executive power and intertwined them in a sort of Frankenstein ideology. In the great Islamic caliphates of the premodern era, the legal system was decentralized and the state’s reach was limited, with clerics enjoying considerable autonomy. As the keepers of sharia, God’s law, they interpreted how it applied to matters as varied as criminal codes, business contracts, and inheritance. But these clerics had never ruled directly. Instead, the caliph—who, in most cases, was not trained as a religious scholar—was responsible for executing laws and devising new ones on issues not explicitly covered by sharia. In revolutionary Iran, such distinctions would be put to the side, with a notably sectarian element added to the mix. Iran’s clerics, like the overwhelming majority of Iranians, were part of the Shiite branch of Islam. They would take Shiism’s historical reverence for clergy and fuse it with a modern conception of the state.
Until the Safavid empire emerged in Persia in the 16th century, Shiite Muslims had largely lived as minorities under Sunni rule. Because Shias were rarely in a position to govern, Shiite doctrine had relatively little to say about the appropriate exercise of political power. Shias believed that legitimate authority was to be found in the descendants of the Prophet Muhammad, unlike Sunnis, who—in theory, if not necessarily in practice—selected their leaders through a consultative process. Importantly, Shiite tradition held that the imams in the line of the prophet were divinely protected from error on theological matters.
The problem was that the 12th of these imams went into occultation in the 10th century. He was, and still is, the hidden imam. Because he was endowed with infallible powers of religious interpretation, his absence deprived the Shiite clergy of their source of authority and led them—albeit with some exceptions centuries later—toward a politics of political resignation. As the Islamic legal scholar Mohammad Fadel notes in a forthcoming paper, “All hopes for political transformation were deferred to an indefinite, apocalyptic future.”
For Khomeini, the future arrived in 1979. Any number of questions about how to govern legitimately while the imam was in occultation remained unresolved. Khomeini provided an answer—the responsibilities of the inerrant imam were to be, in effect, delegated to the jurists, and then more specifically to the jurist. It just so happened that Khomeini was that jurist.
In fairness to Khomeini, when he was giving the lectures that would form the core of Islamic Government, he probably hadn’t fully entertained the possibility that, one day, he’d return triumphant to Tehran and get the chance to implement his ideas. Beyond the sort of vague sketching that one tends to do in exile, Khomeini had offered few specifics about how he might actually govern. Some of this ambiguity was strategic. To avoid frightening leftist and liberal allies during the revolution’s honeymoon, he and his supporters downplayed the harder edges of juristic rule.
Ideas matter. Ideology made Iran’s Islamic revolution possible. But ideas do not come fully formed in a vacuum. Unusual ideas are typically the product of unusual situations. As perhaps all political doctrines are, the unadorned radicalism of Khomeini’s philosophy of government was a reaction to what had come before. The shah wasn’t just any dictator. He was an exceptionally brutal one. More than that, he fashioned himself an authoritarian modernizer, like Turkey’s Kemal Atatürk before him, who would cut Islam down to size and reorganize society on strictly secular lines—with Western backing no less. The orchestrated attack on Islam that many Iranians perceived was made more sinister by the unfortunate fact of a CIA-supported coup that had ousted the democratically elected prime minister in 1953, thereby elevating the shah.
Khomeini, along with a growing number of conservative clerics and laymen, came to believe that Islam was in danger of being extinguished. If as much as Islam’s very preservation was at stake, exceptional measures would have to be taken, with a frown and a grimace if need be. This helps explain how Khomeini could possibly declare that the absolute mandate (velayat-e-motlaq) of Islamic government was “the most important of the divine commandments … and has priority over all derivative commandments, even over prayer, fasting, and pilgrimage to Mecca.” In another time and place, this would have been dismissed as nonsensical ranting, or worse, heresy.
Khomeini’s radicalism was real and deeply felt. His grievances were legitimate. But the totalizing nature of the dictatorship to come was not predestined. Another ingredient was necessary. That something else was the modern state, in all of its sprawling, overbearing glory. Until the 20th century, states simply could not be authoritarian in the fullest sense of the word. Their bureaucratic, technological, and surveillance capacity was limited. Even under despots, ordinary people could still live relatively free lives because the state could only extend its tentacles of control so far. The introduction of the nation-state removed any such constraints. Leaders could seek dominion not just over government but over society, too. Not only did they want to change your behavior; they wanted to transform the way you perceived the world.
Read: Sons of the Iranian revolution
If the shah’s strong state was what threatened Islam, a strong state—and perhaps even a stronger one—would be required to protect it from its enemies at home and from those abroad as well. This expansiveness is in the character of revolutions, when they succeed. They are wondrous events. As the longtime Berkeley professor Hamid Algar once argued, perhaps with a hint of hyperbole, the Iranian revolution was “the most significant, hopeful, and profound event in the entirety of contemporary Islamic history.” But many revolutions prove too wondrous. Because they fight against great injustice and promise, in turn, a great reordering, revolutions can’t help but forge a stronger state than the one they seek to destroy.
The irony is that the clerics were well aware of these pitfalls. As the Iranian American sociologist Said Arjomand writes, Khomeini’s original vision was one of “a withered state.” For both better and worse, this antiauthoritarian impulse is embedded in Islam. In the fall of 1979, during the early, heady days of revolution, Khomeini observed that “dictatorship is the greatest sin in Islam.” On this, he wasn’t necessarily wrong. But for the ayatollah and his heirs, the modern state—in all of its power—proved too alluring.
"
The National Conservatives Don’t Know What They Think,9-17-2022,"Donald Trump will be remembered as one of the most consequential presidents in American history. On a political level, he attempted to overturn an election—an unusual enterprise for a president—and popularized the idea that democratic outcomes can be rejected outright if you don’t like the results. Oddly enough, however, Trump’s impact may prove more distinctive and perhaps even more lasting on an intellectual level.
Trump had an instinct that something had gone fundamentally wrong in America and felt that his supporters should be angry as a result. And he came to channel that impulse viscerally. That such an anti-intellectual president could provide inspiration for a distinct intellectual orientation is an amusing twist. The struggle to codify Trumpism and transform it into a working philosophy is under way, to mixed results so far. Earlier this week, self-described “national conservatives” descended upon Miami for a major conference of a movement whose members “understand that the past and future of conservatism are inextricably tied to the idea of the nation.” For them, the nation is a distinct cultural unit, whose independence and sovereignty must be jealously guarded against globalists, international institutions, and large-scale immigration. These are not neoconservatives or even just conservatives. For the national conservatives, the George W. Bushes and Mitt Romneys of the world are the problem. And they themselves are apparently the solution.
David Brooks: The terrifying future of the American right
These partisans of the new right have the potential to push through a genuine reorientation of the Republican Party—not just the haphazard shift that Trump touched off. Because America’s winner-take-all electoral system practically guarantees a two-party system, to transform one of those parties will be to transform American public life. The problem for the national conservatives, however, is that they have defined themselves in opposition to something real but have not necessarily defined what they want to do about it.
As president, Trump demonstrated remarkable flexibility and little regard for ideology. Self-interest trumped all. And it was his self-interest to draw a stark contrast with a Republican Party that was long oriented around the ideas of limited government, free trade, comprehensive immigration reform, and neo-imperial adventures abroad. Through bumper-sticker slogans, such as “America First” and “Make America great again,” that elevated the nation as a sort of transcendent political community, Trump gave permission to conservatives to think beyond the bipartisan assumptions—prioritizing the individual at home and globalization abroad—that had structured postwar American politics. And that consensus, if it wasn’t already dead, was clearly dying.
At least until recently, classical liberalism—not to be confused with the modern American designation of anyone left of center as “liberal”—was the dominant American tradition. At the most basic level, liberalism is the project of carving out rights, which derive from a recognition of the dignity inherent to every human life. Post-liberal movements, including the national conservatives, aren’t in principle opposed to individual rights. The issue is that they believe this conception of liberalism exists only in theory.
In practice, liberalism, animated by a belief in human progress, can’t help but shake free of its past limits, demanding more and more for itself over time. And so the project of carving out rights is ongoing and perpetually in motion, extending itself into new areas—including the right to discard traditional conceptions of gender and sexuality and turning aside the views of anyone who objects. This new liberalism, at once a deformation of liberalism and seemingly its inevitable conclusion, is what Senator Josh Hawley in his conference address called “repressive tolerance” and what the Israeli theorist and conference organizer Yoram Hazony terms “woke neo-Marxism.” For Hazony, the effort to recover “the old liberalism” is futile, an exercise in fighting a battle that has already ended. As someone who studies various iterations of post-liberalism and outright illiberalism, I am intrigued but also worried to see a movement like this gaining ground in my own country. Though the new right may be correct about liberal excesses, its solutions are another matter.
Even though Hazony is an Orthodox Jew, national conservatism has a Christian cast. This isn’t a problem for Hazony, who believes that majorities should have the right to define the contours of a nation’s cultural and political reality. The most recent National Conservatism Statement of Principles, which he helped draft, lays this out in some detail:
The Bible should be read as the first among the sources of a shared Western civilization in schools and universities, and as the rightful inheritance of believers and non-believers alike. Where a Christian majority exists, public life should be rooted in Christianity and its moral vision, which should be honored by the state and other institutions both public and private.
The problem, as with all post-liberal projects, is that although highlighting liberalism’s failures is easy and even necessary—I have made many of these criticisms myself here in these pages—devising a viable alternative is much more difficult.
In perhaps the most striking speech at the National Conservatism conference, Hawley called for a “biblical revolution.” But when he explained what this meant to him, it seemed empty of specific content:
We are a revolutionary nation precisely because we are the heirs of the revolution of the Bible … To a world composed of clans and tribes, the Bible introduced the very idea of the individual. To a world that valued the wealthy and the well-born before all others, the Bible taught the dignity of the common man. To a world that prized order and social control, the Bible spoke of liberty. Without the Bible, there is no modernity. Without the Bible, there is no America.
I am the rare Muslim who wishes that there was more, rather than less, Christianity in America. But it’s unclear what exactly can be done about this, short of an act of God. The simple fact is that Christian belief and observance has dropped precipitously over the past two decades. So what does it mean for America to reconstitute itself as a Christian nation if a growing number of Americans themselves seem uninterested or opposed to the prospect?
Insofar as nationalism is about protecting distinctly national traditions and mythologies, self-respecting nationalists of any faith will understandably seek to elevate Christianity’s role in public life. But if Christianity is what made America great, then surely liberalism, classically understood, was an important part of the story too.
To say that the Bible introduced the idea of the individual is an argument for the Christian origins of the liberal faith, or what Hazony might call “old liberalism.” It is difficult, and perhaps even impossible, to separate the seemingly secular idea of individual rights from the Christian notion of man being created in God’s image, endowed with self-evident, inalienable rights by his creator. In his book Dominion, the British historian Tom Holland writes that “to live in a Western country is to live in a society still utterly saturated by Christian concepts and assumptions.” The revolution Hawley is describing and seems to long for already happened. It is, as he himself suggests, the intellectual revolution that gave birth to modern liberalism—the same liberalism that national conservatives are now lamenting with increasing vehemence.
This vehemence is not, as some critics allege, merely a new ruse for blocking wealth redistribution through tax cuts and deregulation. In actual policy, if not necessarily in rhetoric, the Republican Party has lurched leftward on economic issues. This has led to a modest if somewhat remarkable upsurge in bipartisan cooperation on major spending bills. As the writer James Sutton recently argued, Congress is more functional today than it has been at any point in at least a decade.
Like most things in American politics today, the deeper—and perhaps irresolvable—divides are about culture, meaning, and the nature of the human person. The national conservatives view today’s liberals as woke cultural warriors who pose an existential threat to the nation and its traditions. In this sense, the new right is more concerned with who we are—and who we aren’t—than what Congress does or doesn’t do. This is not an army of would-be policy wonks.
Coherence or specificity are probably too much to ask for, especially at such an early stage in the development of a conservative countercultural movement. And, for now, it’s just that: a movement. And movements can survive and even flourish as long as they have an enemy against which to define themselves. The national conservatives at least have that, and it’s probably enough to sustain them—for now. Opposition is the first step, but it certainly isn’t the last.
"
The Allies Who Are Happy to Humiliate America,7-21-2022,"President Joe Biden’s much-touted trip to the Middle East—his first as president—was almost entirely devoid of drama or excitement. It produced no significant deliverables, nor was it meant to. To be underwhelmed, however, is to miss a more troubling story. The visit may have been pointless and performative, but it was also a major setback for American interests, confirming what many long suspected: Supposed allies can disrespect, embarrass, and undermine the United States at will.
The costs are already evident. On Saturday, less than 24 hours after Biden left the region, the United Arab Emirates sentenced an American citizen, Asim Ghafoor, to three years in prison on nebulous charges. Ghafoor, a lawyer for the slain Washington Post columnist Jamal Khashoggi, was detained only two days prior while transiting through Dubai International Airport.
This is the sort of thing that happens under dictatorships. But it is not the sort of thing that happens under dictatorships that are ostensibly close U.S. partners. In effect, the leaders of the UAE either are taunting Biden or are indifferent to the perception that they are taunting him. Neither of these possibilities is encouraging. Such provocations illustrate a long and enduring story in the Middle East, one in which the United States again and again proves unable to respond with any sense of purpose or self-respect. Autocrats test the limits to see how far they can go, only to find that such a limit doesn’t exist.
Ben Rhodes: Why no one believes American rhetoric about democracy
Saudi Arabia offers an even starker example. Years ago, when Middle East hands would joke that the kingdom could get away with murder, it was merely a figure of speech. But then the Saudis really did get away with it. Perhaps the sole memorable moment from Biden’s trip was his fist bump with the Saudi crown prince and de facto leader, Mohammed bin Salman. MBS needed only four years to rehabilitate himself after the grisly murder of Khashoggi, in which he was directly implicated.
But the meeting wasn’t merely a rehabilitation. In the misplaced hope of easing gasoline costs at home, the American president felt he needed to go to MBS to ask him to boost oil production. This wasn’t quite groveling—the proud and stubborn Biden was unlikely to reduce himself to that—but it was a clear demonstration of an administration ever weaker and more adrift.
One cannot overstate just what an odd and unwarranted reversal of the balance of power this was. The United States is a superpower—and, for now at least, the superpower. Saudi Arabia and the UAE are, to use an impolitic term, client states. In other words, they depend on American power for their security and survival. Their armies would be grounded in short order if the United States were to suspend all military provisions, including spare parts and maintenance for equipment as well as training and logistical support. At the risk of stating the blindingly obvious, they need us more than we need them. Yet if an extraterrestrial descended from outer space and witnessed last week’s events without the benefit of prior knowledge, they might have assumed the opposite—that the United States was the junior partner paying tribute to its superpower patrons.
The president’s very public deference to a brutal but weak regime is not just a problem for American strategy; it is a problem for American identity. On the world stage, is this what we’re intent on becoming?
Of course, former President Donald Trump was enamored of the Saudis and acted accordingly. Today, the same coddling of autocrats is happening under a Democratic administration, despite Biden’s insistence that his predecessor’s approach would be a thing of the past. In a sense, Biden has left us with the worst of both worlds, an untenable middle position that rarely works in the Middle East. The United States still has a pro-autocrat policy, only the autocrats in question don’t like us and don’t even pretend to respect us. Upon arriving in Saudi Arabia, Biden received a cold welcome from his hosts. Barack Obama found himself similarly snubbed during a 2016 visit. Obama was responsible for a historic increase in arms sales to Saudi Arabia, but his goodwill was neither appreciated nor reciprocated. This is not an accident. In fact, what analysts have called “reverse leverage” is perhaps the defining feature of America’s relationship with Arab autocrats. The United States rarely puts conditions on military support to the Gulf. Gulf states, in turn, take the assistance for granted, viewing it as an entitlement.
Andrew Exum: Biden is right about Saudi Arabia
The result is intensifying repression, including the harassment and detention of U.S. citizens. But American officials may not be sufficiently moved by moral objections. After all, the United States is a country, not a human-rights organization. In this imperfect, tragic world, America has to deal with dictators. Such an argument might hold up if Saudi Arabia and the UAE were reliable American allies. They are not. Emboldened and unaccountable, they are behaving recklessly, including in the realm of foreign policy. The ever-expanding list of examples includes attempting to cozy up to China, plotting a more conciliatory approach toward Russia, kidnapping the Lebanese prime minister, fueling the long-running war in Yemen, and supporting the side opposite the U.S. in Libya’s proxy battles.
The hardheaded pragmatist may insist that such adventurism must be stomached, a necessary evil on the path to “stability.” But what is happening now is not that. It is worse. America is being manipulated by the very countries that depend on it for their security. Somehow, the United States has managed the unlikely feat of undermining both its values and its interests. As it turns out, in the Middle East, the two cannot be separated."
The Liberals Who Won’t Acknowledge the Crime Problem,6-21-2022,"On a recent June weekend, 10 people were killed in shootings across cities in Pennsylvania, Michigan, Tennessee, and South Carolina. In Philadelphia, multiple active shooters fired into a crowd in the popular nighttime destination of South Street. “It was chaos,” one witness told The Philadelphia Inquirer. “People were coming off the street with blood splatters on white sneakers and skinned knees and skinned elbows.”
Coming so soon after the horrific Uvalde school shooting, these other killings were perhaps unlikely to garner much national attention. These stories were primarily of concern to the people living in the cities in question. But perhaps more importantly, this was “just” crime—no political motives, no obvious political solution, no broader lesson to be learned, with no wisdom to be gained.
Crime is rising nationally, but it is still experienced locally. In an October 2021 Gallup survey, the number of Americans who believe that crime is up in their local area is the highest it’s been in 25 years. Other polls underscore crime and personal safety as a top concern among registered voters. In Washington, D.C., where I live, many of my own friends and acquaintances can relay a recent experience with petty crime—and the sense of fatalism that comes from realizing that authorities and institutions probably won’t do much, for whatever reason.
Derek Thompson: Why America’s great crime decline is over
Washington, like many big American cities, had been enjoying a couple of decades in which rates of homicide and other violent offenses dropped steeply and then stayed low. Crime obviously still happened, but at least it wasn’t getting worse. Human beings tend to experience change in relative rather than absolute terms. They can make comparisons accordingly, assessing the way things are versus the way they were recently. And right now, the comparisons aren’t flattering. Yet in certain circles on the left, an orthodoxy has taken hold: To complain about ostensibly minor crime and other urban disorder, when so many people endure much worse, is to flaunt your privilege—which some readers may say I am doing right now. But off of Twitter, many left-leaning urbanites will acknowledge that, say, being assaulted by a stranger on the street is actually bad. Despite their efforts to resist the temptations of wrongthink, otherwise liberal Americans are being redpilled.
Anecdata, of course, are not the same as data. And in cities such as Philadelphia and San Francisco, progressive district attorneys have insisted that their critics have gotten the facts wrong. As The New York Times recently reported, the now-recalled San Francisco District Attorney Chesa Boudin routinely “confront[ed] voters with data that shows overall crime has not increased meaningfully while he has been in office.” Larry Krasner, Philadelphia’s cantankerous district attorney, has developed a habit of browbeating critics in town-hall meetings with appeals to “the science.” His in-house criminologist, Krasner has insisted, can give people the real numbers if they really want them. Ordinary residents are being told that what they perceive to be true is not, in fact, true. The problem here is that humans understand and interact with the world based on perception and feeling. Politics is about policy, but it is also about human nature—which, however one wishes to characterize it, is a constant to contend with. You can try to transcend human nature by appealing to people’s better angels or through education and enlightenment—but only up to a point. Information and education don’t necessarily serve the purpose liberals assume they will. Very few of us will read a detailed academic journal article about trends in crime reporting before deciding how to feel about crime. Your assessment also depends on which facts you pay attention to. Any self-respecting political scientist will be aware of how the data can be manipulated to confirm one’s prior beliefs. A criminologist—considering how politicized debates over crime are—is likely to have ideological biases that inform his or her research. Are you looking at “overall crime” or certain subcategories—and who’s to say which subcategories matter more than others? The notion of neutrality may be comforting, but no one, in the end, is a disinterested observer.
Jeff Asher: The FBI’s next set of crime data is going to be a mess
In writing this article, I read through various sources to get a better handle on the available crime statistics. The Times at least provides verifiable numbers, even if you have to sift through some editorializing to get there. The aforementioned Times article on Boudin’s tenure as San Francisco’s chief prosecutor states that “there is no compelling evidence that Mr. Boudin’s policies have made crime significantly worse in San Francisco. Overall crime in San Francisco has changed little since Mr. Boudin took office in early 2020.” Yet, just a few paragraphs later, the same article says that “burglaries, especially in wealthier neighborhoods, have soared during the pandemic. The city recorded 7,575 burglaries in 2020 and 7,217 last year, a sharp increase of more than 45 percent from 2019.”
If an increase of more than 45 percent in burglaries does not qualify as significant, then what would be? (When I requested comment, a Times spokesperson, Charlie Stadtlander, defended the article, noting San Francisco police data showing declines in several categories of crime since Boudin took office. “While burglaries increased sharply,” Stadtlander wrote in an email, “the pandemic and other broad societal factors seem to have influenced the patterns of property crime, rather than any causal link to policies within the purview of a district attorney.”)
The very nature of truth and reality has come under similar scrutiny in Philadelphia. In late 2021, Krasner declared, “We don’t have a crisis of lawlessness, we don’t have a crisis of crime, we don’t have a crisis of violence.” He added, “It’s important that we don’t let this become mushy and bleed into the notion that there is some kind of big spike in crime.” The debate, though, was a national one, consuming local politics in cities across the country. How should one assess crime? Were the numbers just the numbers? On the question of whether or not there was a crisis, The Guardian dutifully published a fact-check last summer. “‘Crime’ is not surging,” the reporters wrote, referring to national-level rates. “Even the broader category of ‘violent crime’ only increased about 3 percent last year … It’s homicide in particular that has increased, even as other crimes fell’” (emphasis mine). The article shifted back and forth between noting large homicide spikes in cities such as New York and St. Louis and describing a less dramatic, but still worrisome, national trend.
Conor Friedersdorf: Justice reformers need to update their priors
The motivated reasoning here, ostensibly in the form of an objective fact-check, reveals a larger instinct to minimize the problem. America is a big country. Were Philadelphians supposed to be reassured that it wasn’t all that bad, on average, everywhere else? In the same article, the Guardian writers did acknowledge that in 2020 Philadelphia “returned close to [its] historic highs for the number of people killed in a single year.” (It surpassed that high the following year.) Yet the article seemed to suggest that alarming figures shouldn’t worry us too much—after all, “even after an estimated 25% single-year increase in homicides, Americans overall are much less likely to be killed today than they were in the 1990s.”
That people are being killed but at lower rates than their parents’ generation was an intriguing message—and one that may not have been as reassuring as intended. (When I told a Guardian spokesperson as much, she responded, “This particular article is focused on crime statistics, not how residents perceive increases. At no point in the piece is it suggested that gun violence shouldn’t worry residents.” She also recommended that I listen to the experts: “If you’re interested in learning more about why journalists distinguish between overall crime and lethal violence, we recommend consulting some of the literature on this question by American criminologists.”)
I was and still am sympathetic to what Krasner is trying to do in Philadelphia, the city where I was born and a city I still care about and visit often. Philadelphia’s criminal-justice system is notorious, and for good reason. The city has one of the highest incarceration rates in a country that has one of the highest incarceration rates in the world (to say nothing of the moral stain of “mass supervision,” which is what happens after convicts are released but find that they’re not actually free). Such notoriety is due in no small part to the 19-year reign of District Attorney Lynne Abraham, whose enthusiasm for life sentences and capital punishment earned her the nickname the “Queen of Death.” But one can acknowledge this history without putting “crime” in scare quotes—as if voters should make do with the fact that overall crime is down but homicides are up. Presumably, homicides are worse, because it is more difficult to recover from death than from experiencing a break-in or witnessing creative acts of shoplifting at your local CVS.
Being forthright with the public when certain categories of crime are increasing is important, but debates over numbers obscure a more fundamental objection. The data miners, the journalists, and the otherwise well-intentioned people who believe—as one might believe in a religion—that all we need to come to the right conclusion is the right information seem unable to grasp that crime isn’t just crime.
Crime is also a proxy for a deeper malaise, that inchoate sense of almost-but-not-quite social collapse that’s in the air we breathe, impossible to measure with precision but unmistakably palpable all the same. The malaise draws on our own confusion, driven by the intuition that things aren’t as they should be. Burglaries and homicides are not the only signs that something is amiss. The tent encampments that have spread across our nation’s capital over the past two years suggest that something has gone very, very wrong. This is the most powerful city in the world, and yet people are living in makeshift tents in its richest neighborhoods, a stone’s throw from the White House and Capitol Hill.
But no one seems to know what to do about it. Or people do know what to do about it but can’t be bothered to act. Or they’ve found a way to resign themselves to a new reality—the so-called new normal. After all, the thinking goes, young professionals and middle-class urbanites should be grateful for what they have, that it at least isn’t worse, because it could always be worse. Who are they to complain anyway—especially if they are white, well-off, and gentrifiers to boot—about the decline of a city that isn’t really theirs or the fact that they might get assaulted after dinner at a nice restaurant?
To be a liberal is to take care to balance one’s individual need for basic security with a benefit of the doubt for the least fortunate and compassion for the victims of an uncaring society. The good liberal knows that poverty, substance abuse, and untreated mental illness fuel criminal activity. These are root causes. But the root causes haven’t been addressed, even by the very progressives who say that they should be. This, too, reflects a debate about moral claims and starting assumptions, and fact-checking can’t quite address those. Are the least fortunate necessarily morally superior simply by virtue of their victimhood? Is crime simply a matter of addressing grievances—or is it also true that there is bad and even evil in a fallen world and that it can’t always be resolved through social policy? Sometimes, particularly when it comes to actual criminals, crime must be punished.
It is easy to dismiss this line of argument as a right-wing trope. Because everything is a culture war, what hurts Democrats benefits Republicans. To acknowledge crime in left-wing bastions is to concede something to conservatives, or so the thinking goes. But this isn’t quite right. After all, it is people of color—not the predominantly white liberals who often dismiss the prevalence of crime as a right-wing talking point—who are most affected by crime in American cities. There’s something odd about those same white liberals, along with the politicians and pundits who cater to their sensibilities, insisting that rising crime rates are a figment of our imagination.
That crime is real—and getting worse—is not a fantasy. The recall of Boudin succeeded in an overwhelmingly liberal city. The problem of crime is hurting and dividing liberals, because crime is not—or at least should not be—a matter of left or right, subsumed by the superficial polarization that is roiling American life.
People see what they see, and to deny the truth or legitimacy of what they see with their own lying eyes is patronizing at best. It is also dangerous. Things aren’t worse; they just seem worse makes for an odd battle cry, and I, for one, don’t find it particularly reassuring. The disorder on display in American cities isn’t the end of the world, but it doesn’t have to be the end of the world for people to care and worry.
"
Why the Russian People Go Along With Putin’s War,4-23-2022,"In the early days of the war on Ukraine, tens of thousands of Russians protested an invasion launched in their name. This was encouraging. Americans could content themselves with the possibility that Russian citizens might take matters into their own hands, challenging and weakening their president, Vladimir Putin. In recent weeks, however, such protests have become rare. This is in no small part due to the criminalization of opposition; publicly contesting the Kremlin’s war propaganda carries prison terms of up to 15 years. But fear is only a piece of the story. Russians also appear to be rallying behind their president, raising the question of whether ordinary citizens are partly to blame for their regime—and perhaps even morally culpable.
If Putin’s regime and the Russian people are more intertwined than they initially appeared, a presumption of innocence becomes harder to sustain. According to the Levada Center, the closest thing to an independent pollster in Russia, Putin’s favorability ratings jumped from 69 percent in January to 83 percent in late March, a month into the so-called special military operation. Perhaps more ominously, Russians appear to be informing on one another in growing numbers, condemning friends, neighbors, and colleagues for insufficient support of the war effort. One hard-line member of Parliament noted that a “cleansing” was inevitable. In a speech, Putin himself colorfully praised his fellow Russians’ ability to “distinguish true patriots from scum and traitors and simply spit them out like a fly that accidentally flew into their mouths.”
Carl Miller: Who’s behind #IStandWithPutin?
To be sure, an 83 percent approval rating almost certainly overstates Putin’s support. Individuals may understandably hide their true preferences from pollsters, as a culture of paranoia spreads across the country. In tandem with reports of erstwhile Putin opponents embracing the war, however, we can fairly assume that a large number of Russians, and perhaps a clear majority, are indifferent to the atrocities committed in their name. What, if anything, should we make of this?
Anti-war protest in Moscow, Russia.
Daniil Danchenko / NurPhoto / Getty
Of course, the question of evil—and why ordinary people incline toward it—is an old one, destined to repeat itself with stubborn insistence. As my podcast co-host, Damir Marusic, an Atlantic Council senior fellow, recently wrote, “Putin is a wholly authentic Russian phenomenon, and the imperialist policy he’s pursuing in Ukraine is too.” This is right, but only up to a point. We simply don’t know what individual Russians would choose, want—or become—if they had been socialized in a free, open democracy, rather than a dictatorship where fear is the air one breathes. Like everyone else, they are products of their environment. Authoritarianism corrupts society. Because punishment and reward are made into arbitrary instruments of the state, citizens have little incentive to pool resources, cooperate, or trust others. Survival is paramount, and survival requires putting one’s own interests above everything else, including traditional morality. In such a context, as the historian Timothy Snyder puts it, “life is nasty, brutish, and short; the pleasure of life is that it can be made nastier, more brutish, and shorter for others.” This is the zero-sum mindset that transforms cruelty into virtue.
In short, authoritarianism twists the soul and distorts natural moral intuitions. In so doing, it renders its citizens—or, more precisely, its subjects—less morally culpable. To be fully morally culpable is to be free to choose between right and wrong. But that choice becomes much more difficult under conditions of dictatorship. Not everyone can be courageous and sacrifice life and livelihood to do the right thing.
The invasion of Ukraine was very much Putin’s creation, his idiosyncratic bid to reimagine Russia. It is unlikely that something similar would have happened in his absence. While Russians have now hardened against their Ukrainian neighbors, early reactions to the war tended more toward surprise and even shock. Putin, after all, had repeatedly denied that he was planning to invade. This is why many of the Russian troops deployed to Ukraine did not seem to initially grasp that they were entering a war zone. If a referendum on an invasion of Ukraine had been held months ago, there is little reason to think that Russians would have been particularly enthusiastic. Putin’s war enjoys considerable popular support now, but that’s because it is too late to imagine an alternative. The war is a fait accompli. If Russians wish to continue living in their country and not get on the wrong side of things, acclimating themselves to this new reality is the best option, if not necessarily a moral or brave one.
Shadi Hamid: There are many things worse than American power
Russians may be unique, just like all peoples are, but this does not mean that they are uniquely bad. Or, to put it differently, being good is hard if you live under an authoritarian regime. As the war rages on and anti-Russian sentiment grows, the temptation to see the Russian people as perpetrators rather than victims also grows. But to view them this way obscures something more fundamental: They too are victims, because they have been gradually stripped of their status as free moral agents. This is by design. Authoritarian leaders aim to implicate their own people in their crimes, which in turn allows them to both spread and dilute political responsibility. If responsibility is spread across the population, then so is guilt. To repudiate Putin would mean repudiating themselves.
This is yet another reminder of the elemental distinction between autocracies and democracies that President Joe Biden has highlighted in a series of speeches and other public statements. Americans have no trouble seeing Russia and China primarily as national-security threats and challengers to the United States, in part because they are. But there is a deeper divide—one that cuts to the very core of what it means to be a citizen and even a human being. Dictatorships elevate the nation and the leader as ultimate ends, while mere individuals have no inherent worth outside of their service to the state.
Driven by an inherent logic of force and brutality, authoritarian regimes—particularly those with delusions of imperial grandeur—commit atrocities with indifference and even abandon. And they bring their populations along with them, willingly or unwillingly. This is what makes them doubly dangerous. It is also why the struggle ahead of the United States—and all democratic nations, whether they realize it or not—is likely to be a long one. As systems of government and ways of organizing society, democracies and dictatorships are irreconcilable. In a better world, coexistence might have been possible. But that is no longer the world we live in."
There Are Many Things Worse Than American Power,3-6-2022,"If there was any doubt before, the answer is now clear. Vladimir Putin is showing that a world without American power—or, for that matter, Western power—is not a better world.
For the generation of Americans who came of age in the shadow of the September 11 attacks, the world America had made came with a question mark. Their formative experiences were the ones in which American power had been used for ill, in Iraq and Afghanistan. In the Middle East more broadly, and for much longer, the United States had built a security architecture around some of the world’s most repressive regimes. For those on the left, this was nothing new, and it was all too obvious. I spent my college years reading Noam Chomsky and other leftist critics of U.S. foreign policy, and they weren’t entirely wrong. On balance, the U.S. may have been a force for good, but in particular regions and at particular times, it had been anything but.
Blaming America first became all too easy. After September 11, U.S. power was as overwhelming as it was uncontested. That it was squandered on two endless wars made it convenient to focus on America’s sins, while underplaying Russia’s and China’s growing ambitions.
Derek Thompson: How the crisis in Ukraine may end
For his part, Putin understood well that the balance of power was shifting. Knowing what he knew, the Russian president wasn’t necessarily “irrational” in deciding to invade Ukraine. He had good reason to think that he could get away with it. After all, he had gotten away with quite a lot for nearly 15 years, ever since the Russian war against Georgia in 2008, when George W. Bush was still president. Then he annexed Crimea in 2014 and intervened brutally in Syria in 2015. Each time, in an understandable desire to avoid an escalatory spiral with Russia, the United States held back and tried not to do anything that might provoke Putin. Meanwhile, Europe became more and more dependent on Russian energy; Germany, for example, was importing 55 percent of its natural gas from Russia. Just three weeks ago, it was possible for Der Spiegel to declare that most Germans thought “peace with Russia is the only thing that matters.”
The narrative of a feckless and divided West solidified for years. We, as Americans, were feeling unsure of ourselves, so it was only reasonable that Putin would feel it too. In such a context, and after four years of Donald Trump and the domestic turmoil that he wrought, it was tempting to valorize “restraint” and limited engagements abroad. Worried about imperial overreach, most of the American left opposed direct U.S. military action against Bashar al-Assad’s regime in the early 2010s, even though it was Russian and Iranian intervention on behalf of Syria’s dictator that bore the marks of a real imperial enterprise, not just an imagined one.
Russia’s unprovoked attack on a sovereign nation, in Europe no less, has put matters back in their proper framing. The question of whether the United States is a uniquely malevolent force in global politics has been resolved. In the span of a few days, skeptics of American power have gotten a taste of what a world where America grows weak and Russia grows strong looks like. Of course, there are still holdouts who insist on seeing the United States as the provocateur. In its only public statement on Ukraine, the Democratic Socialists of America condemned Russia’s invasion but also called for “the U.S. to withdraw from NATO and to end the imperialist expansionism that set the stage for this conflict.” This is an odd statement considering that Russia, rather than the United States, has been the world’s most unabashedly imperialist force for the past three decades. But many on the anti-imperialist left aren’t really anti-imperialist; they just have an instinctive aversion to American power.America’s low opinion of its own capacity for good—and the resulting desire to retreat or disengage—hasn’t just been a preoccupation of the far left. The crisis of confidence has been pervasive, spreading to the halls of power and even President Barack Obama, whose memorable mantra was “Don’t do stupid shit.” Instead of thinking about what we could do, or what we could do better, Obama was more interested in a self-limiting principle. For their part, European powers—content to bask under their U.S. security umbrella—could afford to believe in fantasies of perpetual peace. Europe’s gentleness and lethargy—coaxing Germany to commit even 2 percent of its GDP to defense seemed impossible—became something of a joke. One popular Twitter account, @ISEUConcerned, devoted itself to mocking the European Union’s propensity to express “concern,” but do little else, whenever something bad happened.
Read: Bury the old world order
Suddenly, the EU has been aroused from its slumber, and the parody account was rendered temporarily speechless. This is no longer tepid concern, but righteous fury. Member states announced that they would send anti-tank weapons to Ukraine. Germany, for the first time, said that it would ramp up its military budget to 100 billion euros. On the economic front, the EU announced some of the toughest sanctions in history. My podcast co-host, Damir Marusic, an Atlantic Council senior fellow, likened it to a “holy war,” European-style.
Sometimes, unusual and extreme events mark the separation between old and new ways of thinking and being. This week, the Berlin-based journalist Elizabeth Zerofsky remarked that the current moment reminded her of the memoir The World of Yesterday, written by the Austrian novelist Stefan Zweig as World War II loomed. In it, he recalls the twilight of the Austro-Hungarian Empire with an almost naive fondness. On the first day of the Ukraine invasion, I happened to be speaking to a group of college students who had no memory of September 11. I told them that they may be living in history. Those students, like all of us, are bearing witness to one of those rare events that recast how individuals and nations alike view the world they inhabit.
The coming weeks, months, and years are likely to be as fascinating as they are terrifying. In a sense, we knew that a great confrontation was coming, even if we hadn’t quite envisioned its precise contours. At the start of his presidency, Joe Biden declared that the battle between democracies and autocracies would be the defining struggle of our time. This was grandiose rhetoric, but was it more than that? What does it actually mean to fight such a battle?
In any number of ways, Russia’s aggression has underscored why Biden was right and why authoritarians—and the authoritarian idea itself—are such a threat to peace and stability. Russia invaded Ukraine, a democracy, because of the recklessness and domination of one man, Vladimir Putin. The countries that have rallied most enthusiastically behind Ukraine have almost uniformly been democracies, chief among them the United States. America is lousy, disappointing, and maddeningly hypocritical in its conduct abroad, but the notion of any moral equivalence between the United States and Putin’s Russia has been rendered laughable. And if there is such a thing as a better world, then anti-imperialists may find themselves in the odd position of hoping and praying for the health and longevity of not just the West but of Western power.
"
Race-Based Rationing Is Real—And Dangerous,1-30-2022,"The stock market has plummeted, erasing hundreds of billions of dollars in household wealth in the span of weeks. War in Ukraine is a distinct possibility and not merely a worst-case scenario. Stakes as high as this tend to concentrate the mind. As a result, the ongoing and seemingly endless debates about “wokeness”—for want of a better term for the way a powerful sliver of the left discusses race and identity—seem odd and even unimportant.
Every day, social media blows up over some new excess of language policing, the latest unintended offense against elite manners, or the most recent eruption of cancel culture on campuses. I, too, take part in these discussions. For several months now, though, I have made a conscious effort to limit my tweeting, writing, and speaking about these cultural battles. To treat them as the overarching crisis of the moment can distort one’s sense of reality. For most ordinary Americans—at least the ones who don’t have kids in school—these concerns are not in the forefront. Social and political elites, however, are a different matter. Because they are highly educated, disproportionately online, and liberated from day-to-day fears of financial catastrophe, they tend to be more ideological and more committed to abstract, utopian objectives. Because I am part of this group—and therefore part of the problem—I have a duty to try to resist the undeniable pleasures of perpetual outrage over ultimately ridiculous things such as using Latinx instead of Latino.
Graeme Wood: What’s behind the COVID-19 racial disparity?
And yet the influence of the cultural left’s worldview goes beyond mere terminology. During the coronavirus pandemic, the instinct to bring crude generalizations about race to the center of every discussion is seeping into public policies about quite consequential matters. What happens, for instance, when in the name of racial equity, membership in a particular ethnic group can make the difference between getting and not getting potentially lifesaving medical care? This might sound like a far-fetched hypothetical. Except that it’s not.
In a series of articles this month, The Washington Free Beacon’s Aaron Sibarium reported that hospitals in Minnesota, Utah, New York, Illinois, Missouri, and Wisconsin have been using race as a factor in which COVID-19 patients receive scarce monoclonal-antibody treatments first. Last year, SSM Health, a network of 23 hospitals, began using a points system to ration access to Regeneron. The drug would be given to patients only if they netted 20 points or higher. Being “non-White or Hispanic” counted for seven points, while obesity got you only one point—even though, according to the CDC, “obesity may triple the risk of hospitalization due to a COVID-19 infection.” Based on this scoring system, a 40-year-old Hispanic male in perfect health would receive priority over an obese, diabetic 40-year-old white woman with asthma and hypertension.
Meanwhile, Minnesota’s Department of Health used a scoring calculator that counted “BIPOC status” as equivalent to being 65 years and older in its risk assessment. (BIPOC is shorthand for Black, Indigenous, and people of color.) New York did away with a points system entirely; people of color are automatically deemed to be at elevated risk of harm from COVID—and therefore are given higher priority for therapeutics—irrespective of their underlying health conditions. Sibarium’s reporting in the Free Beacon spread to various right-wing media outlets, prompting significant pushback. Under threat of legal action, SSM Health announced on January 14 that it “no longer” uses race criteria. On January 11, Minnesota’s public-health authorities edited out the BIPOC reference, leaving no trace of the previous wording. New York State, however, has not yet altered its guidelines.
The racial disparities in COVID outcomes are a matter of record, but to suggest that race causes these negative outcomes is a classic case of mistaking correlation for causation. This is how facts, despite being true, are misused and weaponized. Rather than race itself, variables that are correlated with race—such as socioeconomic status, health-care access, geography, and higher rates of obesity or diabetes—are what affect a patient’s health. Those who presumably know better, such as the Food and Drug Administration, have contributed to the confusion by highlighting that race—on its own—may place individuals at greater COVID-related risk.
To emphasize race or ethnicity as a determining factor for risk assessment also raises the question of which race. Presumably, not all people of color are the same. Should all nonwhite people—Hispanic, Black, Arab, South Asian, East Asian, Indigenous—be lumped in together as part of some undifferentiated whole? To put a finer point on it, I am nonwhite. Should I be given priority for COVID treatments over a white person who is obese, asthmatic, and diabetic? That I happen to be nonwhite—an accident of birth—defines me in opposition to whiteness, but it says practically nothing about whether I’m at higher risk of hospitalization due to COVID.
Advocates of sweeping policies to promote equity tend to dismiss objections like mine as statistical blips—or, worse still, as a sign of hostility to historically oppressed groups. But the possibility that someone’s race could, quite literally, affect whether they qualify for lifesaving COVID treatment isn’t just another inconvenience. In theory as well as practice, it is a matter of life and death. Race triage in a hospital setting is a reminder that “symbolic” ideas, however abstract or fantastical, can extend their reach and impact well outside of the rarefied halls of elite universities.
From the July 2020 issue: In a pandemic, all people see is your color
The battles waged over culture and identity are felt deeply and intensely precisely because they are rather abstract. On matters of pure principle, splitting the difference is impossible—which is why so many of us can’t help but obsess over these disputes. But they don’t stay abstract. As in the case of race-conscious drug rationing, the tangible effects of the merely symbolic come later, when few are paying attention.
The rationing rules in New York and elsewhere are not the product of anything resembling conventional political persuasion. No party would support—certainly not openly—the essentialization and instrumentalization of race in medicine. Few are willing to defend policies such as these on the merits, because what exactly would they say? Tellingly, these controversies have received limited coverage from mainstream outlets. Recently, the Associated Press published an article portraying claims of race triage as right-wing propaganda. “Medical experts say the opposition is misleading,” the story declared. (I requested comment from the AP about its coverage. A spokesperson responded, “AP does not do editorial commentary, nor does it have an opinion agenda. It is an independent, nonpartisan, fact-based news organization.”)
Asserting that reality is not real simply because it is a Republican talking point is gaslighting. Ideas, even good ones, become destructive when they demand that people prioritize advocacy over truth. Central to what I and others call woke ideology are the notions that racial identity is all-encompassing and the primary mover of politics; that systemic prejudice alone accounts for disparities across ethnic groups; and that any steps taken to correct those outcomes are presumptively justifiable and cannot be questioned in good faith.
Democrats and liberals now find themselves under considerable pressure to acquiesce to this way of looking at the world. Going against the norm is simply too costly if you want to remain a member of the tribe in good standing. There is no end to this way of thinking, unfortunately, and we are all susceptible to it. In a zero-sum political struggle, anything that could conceivably undermine morale on your side is perceived as helping the other side. And the other side, the argument goes, is an existential threat.
In theory, woke ideology shouldn’t matter that much, but it will matter in practice, including in ways unanticipated just a few years ago. What public-health officials and hospital administrators have done with race criteria, likely with the best intentions, is only the most striking example of how seemingly symbolic positions become tangible. As I write this, standardized testing and entrance exams are being rolled back because of the intriguing notion that doing well on tests is a form of white privilege. Crime rates are rising across the country, yet prominent Democrats either dismiss the problem as “hysteria” or avoid talking about it altogether. Addressing crime and protecting those at risk require police, which in turn require funding and resources that progressive elites—but not actual Democratic voters—propose to divert away from law enforcement.
Juan Williams: Eric Adams is making white liberals squirm
Somehow, progressives have fallen under the sway of a set of ideas so off-putting that they threaten progressivism itself. Those of us who are not white are not just “nonwhite.” We are not interchangeable. We are not always and forever victims. We are individuals, first and foremost, not merely members of a group to be patronized by other people’s good intentions.
At times, I worry about letting my own dislike of wokeness—few things feel more anathema to my understanding of what makes us who we are—distort my otherwise progressive commitments on substantive policy issues such as reducing mass incarceration, reforming the criminal-justice system, and boosting immigration to counter depopulation. And yet the reason to speak out against the emerging conformity on the left is that its ideas, if enough people look away, lead to destructive policies that cost lives and livelihoods. Because outrage is so tempting, those of us who oppose bad ideas should probably reserve our frustration and anger for when it matters most. One of those times is now.
"
The Forever Culture War,1-8-2022,"The future of American politics is taking shape, and it is frightening. I, along with many others, thought—or at least hoped—that Joe Biden’s tenure in the White House would allow enough Americans to unspool themselves from the daily efforts of outrage and apocalyptic thinking. Biden was bland enough that politics could revert to something more measured than it had been under his predecessor, Donald Trump. This was wishful thinking.
Politics seems more existential, not less. Pundits and partisans cast everything as a culture war, even those things that have little to do with culture. Policy debates that might have otherwise been boring—over COVID-testing protocols or the cost of the Build Back Better bill, for example—have become part of an apocalyptic battle between the forces of good and evil. As the conservative writer Jack Butler characterized the growing unease: “We’re in the battle at the end of time, and the prince of darkness is already at the door, and the whole world is now a contest between activist left and activist right.”
In retrospect, it was a mistake to think that the sheer intensity of recent political debate was unusual or temporary, when it is likely to be neither. After a couple of relatively tame and boring decades, the shift made itself apparent during the Trump years. In 2012, 45 percent of Americans cited the economy as the “most important problem” facing the country. By 2017, that number had dropped to around 10 percent. The United States was far from exceptional, however. In 2018, immigration had become the top concern for voters in seven European countries, with terrorism following closely behind. The economy has since become a primary concern again, partly because of the pandemic. Yet economic debates themselves have become less polarized. There is broad agreement and even consensus across the ideological spectrum. In much of Europe, right-wing populist parties have taken a sharp left turn, positioning themselves as the true defenders of the welfare state and the working class.
The American right has lagged behind. Traditions of frontier libertarianism and trickle-down economics make old habits hard to shake. But this, too, is changing, helped along by Republicans’ growing indifference to deficit spending. Trump’s embrace of far-right nationalist tropes has obscured the Republican Party’s lurch leftward on economic issues—a shift that the writer Matthew Yglesias calls “unhinged moderation.” This impulse of right-wing identity politics and economic populism is inspiring a younger generation of conservatives on the “new right,” profiled recently by Sam Adler-Bell in The New Republic and David Brooks in The Atlantic.
David Brooks: The terrifying future of the American right
Trump was radical in style and, occasionally, on policy—at least by conservative standards. He abandoned earlier Republican efforts to privatize Social Security and cut Medicare. His scrambling of traditional left-right politics gave license to young conservatives to embrace economic populism, which isn’t very conservative. The influential journal American Affairs—initially launched as a quasi-Trumpist intellectual organ—welcomes contributors from the other side and features more socialist ideas than unabashedly capitalist ones (I wrote an essay for the journal on formulating a new left-wing populism). Various right-wing intellectuals have long fantasized about an electoral holy grail of economic populism and social conservatism. In Britain, they were known as “red Tories,” but such grand projects of realignment tended to fizzle out. They were compelling in theory but not necessarily in practice—perhaps until now. As the conservative writer and podcaster Saagar Enjeti argued in 2020: “The whole reason that the GOP has been able to even compete for so long is that despite their horrible economics, they do hold the cultural positions of so much of the American people. But they keep thinking they’re winning because of their economic policy and losing because of their cultural policy, when really it’s the opposite.”
As Democrats hemorrhage working-class support—not only among white people but also among communities of color whom the party was counting on—the new right sees an opportunity. Glenn Youngkin’s victory in the Virginia gubernatorial elections was an early test case. Youngkin, a Republican, was happy to pledge increased spending on education, for example. Few in his party seemed to mind. What mattered was culture, which is precisely what the otherwise mild-mannered former executive zeroed in on in the campaign’s final weeks. Education was the dividing line, but these weren’t your old Bush-era debates about charter schools, class size, teacher training, test scores, and budgets. Republicans may have weaponized the threat of “critical race theory,” but school closures and remote learning undoubtedly forced parents to pay closer attention to what their kids were actually learning—or not learning. The divide wasn’t about whether kids were solving their math problems; it was about values, history, and culture—the fear that the state, through its schools, was discarding the pretense of neutrality and instead promoting contested ideological propositions.
Whether this growing sense of cultural overreach by the left ultimately pushes Republicans to Ronald Reagan–style electoral victories is an interesting question. An even more interesting question is what this shift—if it becomes permanent—means for the future of American politics. And what it means is discouraging at best.
In effect, because of the GOP’s dash to the center on spending as well as on industrial and trade policy, economics has been neutralized as the country’s primary partisan cleavage. To the extent that a left-right divide is still meaningful, it matters much more on race, identity, and the nature of progress than it does on business regulation, markets, and income redistribution. Because the former are fundamentally about divergent conceptions of the good, they are less amenable to compromise, expertise, and technocratic fixes. These are questions about “who we are” rather than “what works.”
Elites in both parties enjoy a certain privilege—one appropriate to a rich, advanced democracy—that allows them to emphasize culture while deprioritizing economic well-being. Civilizational concerns gain more political resonance precisely as perceptions of civilizational decline intensify on right and left alike. But this particular kind of decadence—characterized, per The New York Times’ Ross Douthat, by reproductive sterility, economic stagnation, political sclerosis, and intellectual repetition—is an ideal foil for young conservatives cum reactionaries. It gives them something worthy of reaction. And, importantly, it doesn’t require being religious as much as it requires a recognition that religion is a vital societal good, regardless of whether it’s true.
Like Trump, the most secular president of the modern era, many of the new right’s most prominent figures are not particularly religious. Their (potential) constituency of young Republicans isn’t particularly religious either. The number of unaffiliated Republicans has tripled since 1990, much of that concentrated among the young and the relatively young.
Civilizational health, to use the term of the Claremont Institute’s Matthew Peterson, is what unites believers and nonbelievers alike. They appreciate religion’s role and utility in buttressing Western civilization, offering as it does transcendence as well as tradition. And, of course, elevating religion as the wellspring of morality is a pretty good way to own the libs, for those who place special value on that.
If this division around morality, the meaning of the American founding, and “civilization” solidifies, we should all be at least slightly worried. It would mean a multifaceted culture war for, perhaps, the rest of our lives. That’s putting it somewhat dramatically, but there is good reason to view some changes, rather than others, as extremely sticky, if not quite permanent.
Read: Democrats are losing the culture wars
There wasn’t always a left-right cleavage organized around class, redistribution, and the means of production. But it came to be, and it has persisted for a very long time. In their seminal 1967 study, Party Systems and Voter Alignments, Seymour Martin Lipset and Stein Rokkan argued that state formation, the industrial revolution, and urbanization allowed economic divides to supersede religious ones. That economic cleavages are (or were) paramount in most Western democracies, then, is no accident. Over time, the economic dimension of conflict in Western democracies became “frozen” in the form of parties that self-defined according to economic interests.
Parties play an important role too. They decide what issues to prioritize in order to distinguish themselves from the competition. As the political scientists Adam Przeworski and John Sprague note, “class is salient in any society, if, when, and only to the extent to which it is important to political parties which mobilize workers.” But neither Democrats nor Republicans are likely to become workers’ parties anytime soon. Conservatives’ rhetorical interest in the working class remains largely electoral and opportunistic. Meanwhile, the left is preoccupied with language policing, elite manners, and a kind of cultural progressivism far more popular among hypereducated white liberals than working-class Latino, Black, Asian, and Arab Americans.
Republicans and Democrats may simply converge around a diffuse and vague economic populism and call it a day. To distinguish themselves from each other in a two-party system, they will have to underscore what makes them different rather than what makes them similar. And what makes them different—unmistakably different—is culture. This isn’t just instrumental, though, a way to rally the base and mobilize turnout. If one listens to what politicians and intellectuals in these two warring tribes actually say, it seems clear enough: They believe that civilization is at stake, and who am I to not take them at their word? If the end of America as we know it is indeed looming, then the culture war is the one worth fighting—perhaps forever, if that’s what it takes.

"
Americans Never Understood Afghanistan Like the Taliban Did,8-23-2022,"The United States never understood Afghanistan. American planners thought they knew what the country needed, which was not quite the same as what its people wanted. American policy was guided by fantasies; chief among them was the idea that the Taliban could be eliminated and that an entire culture could be transformed in the process.
In an ideal world, the Taliban wouldn’t exist. But it does exist, and it will exist. Western observers always struggle to understand how groups as ruthless as the Taliban gain legitimacy and popular support. Surely Afghans remember the terror of Taliban rule in the 1990s, when women were whipped if they ventured outside without a burka and adulterers were stoned to death in soccer stadiums. How could those dark days be forgotten?
America saw the Taliban as plainly evil. To deem a group evil is to cast it outside of time and history. But this is a privileged view. Living in a democracy with basic security allows citizens to set their sights higher. They will be disappointed with even a relatively good government precisely because they expect more from it. In failed states and in the midst of civil war, however, the fundamental questions are ones of order and disorder, and how to have more of the former and less of the latter.
The Taliban knew this. After its fall from power in 2001, the group was weak, reeling from devastating air strikes targeting its leaders. But in recent years, it has been gaining ground and establishing deeper roots in local communities. The Taliban was brutal. At the same time, it often provided better governance than the distant and corrupt Afghan central government. Doing a little went a long way.
Afghanistan’s U.S.-backed government didn’t fail just because of the Taliban. It was hobbled from the start by America’s blind spots and biases. The United States saw a strong, centralized authority as the answer to Afghanistan’s problems and backed a constitution that invested the president with sweeping powers. That, along with a quirky and confusing electoral system, undermined the development of political parties and the Parliament. A strong state required formal legal institutions—and the United States dutifully supported courts, judges, and other such trappings. Meanwhile, it invited resentment by pushing programs that were meant to reengineer Afghan culture and gender norms.
All of these choices reflected the hubris of Western powers that saw Afghan traditions as an obstacle to be overcome when, it turns out, they were the lifeblood of the country’s political culture. In the end, few Afghans believed in a government that they never felt was theirs or wished to wade through its bureaucratic red tape. They kept turning to informal and community-driven dispute resolution, and local figures they trusted. And this left the door open for the slow return of the Taliban.
The Special Inspector General for Afghanistan Reconstruction oversaw how the U.S. disbursed reconstruction funds and assessed their effectiveness. Over the past year, two depressing SIGAR assessments were made available to the public.
One—grandiosely if obsoletely titled “What We Need to Learn: Lessons From Twenty Years of Afghanistan Reconstruction”—notes that the United States spent about $900 million helping Afghans develop a formal legal system. Unfortunately, Afghans do not seem to have been impressed.
One of the first things militant groups like the Taliban do when they enter new territory is provide “rough and ready” dispute resolution. Often, they outperform the local court system. As Vanda Felbab-Brown, Harold Trinkunas, and I noted in our 2017 book on rebel governance, “Afghans report a great degree of satisfaction with Taliban verdicts, unlike those from the official justice system, where petitioners for justice frequently have to pay considerable bribes.”
This is one major reason why religion—particularly Islam—matters. It provides an organizing framework for rough justice and a justification for its implementation, and is more likely to be perceived as legitimate by local communities. Secular groups and governments simply have a harder time providing this kind of justice. The Afghan government wasn’t necessarily secular, but it had received tens of billions of dollars from governments that certainly were. A Sharia-based, informal dispute system would almost certainly be frowned upon by those Western donors. How likely was it that an Afghan government headed by an Ivy League–educated technocrat could beat the Taliban at its own game?
As the SIGAR report noted archly, “The United States misjudged what would constitute an acceptable justice system from the perspective of many Afghans, which ultimately created an opportunity for the Taliban to exert influence.” Or, as a former USAID official put it, “We dismissed the traditional justice system because we thought it didn’t have any relevance for what we wanted to see in today’s Afghanistan.”
What, then, did the United States want to see in today’s Afghanistan?
When the Bush administration helped shape the post-Taliban Afghan government, it was still claiming that it had little interest in nation building. Pilfering from Afghanistan’s past constitutions was easier than proposing something more appropriate for what had become a very different country. The new constitution created a top-heavy system that gave the president “nearly the same powers that Afghan kings exercised,” as Jennifer Brick Murtazashvili, a prominent Afghanistan scholar, has written.
Strong presidential systems are appealing because they offer the prospect of determined action. But the concentration of power inevitably alienates other stakeholders, particularly on the local and regional levels.
From the beginning, the Afghan Parliament suffered from a legitimacy deficit. Afghanistan used an electoral system known as single nontransferable vote (SNTV), one of the rarest in the world. There are reasons SNTV is sometimes used in local elections but almost never nationally: Among other things, it allocates votes in a way that depresses the development of political parties. If there’s anything Afghanistan needed, it was political parties—and a parliament—that could check the dominance of the president.
The risks of a presidential system are heightened in divided societies, and Afghanistan is divided along ethnic, religious, tribal, linguistic, and ideological lines—in almost every way possible. This raises the stakes of political competition, because what matters most is who ends up at the very top.
Finally, the system works only if the president is competent. The now-exiled president, Ashraf Ghani, managed to be all-powerful in theory but resolutely feckless in practice. Despite having been the chair of the Institute for State Effectiveness, his ineffectiveness—reflected in his mercurial style and penchant for micromanagement—infected the entire political system, and little could be done to reverse the trend as long as he remained in office.
In addition to fashioning new political institutions, America believed that it could transform the culture of a country. Naturally, most American politicians, nongovernmental organizations, and donors thought that the things that worked in advanced democracies would work in fragile would-be democracies. Liberal values were universal. And because they were universal, they would be, if not embraced, at least appreciated.
Somewhere close to $1 billion was spent on promoting gender equality. But such a focus was too often tantamount to social and cultural engineering in a conservative country that was still struggling to establish basic security. USAID’s Gender Equality and Female Empowerment Policy stated as one of its rather ambitious goals “working with men and boys, women and girls to bring about changes in attitudes, behaviors, roles and responsibilities.” This is a worthy objective, but the American approach was heavy-handed and at times counterproductive.
As the second SIGAR report, titled “Support for Gender Equality: Lessons From the U.S. Experience in Afghanistan,” concluded, U.S. officials need “a more nuanced understanding of gender roles and relations in the Afghan cultural context” and of “how to support women and girls without provoking backlash that might endanger them or stall progress.”
These efforts were well-intentioned, but they drew on assumptions about the arc of progress, and the belief that the United States would make progress happen even if Afghans themselves were less sanguine.
If the United States had made other choices, would the outcome have been different? I don’t know. Americans believe in certain things. Suspending those beliefs in the name of understanding another society can easily devolve into moral and cultural relativism that many, if not most Americans, would reject. Would a Republican—or, for that matter, a liberal suspicious of religion’s role in public life—have felt comfortable supporting programs in Afghanistan that involved the implementation of a version of Sharia, even if that version wasn’t the Taliban’s?
But the order and sequence in a transition matter. It’s clear now that we got that sequence wrong in Afghanistan, especially considering that women’s rights had long been one of the country’s most divisive issues. As the experts Rina Amiri, Swanee Hunt, and Jennifer Sova warned in 2004, when the Taliban seemed a relic of the past, “While the situation has markedly improved since the Taliban regime, the stage is set for a struggle between traditionalists and modernists; and once again women’s roles and religion are central to the conflict.”
Was it America’s place to change a culture? Did anyone really expect that the U.S. government would be good at it? If there is any change that should come from within, presumably it’s cultural change. But if there’s anything that’s universal—transcending culture and religion—it is the desire to have a say in one’s own government. Instead of telling Afghans how to live, we could have given them the space to make their own decisions about who they wanted to be.
With the Parliament weak, in part because of that bizarre electoral system, all attention was diverted to presidential contests, which were invariably acrimonious. The result was a winner-takes-all system in a country where the winners had long subjugated the losers, or worse. It is little surprise, then, that “every Afghan presidential election has been brokered or mediated by U.S. diplomats,” as Jarrett Blanc, one of those diplomats, put it. This was the democracy that America and its allies tried, for years, to build.
Many of the political institutions that America helped create have now been washed away. It is almost as if they never existed. By insisting on the primacy of culture over politics, the United States thought it could improve both. Might Afghanistan have been doomed regardless? Perhaps. Now we will never know.
"
The Return of Hypocrisy,7-30-2021,"Governments, even democratic ones, are often ineffective or simply bad. Elections sometimes produce uninspiring results, particularly when a patchwork of parties forms an unwieldy coalition government that struggles to get much of anything done. This doesn’t mean it should be overthrown. Nor should the United States ignore coup attempts staged in the name of bypassing the messiness of democracy. Yet in Tunisia, this is what the Biden administration appears to be doing, revealing the widening gulf between American words and deeds.
On Sunday, Tunisian President Kais Saied, who is supposed to share power with Parliament and a prime minister, suspended the former and dismissed the latter. In case anyone doubted his intentions, Saied addressed the nation while flanked by top military and security officials. On Monday, the army surrounded Parliament and blocked legislators from entering the building. Most Americans probably don’t care that Tunisia is—or, perhaps more precisely, was—the lone success story of the Arab Spring. But the atmospherics of the story might resonate. A president longing to be a strongman is something that we in the United States recently experienced. As a long-standing democracy, America had institutions that rose to the challenge and restrained former President Donald Trump’s authoritarian instincts. Young, fragile democracies are rarely so lucky.
Read: The world is experiencing a new form of autocracy
From the very start of his presidency, Joe Biden identified the struggle between democratic and authoritarian governments as the central challenge of both the present and future. As he put it in his first press conference as president: “It is clear, absolutely clear … that this is a battle between the utility of democracies in the 21st century and autocracies.” This lofty rhetoric was somewhat surprising, especially for a man who had viewed the 2011 Arab uprisings with evident skepticism. In one memorable moment, just two weeks before the Egyptian strongman Hosni Mubarak fell amid mass protests, Biden said: “Look, Mubarak has been an ally … I would not refer to him as a dictator.”
Believing in the power and possibility of democracy is easy in theory. The problem with democracy in practice is that it is never quite as good as its proponents hope it might be. The same can be said for how the United States responds to breaches of democracy in the Middle East. Despite ostensibly being on the side of popular rule, the White House has so far refused to take sides in Tunisia, instead expressing “concern” over the developments there. White House Press Secretary Jen Psaki informed reporters that administration officials were in touch with their Tunisian counterparts “to learn more about the situation, urge calm, and support Tunisian efforts to move forward in line with democratic principles.” (After Egypt’s 2013 coup, it was Psaki who infamously said, “We have determined we are not going to make a determination” about whether to call it a coup.)
In the Middle East, Tunisia’s crisis is the first real test of Biden’s professed commitment to a new democracy doctrine. During the unusual presidency of Donald Trump, Americans could easily forget that sustaining a gap between rhetoric and policy was a storied U.S. tradition. In his unapologetic disregard for supporting human rights and democracy abroad, Trump offered a natural experiment. The difference wasn’t so much that he couldn’t be bothered, but more that it didn’t occur to him to be bothered in the first place. For the first time in decades, the gap between words and deeds closed considerably. The United States, under Trump, had become less hypocritical. Dissidents no longer had to wonder if the United States would come to their aid. Under no illusions about American interest in their plight, they could adapt their activism accordingly and focus exclusively on their own local context. In his frank disregard, Trump was simply incapable of betraying them.
Under Joe Biden, America is speaking in terms of values and morality once again, both at home and abroad. Other countries, particularly weak ones, do not have the luxury of high-minded idealism. To pretend, in other words, is a privilege, one that America has insisted on and even earned. Its unrivaled power allows it two things: the ability to have ideals but also the ability to ignore them. For the United States, the charge of hypocrisy is effective precisely because it speaks to something true: We would like to be better, but we can’t.
But why can’t we? Why can’t we thwart a slow-motion coup in Tunisia, a relatively remote country where the risks of being too bold are minimal? Unlike Egypt, the Middle East’s most populous nation, Tunisia can’t claim to be central to U.S. regional objectives, such as the promotion of a two-state solution to the Israeli-Palestinian conflict (however imaginary such a solution might be).
A related question is to what extent the United States can actually influence the internal affairs of faraway countries. Is there much Biden can do? The short answer is yes. If Tunisia’s president doesn’t begin reversing course, the Biden administration can threaten a full—not a partial—suspension of aid. Partial aid suspensions don’t generally work, because they confuse and dilute American leverage. They are also self-undermining, because they communicate to authoritarian leaders that U.S. officials are hedging their bets and unwilling to follow through on their own stated commitments. Half measures can be the worst of both worlds—they anger target governments while failing to accomplish much besides virtue signaling to the foreign-policy community. If you’re going to piss off an ally, at least make it count.
Anne Applebaum and Peter Pomerantsev: How to put out democracy’s dumpster fire
To be sure, threatening an aid suspension is risky. But all bold policy action is risky (otherwise it wouldn’t be bold). We also know that not threatening an aid suspension seems almost certain to lead to an undemocratic result—a continuation of Tunisia’s current course of elevating a would-be strongman over Parliament and other constitutional constraints. So one option, while risky, is considerably more promising than the other. Some observers legitimately worry that suspending assistance to the Tunisian government might backfire. But this perspective misunderstands the direction of leverage; Tunisia needs the U.S. more than the U.S. needs Tunisia. The Biden administration should of course coordinate any such effort with the European Union and individual member states. Considering Europe’s proximity to and influence in Tunisia, any pressure campaign is likely to fail without European buy-in.
Also capable of playing a decisive role is the International Monetary Fund, which has invested in bailing out Tunisia’s battered economy (exacerbated by some of the worst per capita COVID-19 death rates in the world). The IMF’s Articles of Agreement impose no political conditions; autocrats and democrats alike are eligible for support. Even so, the U.S. and European nations, as the largest shareholders, can exercise their voting rights as they see fit. There is precedent for attaching conditions to prospective financial-support packages. During Egypt’s brief democratic opening in 2012 and 2013, the IMF requested that the elected Islamist government secure broad support, including from opposition parties, for an IMF deal. In short, the claim that President Biden lacks sufficient leverage to pressure the Tunisian government simply does not stand up to scrutiny.
I realize that this may be a losing battle. To be disappointed is to be realistic. The Biden administration is unlikely to act boldly, however bold its rhetoric has been up until this moment. In a small, obscure Arab country, then, a surprise coup attempt may mark—after a short interregnum—the return of American hypocrisy.
"
Don’t Take the Narrow View of What’s Happening in Gaza,5-15-2021,"As always in the Israeli-Palestinian conflict, two narratives are vying for primacy. In one, Israel is simply defending itself against a fresh attack. In the other, Israel’s bombardment of Gaza is the latest example of a desire to punish and humiliate Palestinians. These two narratives are not reconcilable, which makes reasoned discussion an exercise in futility. But any sophisticated argument must contend with the long, winding lead-up to the current crisis. Why is war in Gaza returning now, and why does it always seem to return, with stubborn, periodic insistence?
Despite inching toward the Democratic Party’s left flank on various domestic- and foreign-policy issues, the Biden administration has fallen back on the usual formulas, offering robotic recitations about “Israel’s right to defend itself.” On Thursday, President Joe Biden said that he hadn’t seen a “significant overreaction” from Israel, while failing to mention a word about Palestinian deaths. In so doing, he gave Israel what amounts to a green light to intensify its bombing campaign.
The White House has been eager to highlight Biden’s “unwavering support” for Israel, which raises the question of what, if anything, might cause America’s support for the Israeli government to waver even slightly. This question is worth asking sooner rather than later, now that more than 120 Palestinians have died, a quarter of them children—all in a few days—according to Palestinian officials.
Recommended Reading
An illustration of glasses and multi-colored circles.
True Inclusion Requires Viewpoint Diversity
Conor Friedersdorf
A broken window of a school in Afghanistan
America Will Have to Reckon With Its Cynicism About Afghanistan
Elliot Ackerman
An illustration of a gavel, a caduceus, and male and female sex symbols
The War on Trans Kids Is Totally Unconstitutional
Ronald J. Krotoszynski, Jr.
Supporters of the status quo tend to focus on the fact that Hamas started lobbing rockets into Israel, and they argue that Israel has no choice but to retaliate, as any other country would. Some even suggest that the Israeli army is historically unparalleled in its efforts to spare civilian casualties. This line of argument, however, does not tend to offer many details on how this latest conflagration came to be. Why is all of this happening now? Wars and skirmishes don’t occur in a vacuum; they are the result of an accumulation of actions and reactions over years, if not decades.  
[Photos: Violence explodes across Israel and Gaza]
A potential reputational cost attends even asking these questions. Those who do are often accused of justifying or supporting Hamas’s actions. But it should be possible to do two things at once—first, to note that Hamas is a U.S.-designated terrorist organization. This is not in doubt, and to my knowledge there isn’t a particularly large grassroots movement to eliminate the designation. Hamas’s rockets are indiscriminate and are designed to terrorize Israeli civilians. They might hit schools or hospitals, or they might not. It is this lack of knowing that makes them “effective,” despite their imprecision. These are war crimes, as Human Rights Watch has documented. Second, it should also be possible to recognize that the current conflict in Gaza didn’t appear from the sky unannounced, a product of random chance.
If we want to prevent violence or terrorist activity from happening in the future, then we have to understand what motivates violence or terrorist activity. This is a straightforward observation, albeit a fraught one. Shortly after the September 11 attacks, attempts to understand why were viewed by many as terrorism apologetics. Among scholars and analysts of violent extremism, however, it is close to an article of faith that contextual factors make resorting to violence either more or less likely. The goal is to understand what they are and, ideally, to try to address them.
Consider that even the George W. Bush administration made a rather sophisticated and somewhat original argument about the “root causes” of the September 11 attacks. President Bush and his top aides argued that citizens are more likely to resort to violence when they lack peaceful, constructive means to express their grievances. Accordingly, September 11 did not happen because Arabs despised our freedom, but rather because the Middle East’s stifling political environment bred anger, frustration, and ultimately hate. Part of the long-term solution, then, was to promote democratic reform and basic political rights. Later, when the Islamic State rose to prominence, in 2013, a whole literature emerged on the causes and grievances that led to the organization’s rise. When a white supremacist murdered 50 Muslims in Christchurch, New Zealand, in March 2019, I argued in favor of assessing the arguments and motivations in his 74-page manifesto—not to give those views legitimacy, as some feared, but to understand the drivers of radicalization.
In the case of the current situation in Gaza, the objective is not to carefully assess Hamas’s “grievances.” The group’s behavior is not particularly mysterious. Hamas leaders see anger against Israel building among ordinary Palestinians, and they see an opportunity to weaponize it. They send rockets across the border and invite destruction because they wish to project relevance and rally domestic support after years of diminished popularity. Hamas is not a bunch of crazed lunatics. Selfish, self-serving, and cavalier toward Palestinian life, its leaders are acting according to a traditional rational-actor model. Whether or not we like it, they believe they will benefit from the crisis—and they may, in reality, find themselves in a stronger position when this is over.
This is one step in the analysis, but it still doesn’t tell us much about why Palestinian anger had been rising in the first place. The progressive wing of the Democratic Party tends to emphasize the original “source” of the current violence. This source isn’t exactly a secret either. As The New York Times reported: “The trouble started on Monday, when a heavy-handed police raid at Jerusalem’s Al Aqsa Mosque—the third-holiest site in Islam, located atop a site also revered by Jews—set off an instant backlash.” Yet while the police raid was actually unfolding—during the final days of Ramadan and at such a sensitive site—I found only minimal coverage in mainstream outlets. I relied instead on Twitter, Instagram, and Facebook accounts that were covering the raid and its aftermath in real time, although many were censored for “sensitive content.” The tragedy, upon other tragedies, is that the world seems to pay attention to Palestinians only when they use violence. Nonviolent activism goes largely ignored.  
Tensions had, in fact, been building for months, with the threatened eviction of Palestinian families from the Sheikh Jarrah neighborhood of East Jerusalem. Smaller protests in the area, taking place at a steady clip for some time, grew larger. But even these details don’t capture the broader context. What is so important about Sheikh Jarrah, and why are Palestinian families being faced with eviction in the first place? As NBC News reported: “The expansion of Jewish settlements in Sheikh Jarrah, which is on land that helps form the final link in a settlement circle surrounding east Jerusalem—an area that Palestinians hope will be the capital of a future state.”
[Micah Goodman: Eight steps to shrink the Israeli-Palestinian conflict]
That aspiration matters, but seemingly not much to those who see Israel’s right to self-defense as the only truly salient issue. They don’t see the occupation itself—and what has flowed from it—as the original sin. And because they don’t recognize the centrality of the occupation, they don’t acknowledge what is so obvious to the other side: the basic fact of a lopsided power dynamic, in which Israel is the aggressor and Palestinians are the aggressed. This imbalance ought to matter—and not just for moral reasons. American policy makers, regardless of whether they see Palestinians as fully deserving of rights and dignity, should understand that wildly unequal power and capabilities make peace all but impossible. Absent international pressure, the more powerful actor has few incentives to offer substantive compromises and concessions to the weaker party.
The Biden administration is acting as if the past several years (or decades) have not happened. It is repeating the same mistakes as its predecessors, while hoping that a cease-fire can bring an end to hostilities and a return to calm. But until fundamental injustices—and Palestinian national aspirations—are addressed by ending an occupation that has lasted longer than my own existence, the calm will prove uneasy. Maybe that’s good enough for Biden. But it shouldn’t be.
"
America Without God,4-1-2021,"The United States had long been a holdout among Western democracies, uniquely and perhaps even suspiciously devout. From 1937 to 1998, church membership remained relatively constant, hovering at about 70 percent. Then something happened. Over the past two decades, that number has dropped to less than 50 percent, the sharpest recorded decline in American history. Meanwhile, the “nones”—atheists, agnostics, and those claiming no religion—have grown rapidly and today represent a quarter of the population.
But if secularists hoped that declining religiosity would make for more rational politics, drained of faith’s inflaming passions, they are likely disappointed. As Christianity’s hold, in particular, has weakened, ideological intensity and fragmentation have risen. American faith, it turns out, is as fervent as ever; it’s just that what was once religious belief has now been channeled into political belief. Political debates over what America is supposed to mean have taken on the character of theological disputations. This is what religion without religion looks like.
Not so long ago, I could comfort American audiences with a contrast: Whereas in the Middle East, politics is war by other means—and sometimes is literal war—politics in America was less existentially fraught. During the Arab Spring, in countries like Egypt and Tunisia, debates weren’t about health care or taxes—they were, with sometimes frightening intensity, about foundational questions: What does it mean to be a nation? What is the purpose of the state? What is the role of religion in public life? American politics in the Obama years had its moments of ferment—the Tea Party and tan suits—but was still relatively boring.
We didn’t realize how lucky we were. Since the end of the Obama era, debates over what it means to be American have become suffused with a fervor that would be unimaginable in debates over, say, Belgian-ness or the “meaning” of Sweden. It’s rare to hear someone accused of being un-Swedish or un-British—but un-American is a common slur, slung by both left and right against the other. Being called un-American is like being called “un-Christian” or “un-Islamic,” a charge akin to heresy.
From the October 2018 issue: The Constitution is threatened by tribalism
This is because America itself is “almost a religion,” as the Catholic philosopher Michael Novak once put it, particularly for immigrants who come to their new identity with the zeal of the converted. The American civic religion has its own founding myth, its prophets and processions, as well as its scripture—the Declaration of Independence, the Constitution, and The Federalist Papers. In his famous “I Have a Dream” speech, Martin Luther King Jr. wished that “one day this nation will rise up and live out the true meaning of its creed.” The very idea that a nation might have a creed—a word associated primarily with religion—illustrates the uniqueness of American identity as well as its predicament.
The notion that all deeply felt conviction is sublimated religion is not new. Abraham Kuyper, a theologian who served as the prime minister of the Netherlands at the dawn of the 20th century, when the nation was in the early throes of secularization, argued that all strongly held ideologies were effectively faith-based, and that no human being could survive long without some ultimate loyalty. If that loyalty didn’t derive from traditional religion, it would find expression through secular commitments, such as nationalism, socialism, or liberalism. The political theorist Samuel Goldman calls this “the law of the conservation of religion”: In any given society, there is a relatively constant and finite supply of religious conviction. What varies is how and where it is expressed.
No longer explicitly rooted in white, Protestant dominance, understandings of the American creed have become richer and more diverse—but also more fractious. As the creed fragments, each side seeks to exert exclusivist claims over the other. Conservatives believe that they are faithful to the American idea and that liberals are betraying it—but liberals believe, with equal certitude, that they are faithful to the American idea and that conservatives are betraying it. Without the common ground produced by a shared external enemy, as America had during the Cold War and briefly after the September 11 attacks, mutual antipathy grows, and each side becomes less intelligible to the other. Too often, the most bitter divides are those within families.
Without Christianity, Americans no longer have a common culture upon which to fall back.
No wonder the newly ascendant American ideologies, having to fill the vacuum where religion once was, are so divisive. They are meant to be divisive. On the left, the “woke” take religious notions such as original sin, atonement, ritual, and excommunication and repurpose them for secular ends. Adherents of wokeism see themselves as challenging the long-dominant narrative that emphasized the exceptionalism of the nation’s founding. Whereas religion sees the promised land as being above, in God’s kingdom, the utopian left sees it as being ahead, in the realization of a just society here on Earth. After Supreme Court Justice Ruth Bader Ginsburg died in September, droves of mourners gathered outside the Supreme Court—some kneeling, some holding candles—as though they were at the Western Wall.
On the right, adherents of a Trump-centric ethno-nationalism still drape themselves in some of the trappings of organized religion, but the result is a movement that often looks like a tent revival stripped of Christian witness. Donald Trump’s boisterous rallies were more focused on blood and soil than on the son of God. Trump himself played both savior and martyr, and it is easy to marvel at the hold that a man so imperfect can have on his soldiers. Many on the right find solace in conspiracy cults, such as QAnon, that tell a religious story of earthly corruption redeemed by a godlike force.
Though the United States wasn’t founded as a Christian nation, Christianity was always intertwined with America’s self-definition. Without it, Americans—conservatives and liberals alike—no longer have a common culture upon which to fall back.
Unfortunately, the various strains of wokeism on the left and Trumpism on the right cannot truly fill the spiritual void—what the journalist Murtaza Hussain calls America’s “God-shaped hole.” Religion, in part, is about distancing yourself from the temporal world, with all its imperfection. At its best, religion confers relief by withholding final judgments until another time—perhaps until eternity. The new secular religions unleash dissatisfaction not toward the possibilities of divine grace or justice but toward one’s fellow citizens, who become embodiments of sin—“deplorables” or “enemies of the state.”
This is the danger in transforming mundane political debates into metaphysical questions. Political questions are not metaphysical; they are of this world and this world alone. “Some days are for dealing with your insurance documents or fighting in the mud with your political opponents,” the political philosopher Samuel Kimbriel recently told me, “but there are also days for solemnity, or fasting, or worship, or feasting—things that remind us that the world is bigger than itself.”
Absent some new religious awakening, what are we left with? One alternative to American intensity would be a world-weary European resignation. Violence has a way of taming passions, at least as long as it remains in active memory. In Europe, the terrors of the Second World War are not far away. But Americans must go back to the Civil War for violence of comparable scale—and for most Americans, the violence of the Civil War bolsters, rather than undermines, the national myth of perpetual progress. The war was redemptive—it led to a place of promise, a place where slavery could be abolished and the nation made whole again. This, at least, is the narrative that makes the myth possible to sustain.
For better and worse, the United States really is nearly one of a kind. France may be the only country other than the United States that believes itself to be based on a unifying ideology that is both unique and universal—and avowedly secular. The French concept of laïcité requires religious conservatives to privilege being French over their religious commitments when the two are at odds. With the rise of the far right and persistent tensions regarding Islam’s presence in public life, the meaning of laïcité has become more controversial. But most French people still hold firm to their country’s founding ideology: More than 80 percent favor banning religious displays in public, according to one recent poll.
In democracies without a pronounced ideological bent, which is most of them, nationhood must instead rely on a shared sense of being a distinct people, forged over centuries. It can be hard for outsiders and immigrants to embrace a national identity steeped in ethnicity and history when it was never theirs.
Take postwar Germany. Germanness is considered a mere fact—an accident of birth rather than an aspiration. And because shame over the Holocaust is considered a national virtue, the country has at once a strong national identity and a weak one. There is pride in not being proud. So what would it mean for, say, Muslim immigrants to love a German language and culture tied to a history that is not theirs—and indeed a history that many Germans themselves hope to leave behind?
An American who moves to Germany, lives there for years, and learns the language remains an American—an “expat.” If America is a civil religion, it would make sense that it stays with you, unless you renounce it. As Jeff Gedmin, the former head of the Aspen Institute in Berlin, described it to me: “You can eat strudel, speak fluent German, adapt to local culture, but many will still say of you Er hat einen deutschen Pass—‘He has a German passport.’ No one starts calling you German.” Many native-born Americans may live abroad for stretches, but few emigrate permanently. Immigrants to America tend to become American; emigrants to other countries from America tend to stay American.
If only Americans could begin believing in politics less fervently—but this would come at a cost.
The last time I came back to the United States after being abroad, the customs officer at Dulles airport, in Virginia, glanced at my passport, looked at me, and said, “Welcome home.” For my customs officer, it went without saying that the United States was my home.
In In the Light of What We Know, a novel by the British Bangladeshi author Zia Haider Rahman, the protagonist, an enigmatic and troubled British citizen named Zafar, is envious of the narrator, who is American. “If an immigration officer at Heathrow had ever said ‘Welcome home’ to me,” Zafar says, “I would have given my life for England, for my country, there and then. I could kill for an England like that.” The narrator reflects later that this was “a bitter plea”:
Embedded in his remark, there was a longing for being a part of something. The force of the statement came from the juxtaposition of two apparent extremes: what Zafar was prepared to sacrifice, on the one hand, and, on the other, what he would have sacrificed it for—the casual remark of an immigration official.
When Americans have expressed disgust with their country, they have tended to frame it as fulfillment of a patriotic duty rather than its negation. As James Baldwin, the rare American who did leave for good, put it: “I love America more than any other country in the world, and, exactly for this reason, I insist on the right to criticize her perpetually.” Americans who dislike America seem to dislike leaving it even more (witness all those liberals not leaving the country every time a Republican wins the presidency, despite their promises to do so). And Americans who do leave still find a way, like Baldwin, to love it. This is the good news of America’s creedal nature, and may provide at least some hope for the future. But is love enough?
Conflicting narratives are more likely to coexist uneasily than to resolve themselves; the threat of disintegration will always lurk nearby.
On January 6, the threat became all too real when insurrectionary violence came to the Capitol. What was once in the realm of “dreampolitik” now had physical force. What can “unity” possibly mean after that?
Can religiosity be effectively channeled into political belief without the structures of actual religion to temper and postpone judgment? There is little sign, so far, that it can. If matters of good and evil are not to be resolved by an omniscient God in the future, then Americans will judge and render punishment now. We are a nation of believers. If only Americans could begin believing in politics less fervently, realizing instead that life is elsewhere. But this would come at a cost—because to believe in politics also means believing we can, and probably should, be better.
In History Has Begun, the author, Bruno Maçães—Portugal’s former Europe minister—marvels that “perhaps alone among all contemporary civilizations, America regards reality as an enemy to be defeated.” This can obviously be a bad thing (consider our ineffectual fight against the coronavirus), but it can also be an engine of rejuvenation and creativity; it may not always be a good idea to accept the world as it is. Fantasy, like belief, is something that humans desire and need. A distinctive American innovation is to insist on believing even as our fantasies and dreams drift further out of reach.
This may mean that the United States will remain unique, torn between this world and the alternative worlds that secular and religious Americans alike seem to long for. If America is a creed, then as long as enough citizens say they believe, the civic faith can survive. Like all other faiths, America’s will continue to fragment and divide. Still, the American creed remains worth believing in, and that may be enough. If it isn’t, then the only hope might be to get down on our knees and pray.

History Has Begun: The Birth Of A New America
"
Americans Are Losing Sight of What Fascism Means,10-25-2020,"How do Americans decide what to be outraged about? It seems like ancient history now, but that was one of the questions The New York Times inadvertently raised in June when it appended an editor’s note to an op-ed by Senator Tom Cotton—a piece that some on the Times staff saw as presenting a physical danger not only to the country but to themselves.
The op-ed called for American troops to be sent to “restore order” to cities experiencing violent protests. Outside and inside the Times, it was widely condemned as “fascist” or fascist-adjacent. More recently, though, the Times published an op-ed of a similar vein, except this time readers had the opportunity to glimpse what actual fascism looks like. Fascism, in today’s context, isn’t mere authoritarianism, but the attempt to suppress all dissent, public or private, in the name of the nation; it is the expression of a regimented society that elevates order as both the means and end of all political life.
The October 1 op-ed, by Regina Ip, a member of Hong Kong’s Executive Council, captured such sentiments well. Ip laid out the case for a new Chinese-backed security law that would effectively criminalize anything that might be perceived as “subversion.” Included was one of the most disturbing passages I have read in an American publication:
To some, the new national security law is especially chilling because it seems simultaneously vague and very severe. But many laws are vague, constructively so. And this one only seems severe precisely because it fills longstanding loopholes—about subversion, secession, local terrorism, collusion with external forces. One person’s “severe” is someone else’s intended effect.
This time, though, no staff revolt occurred, even though Ip’s article was an elaborate, if refreshingly frank, endorsement of real fascism.
More by this writer

The Democrats May Not Be Able to Concede
Shadi Hamid

Things Were Going to Be So Much Better
Shadi Hamid
An illustration of a raised fist overset with stamped outlines of viruses
The Coronavirus Killed the Revolution
Shadi Hamid
[Read: Hong Kong is a colony once more]
Outrage is always selective. I could have written about something else, but I decided to write about this. The question remains: Why did readers who were infuriated by Cotton’s argument seem to shrug off Ip’s?
Words matter because they help order our understanding of politics both at home and abroad. If Cotton is a fascist, then we don’t know what fascism is. And if we don’t know what fascism is, then we will struggle to identify it when it threatens millions of lives—which is precisely what is happening today in areas under Beijing’s control. Chinese authorities have tightened their grip on Hong Kong. And while the world watches, they are undertaking one of the most terrifying campaigns of ethnic cleansing and cultural genocide since World War II in Xinjiang province, with more than 1 million Muslim Uighurs in internment camps, as well as reports of forced sterilization and mass rape.
For morality to operate, moral proportion is required. Unfortunately, the Trump era has badly damaged our ability to see what’s right in front of our noses.
[Read: Saving Uighur culture from genocide]
Today, the United States is consumed by internal divisions, which means that the flow of ideas is the reverse of what it otherwise might be. Instead of solving problems through the very democratic institutions that once gave inspiration abroad, we now import foreign notions from Europe’s dark past in an attempt to comprehend what seems incomprehensible here in our own country. Donald Trump’s election led to a whole cottage industry of thinking that fascism is near, right here at home. It has grown steadily, reaching its culmination in the lead-up to the November election. In the past month alone, readers have seen Mussolini comparisons from eminent historians, explainers on what it’s like to live through a civil war, and an endless stream of warnings about Reichstag fires and a “fascist coup.” Here, Trump deserves some of the blame. He has a knack for bringing out the worst in his opponents, giving them license to use the very hyperbole and distortion that they criticize in others. This is one of many reasons to hope he is voted out of office.
If America doesn’t descend into fascism—and Joe Biden wins by a comfortable margin and Republicans accept the result, however reluctantly—then Americans will be able, once again, to gain a proper perspective on their long, four-year episode of unreason and myopia. Sometimes, life is elsewhere. In some places, democracy, or what’s left of it, is truly under threat. One of those places is Hong Kong.
The Chinese regime’s totalitarianism is still more evident in Xinjiang, where the sterilization of Uighur women is systematic, with the intent to decrease the Muslim population. Chinese companies have made beauty products for export with what appears to be the human hair of Uighurs in internment camps. Chinese authorities have organized the “Pair Up and Become Family” campaign, in which more than 1 million party cadres have been dispatched to live in Uighur households, monitoring families’ every move, with new male “relatives” sleeping with Uighur women and forcing marriage, while many of their actual male relatives are detained in the camps. There is another name for this, and it’s rape.
Americans are not unusual in caring less about tragedies in countries other than their own. The atrocities committed against the Uighurs, however, attract less attention than they should in part because of whom they’re committed by. Getting large numbers of people genuinely worked up about what China does is difficult. Abuses at home make mainstream commentators and analysts wary about highlighting them in authoritarian regimes, if only because Americans feel our own hypocrisy is more glaring. “The United States cannot credibly speak against abuses in other nations,” Alexandra Schmitt of the Center for American Progress has argued, “if its own policies are perpetuating human rights abuses abroad or if it is failing to uphold and protect rights at home.”
[Read: Uighurs can’t escape Chinese repression, even in Europe]
When I requested comment about the Times’ decision to publish Ip’s op-ed, the acting editorial-page editor, Katie Kingsbury, responded in a statement that the paper had also published a variety of prodemocracy opinions, including from its own editorial board. “Regina Ip’s Op-Ed,” the statement continued, “allowed our readers to hear another side of the debate from a member of the Executive Council of Hong Kong.” Yet Ip’s piece was less a reasoned argument than an explicit assertion of Beijing’s right to repress. This is not a debate that requires a careful exposition of both sides, in part because there isn’t another side to defend. It is one thing for American news outlets to publish perspectives from authoritarian heads of state in the interest of informing. It is quite another to publish actual, and not merely imagined, articulations of the kind of fascism and totalitarianism that the Chinese regime upholds daily.
Liberals and liberal institutions feel understandable discomfort in portraying China as an enemy, since this is what Trump has done—often with considerable resort to xenophobia and without distinguishing between the Chinese regime and the Chinese people. To attack and focus attention on China also runs the risk of boosting the Trump administration’s narrative that China is America’s new enemy. That Trump might be right on one thing is certainly possible, but that doesn’t make the idea of agreeing with him any less uncomfortable.
This can sometimes lead to a moral equivalence, where the United States, under Trump, is relegated to the same plane as the Chinese regime on issues such as digital surveillance. It follows, then, that trying to exclude Chinese technology from American networks and markets would be the height of hypocrisy, as Sam Biddle has argued in The Intercept. This summer, Trump’s efforts to pry the popular app TikTok away from its China-based parent company prompted the writer (and former Times editorial-board member) Sarah Jeong to wonder, “‘Is the United States better, worse, or the same as China?’ …  In 2020, this is becoming a genuinely difficult question to answer.” After all, Jeong reasoned, “China brutally represses its political dissidents; in America, law enforcement in military camouflage have grabbed protesters off the streets and shoved them into unmarked vans.”
Jeong went further than most in drawing an equivalence between China and Trump’s America. Still, the Chinese regime does tend to garner more respect and deference among a certain kind of American observer than the Trump administration does. China, if one puts human-rights abuses aside, can seem tantalizingly efficient—a technocrat’s dream paradise, where unelected leaders “get things done.” Some of this fascination with the Chinese miracle was on display in a 2018 Times article with the suggestive headline “The American Dream Is Alive. In China.” Its authors took at face value polling that the Chinese are now “among the most optimistic people in the world—much more so than Americans and Europeans.” Since then, China’s seemingly effective response to COVID-19 has only made American incompetence starker.
[Read: How history gets rewritten]
These developments, some of them quite recent, conspire to China’s advantage. After all, Trump is a greater threat to the American self-conception than China is. The dislike and even hatred directed toward the Trump administration are partly born of the gap between expectation and reality, one that has widened perilously over the course of the past four years. Americans believe that they can, and should, be better. Few have any such expectations about China’s morality or inherent goodness. Many feel a sense of futility that nothing much can be done.
But this is no justification for twisting the meaning of words such as fascist beyond recognition. Doing so has been a long-standing practice. As George Orwell wrote in 1944, “I have heard it applied to farmers, shopkeepers, Social Credit, corporal punishment, fox-hunting, bull-fighting, the 1922 Committee, the 1941 Committee, Kipling, Gandhi, Chiang Kai-Shek, homosexuality, Priestley’s broadcasts, Youth Hostels, astrology, women, dogs and I do not know what else.” But as citizens of a country apart, across an ocean, Americans were spared at least some of this lexiconic plasticity—until now.
A world where a Republican senator in a democracy—even a flawed democracy—is deemed fascist and therefore beyond the bounds of respectable discussion, while actual authoritarians, or worse, are free to propagate their views with little public censure is a world that is upside down. Words should mean something, and if Americans insist on instrumentalizing them for political objectives, however just, then journalists and analysts will no longer have the language to describe the worst threats from the worst actors.
What the Chinese Communist Party is doing is not unspeakable. It can and should be spoken about, however difficult that may be. Moral clarity requires us to seek both accuracy and proportion. Anything less does a disservice to those who have actually struggled, fought, and died against fascism. If Americans, even for just a moment, could look beyond Trump, they might realize that another world—one where fascism is a living, breathing thing—awaits them."
The Democrats May Not Be Able to Concede,9-13-2020,"This is the era of expecting the worst while hoping for the merely tolerable. Some might say that the worst is already happening—economic disaster and 190,000 dead from a pandemic—while the president and his surrogates insist, in a feat of self-delusion, that the “best is yet to come.” As someone who has argued against catastrophism—I don’t believe Donald Trump is a fascist or a dictator in the making, and I don’t believe America is a failed state—I find myself truly worried about only one scenario: that Trump will win reelection and Democrats and others on the left will be unwilling, even unable, to accept the result.
A loss by Joe Biden under these circumstances is the worst case not because Trump will destroy America (he can’t), but because it is the outcome most likely to undermine faith in democracy, resulting in more of the social unrest and street battles that cities including Portland, Oregon, and Seattle have seen in recent months. For this reason, strictly law-and-order Republicans who have responded in dismay to scenes of rioting and looting have an interest in Biden winning—even if they could never bring themselves to vote for him.
George Packer: This is how Biden loses
In presidential elections, once is a fluke; twice is a pattern. I struggle to imagine how, beyond utter shock, millions of Democrats will process a Trump victory. A loss for Biden, after having been the clear favorite all summer, would provoke mass disillusion with electoral politics as a means of change—at a time when disillusion is already dangerously high. If Democrats can’t beat a candidate as unpopular as Trump during a devastating pandemic and a massive economic contraction, then are they even capable of winning presidential elections anymore? Democracy, after all, is supposed to self-correct after mistakes, particularly mistakes as egregious as electing Donald Trump—whose unfitness for the nation’s highest office makes itself apparent with almost every passing day.
Liberals had enough trouble accepting the results of the 2016 election. In some sense, they never really came to terms with it. The past four years have witnessed the continuous urge to explain away the inexplicable, to find solace in the fact that the voters betrayed them. How could so many of their fellow Americans side with a racist and a fabulist, someone so callous and seemingly without empathy? It was easier to think that those Americans had been lackeys, manipulated and deceived, or that they simply hadn’t understood what was best for them. Moreover, the Russians had interfered, and tipped the balance in an extremely close election through propaganda, fake news, and collusion with the Trump campaign. Perhaps, as former Senate Minority Leader Harry Reid suggested, the Russians had even tampered with the vote itself.
That was then. This time, it would be worse. In 2016, Trump hadn’t ever held political office, so no one could truly grasp just how bad, and exhausting, a president he might become. Perhaps in 2016, too many voters were unwilling to believe that America was “already great” (and, for too many, it wasn’t). They had no reason to be content with the status quo, so their willingness to try something quite risky was understandable. Now, though, everyone should know the risks. Moreover, Hillary Clinton was an unusually polarizing candidate, whereas Joe Biden tends to attract attention for not attracting attention.
Because Biden’s poll numbers this year have mostly been higher than Clinton’s were in 2016, a Trump victory will be even harder for the left to absorb. Until Democrats (and commentators like myself) started panicking recently, overconfidence had set in. The polls offered good reason to think that a Trump victory was drifting out of reach—and they still show the former vice president with a significant, if diminished, advantage. No matter how the polls shift, a Trump win means a squandered lead and shattered expectations.
David A. Graham: The ‘blue shift’ will decide the election
If Trump manages to win, recent polling data indicate, he will likely do so despite losing the popular vote. That will fuel disillusion not just with the election outcome but with the electoral system. The popular-vote numbers will be used to argue that Trump won without winning—again. In theory, this could be a good thing, if it birthed a mass movement to change the way Americans choose their presidents. In practice, though, Republicans, after prevailing only in the Electoral College for the third time in six elections, will vehemently oppose any attempt to abolish it, further driving despair among Democrats that change can come about through “normal” politics.
Liberals have convinced themselves that Republicans are, in one way or another, cheating. In addition to all of Trump’s norm-breaking, the GOP is gerrymandering, purging voter rolls, and shutting down polling places in Black neighborhoods. Yet Republicans wouldn’t have been able to do these things if they hadn’t won enough statewide and local offices in the first place. They have put themselves in a position to enact their favored redistricting and election procedures by finding candidates and pursuing policies that made them competitive in formerly Democratic states, demanding a level of party discipline that Democrats can seldom muster, and getting their supporters to turn out for down-ballot races. Republican manipulation is what the democratic process itself has produced, however unfair, and it can be undone only through that same process, however flawed. To some degree, this is just how the game is played, and Democrats need to play it better if they want to win the Electoral College. Having won the presidency twice in the recent past, Democrats are surely capable of prevailing via normal means, but promising voters a slightly improved version of the present may not necessarily be the best way to do it.
Considering the lopsided stakes, Democrats have every right to be nervous. The anxiety gripping the two parties is asymmetric: Biden is at least marginally more acceptable, ideologically and certainly temperamentally, to Republican voters than Trump is to Democratic voters. Trump represents the nativist wing of an already nativist Republican Party, so it is understandable that Democrats of any stripe would fear him more. Biden, on the other hand, is a conventional Democrat, representing the center of the Democratic Party. If Biden, of all people, is beyond the pale, then so is half the country.
Adam Serwer: The new reconstruction
Of course, Republicans will be angry if they lose, and Trump himself will almost certainly attack the result. But if Biden wins, he’s likely to do so with both the popular vote and the Electoral College—and by potentially significant margins. A clear win for the former vice president means that Republican officials, with the same self-interest that drove them toward Trump in the first place, will have strong incentives to distance themselves from a futile delegitimization campaign waged by a sore loser. Meanwhile, expectations also matter for Republicans, but in reverse. For anyone who had been following the polls, a Biden victory will prompt little surprise. It is easier to accept the things you had already come to expect.
Accepting the things that never should have happened is far more difficult. A certain kind of cognitive dissonance—the gap between what is and what should be—can fuel revolutionary sentiment, and not just in a fluffy, radical-chic kind of way. In such situations, acting outside the political process, including through nonpeaceful means, becomes more attractive, not necessarily out of hope but out of despair.
This distance between what a society should be and the tragedy of what it actually becomes is less of a problem in democracies, because democracies are supposed to be responsive to voters’ demands and grievances. But they aren’t always. The gap will grow larger under a Trump presidency than a Biden one, and this has implications for mass unrest and political violence across American cities. For democracy to work, the losers of elections need to believe that they can win the next time around. Otherwise their incentives to play the spoiler increase. A breakdown of democracy is always a possibility, but the country is more resilient than it may seem, and consolidated democracies seldom break down in any circumstance. That said, this is one of those propositions that is better left untested.
"
Things Were Going to Be So Much Better,6-22-0202,"In moments of crisis and civil unrest, people always say that things will never be the same. But the act of living is a bit more circular than we give it credit for. Things might never be exactly the same as they once were, but they do tend to at least return to some previous and somehow tolerable baseline. Human beings, facing crisis, find ways to adapt, sometimes ingeniously. Life, otherwise, would be unbearable. To carry on through and beyond tragedy would be impossible, and the only thing more common than tragedy is death.
In Peter De Vries’s novel The Blood of the Lamb, published in 1961, the protagonist, experiencing the (temporary) remission of his daughter’s leukemia, marvels, “It seemed from all of this that uppermost among human joys is the negative one of restoration: not going to the stars, but learning that one may stay where one is.” Faced with the finality of death, the mere return of what had previously seemed normal and unremarkable was utter joy.
Then again, the knowledge that circumstances could be much worse comes as little comfort to those who, as recently as a few months ago, might have believed that life was about to get better. Just as the arc of history bends, so too do human lives, particularly for the millions of young people expecting to launch into new careers—and adulthood—this spring and summer.
More by Shadi Hamid
An illustration of a raised fist overset with stamped outlines of viruses
The Coronavirus Killed the Revolution
Shadi Hamid
Xi Jinping at the School of Medicine at Tsinghua University in Beijing
China Is Avoiding Blame by Trolling the World
Shadi Hamid

American Self-Criticism Borders on Narcissism
Shadi Hamid
[Rebecca L. Spang: The revolution is only getting started]
Looking back, I think I made a mistake. In March, I argued here in The Atlantic that the pandemic would make people content with a return to normalcy. Perhaps they would even long for it. Yet although the novel coronavirus has receded into the background—not quite forgotten, but relegated to the ambient mood music of our new lives—the psychic energies that were gathering for months have clearly found expression in both new anger, which can be good when it leads to reforms long overdue, and new resentments, which probably aren’t quite as good.
Politics—particularly when concerning matters of life and death—always seems to loom large in the moment when you suspect you are participating in history. That moment occurred for me, although it would extend to months and then years, nearly two decades ago, when I started my freshman year in college. I was away from home for the first time, trying to figure out who I was and who I wanted to be, which was difficult enough. But then, just two weeks in, the September 11 attacks happened. I saw the smoke rising from the Pentagon from my dorm. It was a double tragedy for me—first as an American, but also as a Muslim seeing people committing such acts of horror in my name. To say that my life really was never the same again wouldn’t be an exaggeration. My career trajectory changed. I decided to study Islamists and Islam, when I could recall, just months prior, a dishonorable if fleeting desire to make a lot of money.
[Shadi Hamid: The coronavirus killed the revolution]
As crazy and destructive as those events were—the debacle of the Iraq War followed 9/11 rather quickly—we had the advantage of not having social media. I didn’t watch television, so my primary access to information was the homepage of The New York Times and a few blogs that were starting to sprout up then—as well as guest lectures, anti-war campus teach-ins, and maybe also the odd, occasional chain email indulging in a conspiracy or two. Both earnest and righteous, we were probably insufferable. No one, at least not right away, told me that reading Noam Chomsky and thinking he was something akin to a prophet was a rite of passage, and that it was likely to pass in time.
What was true then is true now: Human motivation has a darkness at its core. Being outraged feels good, having an enemy feels better, and having a scapegoat always helps. All three of these things are aided considerably by the democratization of information—when, as the author Peter Pomerantsev put it, “nothing is true and everything is possible.”
So this time around, everything will be different, and it will also be the same. This year’s high-school and college graduates are being propelled into a world that is frightening in its uncertainty. In economic terms, this is a summer that could scar them for life. In political terms, they will find themselves living in a more polarized media landscape, and social circles that are self-segregating, if not necessarily by race, then by ideology. The liberal sensibilities that, for all their faults, saw freewheeling and uncomfortable debate as both right and necessary seem stodgy and antiquated today. Safety and security are preferable now, but to seek them doesn’t mean to find them.
[Annie Lowrey: This summer will scar young Americans for life]
I’ve generally been a pessimist about who we are as mere human beings, broken by sin, but an optimist about how our human darkness can be channeled peacefully and perhaps even constructively. My view has not required that Americans individually would behave in ways indicative of greatness, but I did believe that our country, buttressed by institutions, was resilient, strong, and prepared to fight back against the worst to come, if in fact the worst did come.
But even I’m losing faith. Could this spring and summer, with their odd and tragic confluence of unlikely events, be a “turning point,” to use a cliché? I’m not old enough to know what living through the 1960s, the last period of social tumult in the United States, felt like. I was in Tunisia and Egypt for some of the Arab revolutions of 2011, but those tell me only so much; they weren’t happening in my country. I would always be an outsider observing from a place of emotional and intellectual distance. Even if those revolutions succeeded, they would never be mine.
My more grounded friends tell me that things will probably be okay—for the United States. Young Americans, however, may never see a full recovery. As The Atlantic’s Annie Lowrey wrote recently, “The pandemic recession has thus thrust Gen Z, as a cohort, into a deep state of financial precarity. The effects are intergenerational.” Their earnings will likely be depressed for, quite literally, the rest of their life.
But here it may be worth returning to an insight from De Vries’s novel—published before the world got better, but also before the world started ending: Things are never as good as they seem, but they’re usually not as bad as they seem, either.
"
The Coronavirus Killed the Revolution,3-25-2020,"There was a before and an after. Before the seriousness of the pandemic set in, Democrats—and Americans more generally—were divided on whether the moment required deep, structural change. Perhaps it required something less ambitious: a return to normalcy, to the quiet comforts of calm and stability. In that theory, represented by former Vice President Joe Biden, Donald Trump was at once the problem and an aberration in the American story’s broader sweep. This wasn’t a time for radical moves. There was only a need for removing Trump from the presidency. And once he was gone, the country would regain its footing, and we could return to our insistent, if somewhat boring and stubbornly incremental, path to progress.
Read: All the president’s lies about the coronavirus
The “structuralists,” represented by Senators Bernie Sanders and Elizabeth Warren, had a very different reading. They argued that Trump wasn’t the problem or the cause. Rather, he was the symptom of long-standing inequities and injustices in the economic and political system. The way to handle Trump was to address the structures that made someone like him possible in the first place. This was why Biden seemed, to skeptics such as myself and to the American left more generally, a weak candidate, but more important a weak would-be president. He seemed completely unsuited for any deeper reckoning with where we had ended up and why. Why should we merely return to normal, if normal is what gave us Trump? Normal wasn’t good enough.
Then the virus came. The sense of possibility that came with a supposedly radical candidate seems today like an artifact of another world—one we no longer live in. Even before the social distancing, self-quarantines, and lockdowns, the perpetual crisis that characterized Trump’s governing style had already produced starkly different reactions among Democrats. This is what crisis does: It can make people demand revolution, or it can make them long for stability. A significant number of voters—in particular African Americans—found in Joe Biden welcome reassurance, and they saw him as the safest bet to remove their most proximate sense of threat. That longing for safety and security has now been magnified for many more Americans. (As Ross Douthat of The New York Times recently wrote, the pandemic will alter our memory of the Democratic primary. As history will remember it, many years from now, Sanders will have lost agency, having been “vanquished by an act of God”).
One can take only so much crisis before the desire for vaguely normal lives and vaguely competent leaders takes hold. We should have realized how lucky we were to work from an office (working from home is overrated), to go out with friends to a favorite restaurant, to be among the people we cared about, and to be reassured that our leaders, however flawed, had our best interests at heart. Deprived of those things, the baseline of expectations could only change, at least in the short run.
I, for one, have changed. I am more willing to accept “mere” normalcy today than I was just a month ago. Some of this has to do with the idiosyncrasies of individual personalities and how each of us copes with crisis. I’m too tired and too afraid to believe in the promise of politics right now. What I do feel, instead, is the smallness of politics. Some of the biggest controversies of recent years seem almost silly in retrospect—and certainly in comparison. “Ultimately, Brexit is not a matter of life or death, literally or economically,” Tom McTague recently wrote in The Atlantic. Indeed, more of Britain’s wealth and savings have been wiped out in a month than Brexit might have erased in a year (or five). Meanwhile, the Trump impeachment trial is all but forgotten. The killing in January of the Iranian military commander Qassem Soleimani brought with it the unfounded panic of impending regional war, or worse. And, technically, the Democratic primary is still going on, but it has receded to a faint background murmur.
Read: Red and blue America aren’t experiencing the same pandemic
To be struck by the relative irrelevance of political and ideological combat—however much I otherwise enjoy it—is to be tempted to retreat into the personal and private. In a state of semi-isolation, I want to read more, cook more, meditate more, pray more, and think more. For those who believed in Bernie Sanders and how he might have otherwise changed American politics, there is also mourning, which can bring a perverse pleasure, feeding what the writer Sam Adler-Bell calls a “bitterly hopeful disposition.” He writes, “Conditioned by history to expect defeat—to see it as inevitable, the product of malevolent forces beyond our control—we welcome its arrival with something like relief.”
The left-wing retort of “don’t mourn, organize!” at least attempts to take the melancholy of defeat and make it into something productive and affirming. But, today, the option of organizing isn’t as readily available, not just in physical terms but in psychological ones. It is harder to build something new when you feel suspended in time and place, waiting for the after of a pandemic to arrive.
So, then, what happens whenever after comes? Since an event like this hasn’t happened before in our lifetimes, the speculation is wild, and it covers an overwhelming range of possibilities. The left-wing hope is that the pandemic will demonstrate the need for national and universal healthcare. Some on the right see the crisis as further fueling distrust of institutions, authorities, and elites, redounding as it often does to the benefit of populists. For nationalists, the virus offers up a reminder of the virtues of hunkering down, fearing foreigners and travel, and railing against globalization and the intertwining supply chains that sustain it. In a piece titled “We’re All Orbán Now,” referring to the controversial Hungarian prime minister, National Review’s Rich Lowry writes, “This crisis is bringing home that, when push comes to shove, everyone believes in borders.” Meanwhile, a corner of the anti-globalization right believes that this is the right moment, finally, to resuscitate the idea of autarky, or economic self-sufficiency.
Related to this is the question of whether the mounting deaths from the virus will bring us together or tear us apart. Which “authentic” version of ourselves will it reveal—the selfish or the sacrificing? The history of pandemics isn’t encouraging. As the author Ben Judah pointed out on Twitter, “The Black Death led to a terrifying spike in antisemitism and pogroms with Jews being accused of poisoning the wells, being immune, or having bought down the wrath of heaven.” In A Journal of the Plague Year, Daniel Defoe writes of the plague descending on London in the 17th century: “But, alas! This was a time when every one’s private safety lay so near them that they had no room to pity the distresses of others; for every one had death, as it were, at his door.” More recently, during the Spanish-flu pandemic of 1918–20, more than 650,000 Americans died, yet, as the New York Times columnist David Brooks notes, “When it was over, people didn’t talk about it. There were very few books or plays written about it … Perhaps it’s because people didn’t like who they had become.”
Who will we become?
Western democracies—including the United States—are fundamentally different from what they were a century ago. They are more democratic, and we as citizens are more equal. We are less siloed and more aware of what other regions and communities are dealing with. In relative terms, we have better social safety nets and stronger, more interventionist states than those that had to contend with the Spanish flu. If the death tolls were higher, resembling the literal apocalypse, these anchors would likely begin to collapse, forcing citizens to prioritize survival of themselves and their loved ones, the collective be damned. But short of that, it means that the safety of the individual depends on the safety of the community—and ultimately the nation.
Read: How the coronavirus became an American catastrophe
In Game of Thrones, the character Beric Dondarrion grandiosely intoned, “Death is the enemy. The first enemy and the last.” Americans will be looking for an enemy, so this sentiment might prove appropriate. If the sheer scope of the threat—akin to a war or a foreign invasion—creates a collective sense of fear and anxiety and urgency, then the partisanship and ideological divisions that previously defined who we were (and who we weren’t) will be blunted to some degree. For example, if it means saving our economy and preventing the collapse of health-care infrastructure, then Republicans, whatever their ideological premises, will do things they otherwise wouldn’t do—such as the sort of aggressive economic stimulus normally associated with the left or something that sounds a lot like universal basic income. They already are. For the left, though, this is less a victory than a co-optation. And knowing what we know about wartime—and real threats, rather than imagined ones—more voters may be willing to rally around the flag and give Trump the benefit of the doubt.
As the journalist Ezra Klein, in the pre-coronavirus age, lamented and feared, external threats are often what unify Americans. If Americans come together, as I pray we will, we will need to understand that, yes, our government made mistakes. Trump’s initial handling of the virus was a master class in incompetence and deflection, and voters will have the opportunity to punish him at the ballot box. But one’s view of Trump is no longer the primary dividing line in our politics.
If a pandemic is akin to a war, then nationalism and the solidarity that national feeling brings could prove to be positive by-products. If we are under attack, it’s only natural that we would feel more strongly about who we are. This is an ideological, rather than an ethnic, “nationalism.” There is still the risk that these sentiments, particularly in the hands of xenophobes, will turn darker. If that happens, the rest of us will need to stay vigilant and resist the temptations of misdirected anger.
For now, though, we can take solace that the enemy is not one another. Other Americans are no longer the threat, and, in fact, they never were. Those are the smaller divides of American politics. We will have the ability to return to them in due time, and perhaps that will be part of the normalcy we are already craving. For now, though, it is worth remembering the concentric circles of attachment and allegiance that are the most important: family, friends, community, and, perhaps less fashionable, the nation. In what for many of us may be the closest thing we ever experience to a war zone, these are the things I—and I hope we—hold dear.
Shadi Hamid is a contributing writer at The Atlantic, a senior fellow at the Brookings Institution, and assistant research professor of Islamic studies at Fuller Seminary. He is also the co-founder of Wisdom of Crowds, a podcast, newsletter, and debate platform. Hamid is the author of several books, including Islamic Exceptionalism and Temptations of Power.
"
China Is Avoiding Blame by Trolling the World,3-19-2020,"The evidence of China’s deliberate cover-up of the coronavirus outbreak in Wuhan is a matter of public record. In suppressing information about the virus, doing little to contain it, and allowing it to spread unchecked in the crucial early days and weeks, the regime imperiled not only its own country and its own citizens but also the more than 100 nations now facing their own potentially devastating outbreaks. More perniciously, the Chinese government censored and detained those brave doctors and whistleblowers who attempted to sound the alarm and warn their fellow citizens when they understood the gravity of what was to come.
Read: We were warned
Some American commentators and Democratic politicians are aghast at Donald Trump and Republicans for referring to the pandemic as the “Wuhan virus” and repeatedly pointing to China as the source of the pandemic. In naming the disease COVID-19, the World Health Organization specifically avoided mentioning Wuhan. Yet in de-emphasizing where the epidemic began (something China has been aggressively pushing for), we run the risk of obscuring Beijing’s role in letting the disease spread beyond its borders.
China has a history of mishandling outbreaks, including SARS in 2002 and 2003. But Chinese leaders’ negligence in December and January—for well over a month after the first outbreak in Wuhan—far surpasses those bungled responses. The end of last year was the time for authorities to act, and, as Nicholas D. Kristof of The New York Times has noted, “act decisively they did—not against the virus, but against whistle-blowers who were trying to call attention to the public health threat.”
This is what allowed the virus to spread across the globe. Because the Chinese Communist Party was pretending that there was little to be concerned about, Wuhan was a porous purveyor of the virus. The government only instituted a lockdown in Wuhan on January 23—seven weeks after the virus first appeared. As events in Italy, the United States, Spain, and France have shown, quite a lot can happen in a week, much less seven. By then, mayor Zhou Xianwang admitted that more than 5 million people had already left Wuhan.
If that weren’t enough, we can plumb recent history for an even more damning account. In a 2019 article, Chinese experts warned it was “highly likely that future SARS- or MERS-like coronavirus outbreaks will originate from bats, and there is an increased probability that this will occur in China.” In a 2007 journal article, infectious-disease specialists published a study arguing that “the presence of a large reservoir of SARS-CoV-like viruses in horseshoe bats, together with the culture of eating exotic mammals in southern China, is a time bomb. The possibility of the reemergence of SARS and other novel viruses from animals or laboratories and therefore the need for preparedness should not be ignored.” It was ignored.
The political scientist Andrew Michta has drawn controversy and accusations of racism for stating what any measured overview of the evidence makes clear. “The question about assigning agency and blame is pretty straightforward to answer,” he writes in The American Interest. The Chinese state, he says, is culpable.
But is this a time for blame? Yes, it is. Accounting for responsibility when a disaster happens—particularly one likely to devastate entire countries, leaving thousands dead—is not beside the point, particularly as Chinese officials move to take advantage of the crisis and launch a disinformation campaign claiming that the U.S. Army introduced the virus.
Well before the new coronavirus spread across American cities, the Chinese regime was already rather creatively trolling U.S. publications, expelling American journalists, and “weaponizing wokeness” over anything it perceived as critical of China’s role in mishandling the epidemic. To hear Chinese spokespeople use the language of racism and prejudice is somewhat surreal, considering this is a regime that has put more than 1 million Muslims and ethnic minorities in “reeducation” camps.
Of course, Americans will have to be vigilant against scapegoating Asians in general or the Chinese people in particular. With one of the highest infection rates and death tolls, Chinese citizens have suffered enough. The Chinese leadership, however, is another matter. A government is not a race. It’s a regime—and easily one of the worst and most brutal in our lifetime. Criticizing authoritarian regimes for what they do outside their own borders and to their own people is simply calling things as they are. To do otherwise is to forgo analysis and accuracy in the name of assuaging a regime that deserves no such consideration.
Lizzie O’Leary: The modern supply chain is snapping
Those American critics who raise the racism canard are themselves inadvertently collapsing the distinctions between an authoritarian regime and those who live under it. Too many also seem comfortable drawing moral equivalencies between the Chinese regime and Donald Trump. This attitude is hard to take seriously. Trump didn’t block the media from reporting on the coronavirus; he did not disappear his critics. The nature of a regime matters. And this is why I, for one, am glad to live in a democracy, however flawed, in this time of unprecedented crisis.
After the crisis, whenever after is, the relationship with China cannot and should not go back to normal. Nothing, in any case, will go back to normal after the sheer scale of destruction becomes clear. Of course, the rest of the world will have to live with the Chinese leadership as long as it remains in power. But this pandemic should, finally, disabuse us of any remaining hope that the Chinese regime could be a responsible global actor. It is not, and it will not become one.
"
American Self-Criticism Borders on Narcissism,1-9-2020,"Those who said there will be war may not have realized there already was war. This doesn’t mean killing Iranian General Qassem Soleimani was good. It almost certainly wasn’t. Iran quickly retaliated by targeting two American military bases in Iraq and may find new ways to escalate, but Iran had already been escalating. The regime of the Syrian dictator Bashar al-Assad, with its Iranian patrons, led by Soleimani, has been waging a brutal assault on Syrians for more than eight years. War, in short, has been happening—costing hundreds of thousands of Syrian civilians their lives—since long before Donald Trump ordered the drone strike against Soleimani.
In the aftermath of the strike, critics of the Trump administration’s foreign policy, particularly on the left, have described the move as one more rash American intervention that’s sure to further destabilize the region. Yet this formulation gives U.S. policy, for all its flaws, too much credit. Not everything is America’s fault; others are sometimes to blame; and no one, not even the weaker parties, are devoid of agency or freed of responsibility. The burden of de-escalation does not fall entirely on the United States; Iran, too, can choose to de-escalate.
More by Shadi Hamid
An illustration of a raised fist overset with stamped outlines of viruses
The Coronavirus Killed the Revolution
Shadi Hamid
Xi Jinping at the School of Medicine at Tsinghua University in Beijing
China Is Avoiding Blame by Trolling the World
Shadi Hamid
President Donald Trump
Impeachment Could End Badly
Shadi Hamid
There is also the problem of Trump himself. Because killing Soleimani was very much his decision—reflecting the impulsiveness and disarray a decision by him implies—it seems fair to assume that one’s view of the president will affect how one interprets the fallout from Soleimani’s killing. Correcting for subconscious bias isn’t easy, but at the very least, observers should be aware of the Trump effect.
Middle East experts, and particularly those from the region, have tended to be less alarmist than most other commentators. These experts are likely to be less fixated on Trump himself and less likely to put the United States at the center of their analysis. And they are more likely to be aware of the sheer scale of brutality, mass murder, and sectarian cleansing that Soleimani helped orchestrate. Soleimani wasn’t just another bad guy. He was one of the region’s worst. (Yet another humanitarian catastrophe has been unfolding in Syria, but it has garnered little attention. The Assad regime, with crucial military support from Iran and Russia, has been bombing Idlib province. More than 200,000 Syrians have already fled, and hundreds of thousands more could be forced from their homes.)
It is not an overstatement to say that Qassem Soleimani “haunted” the Arab world. As Kim Ghattas wrote here in The Atlantic, “Soleimani was so central to almost every regional event in the past two decades that even people who hate him can’t believe he could die.” It is a rich irony that as Democrats portrayed the strike as one of the worst foreign-policy blunders of the Trump presidency, a significant number of Syrians and Iraqis rejoiced—one of the very few times they have reacted positively to something, anything, that the United States has done. Their interests, of course, are not the same as Americans’, but there should at the very least be an effort to understand why they might have celebrated.
[Read: Qassem Soleimani haunted the Arab world]
In trying to process and respond to Soleimani’s killing, the left finds itself in a bind, torn between two competing impulses. The first impulse combines an opposition to Western imperialism with a justified skepticism toward the use of U.S. military force. Human beings desire, or perhaps even need, moral clarity. Considering America’s destructive record in the Middle East, it is easy to assume that we are the problem, particularly when the resort to military action is buttressed by murky legal rationales. The second impulse is the left’s long-standing tradition of solidarity with the victims of repression and with populations rather than the regimes that subjugate them. In the unique context of Soleimani and the Iranian regime, this second concern comes into direct conflict with the first.
It’s impossible to resolve this tension, and the best one can hope for is that it be marshaled in the service of creative policy ideas. Still, too much of the analysis on the left seems to have erred on the side of anti-imperialist critique with insufficient attention to what Iran has actually been doing for years—at tremendous human cost to Syrians and to other civilian populations in the region. It is understandably difficult to view the Iranian regime as an aggressor when it has found itself in the sights of the world’s most powerful country, which has unparalleled military projection and the largest military budget of any state in human history.
America’s story in the Middle East is a tragic one, animated by a series of “original” sins. One can start history at the 2003 Iraq War, or one can begin earlier, with the first Bush administration encouraging Shias and Kurds to rise up en masse against Saddam Hussein after the Gulf War in 1991, only to turn its back on them as they marched toward Baghdad. Saddam remained in power, and as many as 100,000 Iraqis fell victim to reprisal killings, many of which “were committed in proximity to American troops, who were under orders not to intervene.”
Or one can look still further into the past. In Iran from the 1950s through the ’70s, the United States supported the brutal repression of dissenters by the shah, Mohammed Reza Pahlavi. He was “our S.O.B.,” to borrow Franklin D. Roosevelt’s famous description of a different American-backed authoritarian. But before that, in 1953, Americans helped organize the overthrow of the democratically elected prime minister, Mohammed Mossadegh, which facilitated the conditions for the shah’s bid for absolute control; the shah’s excesses, in turn, are what made the Iranian revolution possible.
Even good things, like the notion that the United States should back dictatorships less and promote democracy more, have been tainted in the eyes of the left (and, for that matter, the right) by the second Bush administration’s rhetorical embrace of democracy promotion and the “freedom agenda.” But this is where U.S.-centrism becomes a blind spot. Not everything is about us. And not everything is primarily a question of whether the United States is using military force. Not every new crisis is about repeating the blunders of the Iraq War. Syria most certainly isn’t, and wasn’t, Iraq, and thinking that it is had a distorting effect on the Obama’s administration’s policy, with tragic consequences.  
[David A. Graham: Trump is no closer to solving America’s Iran problem]
The United States has done terrible things in the Middle East. To even casual observers of the region, this should be clear enough. That, however, doesn’t mean there is a moral equivalence between Iran and the United States. Elevating America as a somehow unique source of evil takes necessary self-criticism and turns it into narcissism. It insists on making us the exceptional ones, glorifying ourselves by glorifying our sins. To suggest that American officials are at the rarefied level of the deliberate, systematic mass murder and sectarian cleansing that Soleimani helped orchestrate isn’t just wrong; it’s silly.
Despite the blood on his hands, 1 million or more Iranians publicly mourned Soleimani’s death. Some commentators took this as evidence that Iranians, despite their differences, were uniting in solidarity with their slain hero. Already, it appeared, the United States was losing. The large crowd sizes were an odd thing for critics of the Trump administration to highlight, though; in the absence of additional context, the mass mourning of a ruthless killer could only have the effect of making the Iranian people look bad. But demonstrations, particularly in a dictatorship, aren’t exactly an accurate bellwether of public sentiment (that’s what elections are for). Iran has a population of more than 80 million. That about 1 million were protesting tells us that some people revered Soleimani or at least felt some instinctual nationalist attachment to him, but it doesn’t tell us much more than that.
To focus on the perceived victims of American might and aggression—and many ordinary Iranians no doubt have suffered from punishing sanctions—runs the risk of imputing moral superiority to the mere act of resistance to the United States. But suffering, or to resisting, is not quite the same as being right. The Iranian regime, and Soleimani first and foremost, have long demonstrated that the weaker party does, in fact, have agency and that the powerless can use their power to destructive effect."
Impeachment Could End Badly,12-16-2020,"I don’t have the courage of my convictions. President Donald Trump deserves to be impeached for trying to pressure Ukraine to investigate his political opponents. With every week, he says or does something worse than what he already said or did. But to say Trump deserves impeachment is different from saying that impeachment is good for the country. It might, in fact, turn out quite badly.
Most of the people whom I like or trust believe—and believe rather strongly—that what Trump has done rises to a crime. For them, the analysis of whether Trump should be impeached can’t help but be informed by their view that Trump represents an existential threat to the country. If he might damage American democracy at some fundamental level, without any obvious recourse, then pursuing his removal from office would seem to go without saying. That he is in a position to win again in 2020 and serve another four years makes impeachment all the more urgent.
Yet if you believe, as I do, that Trump is bad, but also that his badness falls somewhat short of an existential threat, then impeachment, however justified in theory, becomes less straightforward. The process does not unfold in a political vacuum, and Democrats should not let the certainty of their legal reasoning push them toward impeachment without regard for its real-world consequences—which are uncertain and could prove costly. Impeachment also runs the risk of hijacking the debate in the Democratic primary, as well as further embittering Trump’s supporters and souring them on the democratic process.
More by Shadi Hamid
A man walks down a street holding an ISIS flag and a gun in Raqqa.
What America Never Understood About ISIS
Shadi Hamid
A boy whose family is seeking asylum
Europeans Don’t Necessarily Share American Values
Shadi Hamid
Mohamed Morsi in 2012
The Tragedy of Egypt's Mohamed Morsi
Shadi Hamid
Ultimately, the decision to impeach is a matter of judgment, not so much a question of whether Trump committed high crimes and misdemeanors (he almost certainly did) as whether invoking the Constitution’s impeachment provision right now is a good idea.
The now-infamous Ukraine quid pro quo might be obviously worse than what came before, but it is still only the latest in a long series of impeachable offenses. In April 2017, the American University professor Allan Lichtman published The Case for Impeachment, which made its case based on a “deep analysis of Trump’s past and proven behavior.” Considering that the book came in at 300 pages, presumably there was a lot of material (and that was just a few months into Trump’s term, before he had a chance to do much of anything as president). In a September 2017 review of books about impeachment, the law professor Noah Feldman and journalist Jacob Weisberg argued that Lichtman had overreached, but they identified other plausible reasons to impeach the 45th president. “What might constitutionally grounded articles of impeachment against Donald Trump look like? The most clear-cut one,” Feldman and Weisberg wrote, “would be based on public corruption, including conflicts of interest and receipt of foreign emoluments.”
[Read: Impeachment’s inevitability problem]
Every Democratic politician is asking—and should ask: Is impeachment at this moment a good idea politically, and, related but probably less important for politicians, is it a good idea for the country? Presumably, many of them decided finally that, with the Ukraine fiasco, it was a good, or at least an unavoidable, idea politically. To do nothing would be to shrug their shoulders in the face of one of the most corrupt presidents in modern history. Impeachment is, after all, in the Constitution, and if not now, when? A minority of House Democrats may have had doubts but had little choice to go along with it. This being a democracy, they have to be responsive to the people who actually voted for them, and the majority of Democrats support impeachment.
But will impeachment be good for Democrats in 2020 and beyond? On a purely tactical level, it is unlikely that any of this will erode Trump’s support. It has been more than two months since House Speaker Nancy Pelosi initiated the impeachment inquiry, on September 24, yet polling averages have remained as they have always been: immovable, a testament to the growing inelasticity of American politics. What parties or politicians do, or don’t do, has limited bearing on what people—most of whom have already made up their minds—think of them. When Trump made his notorious comment that he could shoot someone in the middle of Fifth Avenue and not lose any voters, he was describing a country in which his supporters’ views are perfectly inelastic.
Even if impeachment proceedings fail to change any minds, they will still have consequences on the overall dynamics of the 2020 election. For one, they threaten to consume public debate and pull the various Democratic candidates in the direction of endlessly commenting on or responding to Donald Trump. Whether this would be to Democrats’ benefit is debatable; focusing on what’s wrong with Trump at the expense of building an inspiring, affirmative case for the presidency didn’t quite work well last time around.
More substantively, a full-blown impeachment trial distracts Democrats from their natural strengths: channeling Americans’ anger against massive inequality and economic injustice and moving Americans toward what I’ve described as the “economics of meaning,” in which economic or class critiques are a means to focus anger, create meaning, and build solidarity. Joe Biden may have based his candidacy on not being Trump, but the other top-tier candidates—Bernie Sanders, Elizabeth Warren, and Pete Buttigieg—have all based their candidacies on something more than mere opposition to the incumbent. They have an interest in keeping it that way. As Ari Berman writes, “One of the biggest divides in the race for the Democratic presidential nomination is whether Donald Trump is a cause or a symptom of the current dysfunction in American politics.” To focus on impeachment, then, is to focus on the symptom.
Then there’s the question of whether impeachment is “good” on its own terms. It is nearly impossible to imagine how Trump could actually be convicted by the Senate and therefore removed from office, but this doesn’t change the fact that the ostensible goal of impeachment is to remove him—and to erase what, for many Democrats, has been since November 2016 an unacceptable reality. The desire to remove Trump from office cannot be separated from the decision to pursue impeachment, so it is worth considering, even as a thought exercise, what removal would actually mean.
[Mario Loyola: Democrats have failed to prove their case against Trump]
As I have argued elsewhere, the removal of Trump, however legally and constitutionally legitimate, would confirm the worst suspicions of his supporters: that their voices, in the end, wouldn’t be allowed to count. Their democratic and electoral agency would be denied. In Britain, there was a palpable anger among Brexiteers that what they’d won at the polls in the 2016 referendum would be taken away from them with calls for a do-over vote. Similarly, a sense of disenfranchisement would sour tens of millions of Americans on the democratic process—and on the idea of democracy. The perception that a legitimate electoral outcome was undone by those other than the voters themselves—in this case partisan actors and political elites—could inflict the very damage on the system’s democratic legitimacy that Democrats themselves have been warning against. Already, as the political theorist Nathan Pippenger writes, “public debate seems driven by an urge to deny the legitimacy of one’s ideological opponents.” How do we reduce—or at least not exacerbate—these “legitimacy” risks?
Some of these legitimacy risks, albeit on a (hopefully) more manageable level, would be present in either of two possible scenarios short of removal: impeachment without removal, followed by a Trump victory in 2020, or impeachment without removal, followed by a Trump defeat. A prolonged impeachment process, even if it has nothing to do with Trump’s loss, could taint an otherwise clean Democratic victory, particularly if the numbers are close. Some Republican voters will, of course, treat any Democratic victory as illegitimate, but there’s no reason to give them additional arguments to use in their favor. If Trump wins, he will be the first president to serve a new term after having been impeached the previous term. This would, in the minds of Democratic voters, make him seem even more illegitimate than he already was and further undermine their perceptions of the democratic process. Democrats will rightly ask how it is that their fellow Americans could reelect—after everything they know—a president both disgraced and impeached. In impeaching Trump, House Democrats are posing a question whose answer they do not want to hear.
And this is why I’m torn. Democrats had to do something. The president has been wrong and done wrong, and his misdeeds must be recorded somehow. There is something to be said for upholding basic constitutional principles, irrespective of outcome, especially when future scenarios can comfortably remain in the realm of the imagined. Or more fatalistically, as the Atlantic Council’s Faysal Itani put it: “Maybe sometimes you gotta do something even if it’s a bad idea.” Democrats have probably made the right choice. It’s just a choice Americans may have to pay for.
"
What America Never Understood About ISIS,10-31-2019,"The Islamic State indulged in some of the most ostentatious brutality and sadism of recent decades. If any extremist group deserves the adjective evil, this would be it. But it is precisely our disgust, which ISIS has well earned, that makes it difficult to talk about what the group was and what it meant—and what it may still mean.
The Washington Post was mocked for describing Abu Bakr al-Baghdadi as an “austere religious scholar” in the headline of its obituary after the ISIS chief was killed on October 27. (The headline was later changed.) Donald Trump Jr. tweeted that the Post and other mainstream outlets had “harsher criticism for the President of The United States than they do for the leader of ISIS, a known serial rapist and murderer.” He kind of had a point.
Similar criticisms were lobbed against Rukmini Callimachi and Falih Hassan, the authors of a New York Times story about Baghdadi’s death, for describing various government services that ISIS provided in the parts of Iraq and Syria that it once controlled. “The Islamic State collected taxes and saw to it that the garbage was picked up,” they wrote. “Couples who got married could expect to receive a marriage license printed on Islamic State stationery. Once children of those unions were born, their birth weight was duly recorded on an ISIS-issued birth certificate. The group even ran its own D.M.V.” Patrick Osgood, a researcher focusing on Iraq, said on Twitter that the Times story’s “emphasis is utterly wrong, privileging ISIS marginalia over a true reckoning of immense human cost—genocide, multiple massacres of 100s, 1,000s missing, ruinous war—of [Baghdadi’s] fetid ambition.”
Graeme Wood: What ISIS really wants
The concern is understandable. Perhaps talking about ISIS in terms of how it governed rather than how many it killed might provide it with a sheen of legitimacy after the fall of the group’s so-called caliphate. But those wishing to focus almost entirely on the Islamic State’s awfulness—to the exclusion of what made it successful—are falling into an analytical trap. After all, most Americans are presumably already aware that ISIS was a terrorist organization that did terrible things, so it’s not as if highlighting ISIS’s savagery, sex slavery, and killing of innocents fills an important gap in the public discourse. (Anyone unaware of this horrifying record is unlikely to be a reader of The Washington Post or The New York Times in the first place.) But, more important, one can recognize the extent of ISIS’s brutality while also dispassionately discussing its relative effectiveness in certain aspects of governing. The bar for what counts as good governance in Iraq and Syria is quite low.
In 2015, at the height of the group’s savagery, academics and experts did considerable work on how ISIS administered the areas it ruled. The logic was simple: The only way to prevent similar groups from emerging in the future was to understand what made ISIS distinctive. ISIS didn’t come out of nowhere. There were reasons it was able to capture as much territory as it did. And the “marginalia” of governance was part of that story. This can be a blind spot. Western observers assume that brutal groups are bad at governing. This is true sometimes, but the opposite can also be true: The more brutal groups are better at it than the less brutal ones. As Yale’s Mara Revkin explained in perhaps the definitive account of how ISIS governed:
Media coverage of the Islamic State frequently refers to the group’s violent and seemingly archaic justice system without considering the institutional structures that enable this violence, or the broader function that it serves in the group’s ambitious state-building project. Legal institutions make it easier for the group to capture and retain territory by legitimizing its claim to sovereignty, justifying the expropriation of the property and land of enemies, and building goodwill with civilians by ensuring accountability.
The notion that we should call ISIS the worst names we can muster and leave it at that is to set ourselves up for future failure. And that is worth worrying about, since there will be attempts to replicate ISIS’s governance model in the coming decades—even if that seems unlikely in the aftermath of the group’s recent defeats. But we don’t even need to wait. Right in front of us, as we speak, is an example of an extremist group—the Taliban—that effectively mixes brutality and “good (enough) governance” in Afghanistan.
If ISIS were merely a bunch of crazies and thugs going around killing people, it would have been easier to defeat. Its fighters wouldn’t have been able to march through large swaths of Iraq and Syria, handily defeat U.S.-trained security forces, and enjoy, at least in the beginning, the acquiescence and even support of segments of the local population. How was ISIS able to do this?
Unlike most terrorist groups, ISIS had a distinctive interest in state-building, an interest reflected in the group’s propaganda. One 2015 study found that about 45 percent of ISIS media outreach focused on building and sustaining the caliphate, with messaging on “traffic police, charity work, judicial systems, hospitals and agricultural projects.” At the time, there was little to suggest that this would be sustainable. As Will McCants, author of The ISIS Apocalypse, once described it to me, “The caliphate may require caution, but the apocalypse requires abandon.” And, indeed, today the caliphate no longer exists. But it did exist.
Graeme Wood: Baghdadi’s final humiliation
Before anything else, a state—or an organization that wishes to approximate a state—must be able to provide some degree of law and order. Without order, there cannot be law, and ISIS’s project was very much about law. ISIS got its biggest break with the collapse of governmental authority in Syria and Iraq in the post–Arab Spring period. The extremist group could do what discredited governments couldn’t: provide Syrians and Iraqis with a degree of security, which is what they came to crave the most. A Syrian in, say, Raqqa—which had been ISIS’s de facto capital—might have detested the group’s ideology but still supported its rule over the alternatives, because having some security was preferable to having none.
Here, oddly enough, ISIS’s absolutism was a feature rather than a bug. Terror and state-building went hand in hand. After a country collapses and descends into warring factions and rampant criminal activity, any group that hopes to reconstitute order must assume a monopoly over the use of force. This means defeating any pretenders to the throne. In an already brutal war zone, brutality can, unfortunately, work. Instilling terror in the hearts of your opponents undermines their morale, making them more likely to stand down, flee, or surrender on the battlefield.
Once territory is captured, what comes next? More challenging is channeling the focused brutality of battle into actual governing. Yet, in fairly quick order, with the international community paying little attention, ISIS began setting up well-developed institutional structures. The elaborate legal structures—oriented around interlocking Sharia courts, binding fatwas, and detailed tax codes—reflected a serious effort to institutionalize a new order, in what Revkin and the political scientist Andrew March term “scrupulous legality.”
With this in mind, it becomes somewhat easier to understand how some residents—in a region that has long lacked law, order, and government services—might have gone along with or at least remained neutral toward ISIS rule. In Iraq, Sunni populations had found themselves marginalized or worse. In Syria, civilians routinely suffered atrocities under Bashar al-Assad’s dictatorship, which, in terms of the sheer human toll, was more brutal and destructive than ISIS ever could have hoped to be. By that standard, ISIS rule may have seemed like an improvement. Of course, it would be a mistake to overstate the level of governance that ISIS actually provided. It didn’t practice good governance so much as as less bad governance, and that can be good enough. As long as you’re able to present yourself as a somewhat better alternative to absolute chaos or sectarian repression, then you can hold on to power—not necessarily in spite of brutality but because of it.
It matters that many people prefer cruel governance to no governance, and, whether we like it or not, it will always matter in places where governments are weak and lack legitimacy. The Taliban seemed defeated after the initially successful U.S.-led invasion in Afghanistan in 2001. That status didn’t last. In the mid-2000s, under President Hamid Karzai, and with corruption and governance failures mounting, the Taliban moved to fill the gap by providing free mediation of tribal and criminal disputes. Afghans soon reported surprising levels of satisfaction with Taliban verdicts in local courts, as my Brookings Institution colleague Vanda Felbab-Brown has detailed in her fieldwork in Afghanistan, and as a leaked report of interviews of Afghans detained by the U.S. military in Bagram also documented.
In his remarks on the death of al-Baghdadi, President Donald Trump, drawing a contrast with his predecessor, used language with the apparent aim of sounding tough. He referred to ISIS fighters as “frightened puppies.” Trump noted that “we obliterated his caliphate, 100 percent, in March of this year. Today’s events are another reminder that we will continue to pursue the remaining ISIS terrorists to their brutal end.” But Trump has said almost nothing about how he envisions preventing ISIS-like groups from emerging in the future. This would require more than bravado. In this respect, Trump’s vision for fighting terror, to the extent he has one, is weak and incoherent.
In fairness, Trump is building on President Barack Obama’s “counterterrorism first” policy, in which terrorism was dealt with in a void—as if groups like ISIS or al-Qaeda fall from the sky, out of place and out of time. But they are very much products of their context. This should be obvious enough: The two countries where ISIS gained the most territory were the two countries most plagued by civil war and governance vacuums. What if the true cause of instability in the Middle East is precisely the absence of legitimate authority, a problem the Trump administration seems to have little interest in talking about?
Read: Trump’s gift to ISIS
As the Middle East analyst Kenneth M. Pollack has written, emphasizing counterterrorism “as a goal of foreign policy” gets something rather fundamentally wrong about, well, counterterrorism. The emergence and growth of terrorist groups in particular places at particular times is a product of other factors, and those other factors will have to be addressed at some point. You cannot fight terrorism just by fighting terrorism, and to think that you can is an illusion that has long hobbled U.S. policy in the Middle East and South Asia.
The irony is that Americans’ willingness to think seriously about the sources of ISIS’s appeal seems to erode as the group and its now-deceased leader recede into memory. One might hope the opposite would occur—that with critical distance from the events themselves, we might be better able to assess what went wrong the last time around. The killing of Baghdadi is no doubt a success, but self-congratulation will take us only so far—and not nearly far enough.
"
Europeans Don’t Necessarily Share American Values,8-1-2019,"Culture matters—and it matters quite a lot. This is the recurring theme within the new movement of “national conservatives” attempting to reshape the American right. One of their most controversial thinkers is the University of Pennsylvania law professor Amy Wax, who recently drew controversy by saying the United States should consider “cultural distance” in deciding which immigrants to admit or reject.
The premise, as Wax put it during the inaugural national conservatism conference earlier this month, is that “many, indeed most, inhabitants of the Third World don’t necessarily share our ideas and beliefs; others pay lip service, but don’t really comprehend them. There are exceptions, of course, but most people are not exceptional.” Based on that premise, she concludes that “embracing cultural distance, cultural-distance nationalism, means, in effect, taking the position that our country will be better off with more whites and fewer nonwhites. Well, that is the result anyway.”
Yet Wax is making a major assumption: that people from European countries hold the same “ideas and beliefs” Americans do. When President Donald Trump states a preference for Norwegian immigrants over those from developing countries, he is—by a very charitable reading of his remarks—presuming the same thing. Yet there are two basic problems with this assumption: First, Americans don’t even agree on what American culture is. Second, the United States and European democracies have historically defined their national cultures in rather different ways.
More by Shadi Hamid
President Donald Trump
Impeachment Could End Badly
Shadi Hamid
A man walks down a street holding an ISIS flag and a gun in Raqqa.
What America Never Understood About ISIS
Shadi Hamid
Mohamed Morsi in 2012
The Tragedy of Egypt's Mohamed Morsi
Shadi Hamid
Since Wax’s remarks became public, other conservatives have defended her against accusations of prejudice. Yet the debate over whether what she said technically qualifies as racist obscures the bigger issue: What she said was incoherent, even on its own terms.
In European democracies, the idea that immigration presents unique challenges for cultural solidarity has the attraction of being somewhat coherent. There is something called “Danish culture” or “Dutch culture” that cuts across partisan divides and that mainstream center-left and center-right parties accept as broadly representative. This usually involves some commitment to liberal ideals such as gender equality, sexual freedom, and a neutral or “rational” public space. Accordingly, right-wing populist parties—and mainstream parties to various degrees—ask recent or prospective immigrants to accept, and even embrace, this national culture. Restrictionists in western Europe have, for instance, portrayed Muslim immigrants as hostile to gay people and sought, in the name of women’s rights, to limit a woman’s right to wear the head scarf. This aggressive, sometimes even coercive, insistence on liberal values leads right-wing populists to adopt illiberal positions—a sort of illiberal liberalism.
In the United States, conservatives see a liberal political order—privileging nonnegotiable rights, personal freedom, and individual choice—as a threat to a historically imagined culture that no longer exists. If anything, the only consensus is that there is a lack of consensus over how to define the American creed. This complicates any new approach to immigration: In the absence of a shared understanding of American culture, whose conception of it would we privilege?
Many national conservatives are either illiberal or anti-liberal. If the United States is a liberal country—in the classical sense of elevating a liberal constitutional tradition—then should we make it more difficult for supporters of right-wing populist parties, such as Italy’s League or Austria’s Freedom Party, to immigrate to the United States? Across Europe, whites, being an ethnic majority, are more likely than nonwhites to hold to an ethnonationalist conception of the state. Accordingly, under a “cultural distance” immigration regime of the sort that Wax proposes, a Democrat could reasonably argue that white Europeans are more likely to believe in things that are contrary to American ideals. One of those ideals is unrestricted birthright citizenship, which is enshrined in the Constitution and, I would argue, is central to Americanness and the American idea. If a white European says he or she doesn’t support birthright citizenship—not a single European country currently has birthright citizenship—should that affect his or her chances of immigrating to the United States? Perhaps.
The irony is that even supporters of Donald Trump would acknowledge that he is somewhat outside American cultural norms. For many, his flouting of norms and traditions is crucial to his appeal. (For opponents such as myself, it is perhaps his only appeal.) He is not like most of the Americans they know. Conservatives stress the importance of cultural cohesion, and pluralism, taken to extremes, can in fact undermine trust and produce civil conflict. But if a hypothetical white Swedish male with Trump’s exact views on Islam (“I think Islam hates us”), the internment of Japanese Americans, and sending minority congresswomen “back,” then that person would be more of a threat to U.S. cultural cohesion than, say, a nonwhite Ghanaian with views closer to those of Representative Alexandria Ocasio-Cortez. Or, to put a finer point on it, if Trump himself tried to (legally) immigrate to the United States, an immigration policy prioritizing culture—or, at least, what is currently the dominant culture—would probably have to reject his application.
In a recent paper, Amy Wax favorably cites the late Samuel Huntington’s book Who Are We?, a sort of founding text for nationalist conservatives, but one that was pilloried upon its release in 2004. In Culture Matters, a volume that he co-edited, Huntington defines culture “in purely subjective terms as the values, attitudes, beliefs, orientations, and underlying assumptions prevalent among people in a society.” Culture is subjective, which is part of the problem. We know cultures change, but less exactly how they change. Americans still do agree that Americanness is important. But they no longer agree, if they ever did, on what American culture or the American idea entails. This makes it difficult, if not impossible, to measure any potential immigrant’s “cultural distance.” We cannot be a “who we are” nation if we don’t agree on who we are."
The Tragedy of Egypt's Mohamed Morsi,6-18-2019,"Mohamed Morsi’s life, especially his later life, was the product of a series of accidents. When I first met him, he was a senior but relatively obscure and not particularly important official in the Muslim Brotherhood—and one could easily imagine him staying that way. He was a loyalist, a functionary, and an enforcer. Then he became something else: Egypt’s first democratically elected president—and also the last, at least for the foreseeable future. Visionary leaders sometimes emerge during moments of crisis and transition. But just as often, ordinary men and women find themselves in the midst of historical events, both shaping them and being shaped by them.  
Morsi, who died in a Cairo courtroom Monday, was elected in 2012 and deposed in a military coup a year later. He was many, but not all, of the things his critics derided him for. He wasn’t what you would call charismatic. He was not a strategic thinker. He seemed a man particularly unsuited for the responsibility bestowed upon him. In retrospect, knowing what they know now, many in the Brotherhood—in prison, in exile, in hiding—would wish that the organization’s leadership had never opted to field a presidential candidate. But this had little to do with Morsi. Morsi wasn’t meant to be president.
Recommended Reading
An illustration of a classroom and Black Lives Matter sign.
‘The Narrative Is, “You Can’t Get Ahead”’
Conor Friedersdorf
Black and white photo of Matt Gaetz
Only Congress Could Give Us a Matt Gaetz
David A. Graham
An illustration of web browser windows spelling out ""lies.""
Scale Was the God That Failed
Josh Marshall
The Brotherhood’s original candidate for president was the businessman Khairat al-Shater, towering in his physical presence, preternaturally confident, and perhaps overwhelmed by ambition. Some called him Egypt’s most powerful man. He was disqualified from running based on a legal technicality. Like so many other things, this, for the group, seemed to confirm that the military sought to block the Brotherhood’s rise by any means necessary. And so Morsi, derided in the Egyptian media as Shater’s “spare tire,” became the accidental candidate and then the accidental president.  
[Read: Egypt’s only democratic leader helped kill its democracy]
When I sat down with Morsi back in May 2010, the longtime dictator Hosni Mubarak was still in office, and the kind of uprising that could force him out seemed implausible. At that point, Morsi insisted the Brotherhood had no interest in power and even objected to the use of the word opposition to describe the group. Repression was intensifying, and political space was closing years after the brief promise of the (first) Arab Spring in 2004 and 2005. The November 2010 parliamentary elections were arguably the most fraudulent in the country’s history, reducing the Brotherhood from 88 seats to 0. Members of the Muslim Brotherhood seemed deflated but not necessarily in despair. They were playing the long game, which is what the Brotherhood always preferred to play. To be tempted by power, on the other hand, led them, and ultimately Morsi himself, into a series of missteps and miscalculations.
The campaign for president in the spring of 2012 took place in a chaotic, uncertain Egypt. Though burdened by a weak candidate, and with only two months to campaign, Brotherhood activists fanned across the country, promoting Morsi’s so-called renaissance project (which had been Shater’s “renaissance project”). In one coordinated show of strength, they held 24 simultaneous mass rallies across the country in a single day. At one rally, I asked a young Brotherhood activist if he was enthusiastic about Morsi. He smiled and then laughed.
It was easy to dismiss Morsi then, and it will be easy to dismiss him now, as a footnote in history. Buried without fanfare and under the glare of a near-totalitarian state—the most repressive in Egypt’s history—he will be easy to forget. But the brief 12 months in which he found himself in power was an unusual time for Egypt. Morsi was incompetent and polarizing, and managed to alienate nearly everyone outside the Brotherhood. Ultimately, he and the Muslim Brotherhood failed. But he was not a fascist or a new pharaoh, as his opponents liked to claim. In a previous piece for The Atlantic, a colleague and I scored Morsi’s one year in power using the Polity IV index, one of the most widely used empirical measures of autocracy and democracy, and then compared it to other cases. We concluded that “decades of transitions show that Morsi, while inept and majoritarian, was no more autocratic than a typical transitional leader and was more democratic than other leaders during societal transitions.”
But to keep the focus narrowly on Morsi, as a person or as a president, is to miss something important, and that something has become clearer to me in the five years since we wrote that piece. That year may have witnessed unprecedented polarization, fear, and uncertainty, but for that time Egypt was the freest, in relative terms, that it had been since its independence in 1952. Egyptians were shouting, protesting, striking, and hoping, both for and against Morsi. This, of course, is also what made the year frightening: the freewheeling intellectual combat, the seemingly endless sparring of ideas and individuals, but also the sheer sense of openness (and the insecurity that came with it). No other period, or even year, comes close. This was not because of Morsi, but because Egypt—with the help of millions of Egyptians—was trying to become a democracy, albeit a flawed one. And Morsi himself, also deeply flawed, was a product of that brief experiment. To remember Morsi, then, is to remember what was lost.
"
The Israeli-Palestinian Dispute Is Only Partly About Land,5-25-2019,"Is the Israeli-Palestinian conflict fundamentally about land and territory? It is certainly partly about that. But when you hear the objections and grievances of both sides, the issue of who has what part of which territory doesn’t necessarily figure all that prominently.
I recently took part in a study tour on religion and nationalism in Israel and the West Bank organized by the Philos Project. One Palestinian official whom we met told us, “I’m not going to compromise my dignity.”
The problem with what we know of the Trump administration’s “peace plan” is that it asks Palestinians to do precisely that. The entire Donald Trump approach seems to be premised on calling for unilateral surrender. It is premised on destroying the will of a people, and on hoping that despair might one day turn into acquiescence. This is the only way to interpret Trump’s senior adviser and son-in-law Jared Kushner’s insistence on prioritizing economic incentives over political progress, but this misunderstands most of what we know about human motivation.
I have a bias: I don’t tend to think that people are primarily motivated by measurable, quantifiable things. To the extent that territory becomes a seemingly insurmountable obstacle, it matters, but it matters as a proxy for other, deeper issues. As my Brookings Institution colleague Shibley Telhami put it: “To assume that the promise of economic improvement would outweigh ordinary human aspirations of a people who have painfully struggled for decades is to miss the nature of the human condition.”
Recommended Reading
An illustration of a classroom and Black Lives Matter sign.
‘The Narrative Is, “You Can’t Get Ahead”’
Conor Friedersdorf
Black and white photo of Matt Gaetz
Only Congress Could Give Us a Matt Gaetz
David A. Graham
An illustration of web browser windows spelling out ""lies.""
Scale Was the God That Failed
Josh Marshall
Our Palestinian interlocutor’s refusal to cede his dignity wasn’t a performance; it was despair. It felt to me like an epitaph. There have been conflicts in which leaders have made compromises that may have seemed like betrayals, only for history to view them as both bold and necessary. But those conflicts are not this conflict.
[Micah Goodman: Eight steps to shrink the Israeli-Palestinian conflict]
The Israelis’ narrative is quite different from the Palestinians’, and on its own terms, it’s not necessarily wrong. According to this perspective, Arabs, from the founding of Israel in 1948 onward, have either longed for the Jewish state to disappear or taken action to actually make it disappear. This relates to the Israeli refrain that there is no Palestinian partner for peace; the most moderate Palestinians may accept Israel’s existence as an unfortunate fact, this argument goes, but not even they believe in Israel’s right to exist as the national homeland for the Jewish people.
In their long history together, Muslims knew Jews less as an ethnic group than as adherents of another religion, different from Islam but also like it. In The Jews of Islam, Bernard Lewis noted that when Muslims expressed negative attitudes toward Jews, they were “usually expressed in religious and social terms, very rarely in ethnic or racial terms.” In conversation, many Palestinians express discomfort with the idea that Jews are both a people and a religion, and Israeli Jews tend to view this lack of recognition as sinister and evidence of Arab irreconcilability.
Many of the early Zionists were secular, so their vision for a State of Israel did not depend on a shared religious faith. It depended, instead, on being a people. The moniker “Jewish state” itself captures this, since a Jewish state can be a secular home for Jews, whereas an “Islamic state”—to use another legalistic religion—suggests a religious mission and theological premises.
Divergent histories and narratives shape the interpretation of otherwise factual questions about what actually happened and didn’t happen at key moments. For example, Israeli politicians attack Palestinians for squandering Prime Minister Ehud Barak’s “generous offer” of 2000, and so a story of Arab and Palestinian recalcitrance builds uninterrupted, with each new rejection confirming the previous one: First, Arabs rejected the 1947 United Nations partition plan. Then Arab nations waged war against the new Israeli state. Decades later, when they finally had their chance, Palestinians rejected Barak’s offer. Then they rejected Prime Minister Ehud Olmert’s offer, and so on.
[Einat Wilf: The fatal flaw that doomed the Oslo Accords]
To put it mildly, Palestinians do not share this interpretation of what went wrong. They believe the offer was far from generous, coming after six years of “more Israeli settlements, less freedom of movement, and worse economic conditions,” as the senior Clinton-administration adviser Rob Malley and Hussein Agha argue in one of the definitive accounts of the 2000 Camp David negotiations. In practice, Barak, the dove, wasn’t much of a dove. As Malley and Agha write: “Behind almost all of Barak’s moves, Arafat believed he could discern the objective of either forcing him to swallow an unconscionable deal or mobilizing the world to isolate and weaken the Palestinians if they refused to yield.”
Palestinian activists tend to speak in terms of justice. An injustice was done, so it must be undone. Christopher Hitchens, in his valediction for the Palestinian American author Edward Said, wrote that his friend’s “feeling for the injustice done to Palestine was, in the best sense of this overused term, a visceral one. He simply could not reconcile himself to the dispossession of a people or to the lies and evasions that were used to cover up this offense.”
Pro-Palestinian protesters often chant the mantra of “no justice, no peace.” One former Israeli official we spoke with in Jerusalem had a different view. He said, “If we make this about justice, there will not be peace.” Too many Palestinians celebrate victimhood—fueled by a profound sense of injustice—rather than overcome it, he suggested.
But then we return to the question of dignity. No one should be asked to overcome their victimhood by giving up their dignity, the one thing even an occupier shouldn’t be able to take away. That might sound naive and impractical, especially for those who would rather Palestinians just get on with it, but that doesn’t make it any less true.
If I were advising the Palestinians, I’d tell them to reject Kushner’s offer, but they don’t need anyone to tell them what’s already painfully obvious. If someone doesn’t understand anything about the history of the Palestinians, their grievances and their narratives, then what’s the point? The outgoing French ambassador to the United States, Gérard Araud, described Kushner this way: “He is so pro-Israeli also, that he may neglect the point that if you offer the Palestinians the choice between surrendering and committing suicide, they may decide the latter. Somebody like Kushner doesn’t understand that.”
Because the two sides are so far apart and are likely to remain so for the foreseeable future, the United States—if it’s unwilling to put serious pressure on Israel or take seriously Palestinian objections—is better off disengaging from an imaginary peace process, rather than lending legitimacy to Israel’s behavior or giving the illusion of progress without the substance. Otherwise we are all just wasting time, at least until a new president attempts to fundamentally rethink America’s sometimes well-intentioned but almost always tragic role in one of the world’s most enduring conflicts.
"
"The Fundamental Legitimacy of Donald Trump
",4-11-2019,"Special Counsel Robert Mueller’s inquiry into links between Russia and the president’s campaign could have turned out so much worse for Donald Trump. It almost seemed certain that it would. But it didn’t. The end of the Mueller investigation has now made hollow the maximalist charges of collusion against Trump and his team.
The collusion claim was an indirect—or direct—way of saying that Donald Trump was illegitimately elected. For Mueller’s team to stop short of concluding that collusion had occurred, then, was the best possible result for American democracy. Citizens should be relieved, not disappointed, when the legitimacy of election outcomes is strengthened, however much we dislike them.
Conspiracy with Russia wasn’t the only thing that commentators—both liberals and Never Trump conservatives—got wrong, though. There was another, related charge that was graver and, on its face, more implausible: that Trump would (or could) destroy American democracy. And he would do so with the help of his Russian enablers. Here, the two claims came together—that the Russians wished to end the American experiment and that Trump provided the vehicle for their ambitious designs.
This was part of a grand narrative. But what if the narrative of American democracy under mortal threat—with or without Russian help—was fundamentally flawed from the very start?
Grand narratives are appealing because they help us comprehend the incomprehensible. In this case, they helped to make sense of the endless shock of Donald Trump’s victory. The democracy-is-doomed narrative is crumbling, and rarely do you hear it anymore—at least not with the full-throated zeal that became routine throughout 2017 and 2018.
It began before that, during the campaign. As The New Yorker’s Adam Gopnik wrote: “Hitler’s enablers in 1933—yes, we should go there, instantly and often, not to blacken our political opponents but as a reminder that evil happens insidiously, and most often with people on the same side telling each other, Well, he’s not so bad, not as bad as they are. We can control him.” This sort of thing continued for more than two years.
On January 4, 2018, despite the helpful information that America hadn’t become a dictatorship in 2017, Vox’s Matt Yglesias wrote in an article titled “2018 Is the Year That Will Decide If Trumpocracy Replaces American Democracy” that “Trump has been extremely long on demagogic bluster but rather conventional—if extremely right-wing in some respects—on policy. But … this is entirely typical. Even Adolf Hitler was dismissed by many as a buffoon.”
Preemptively suggesting that your ideological opponents won’t accept the results of elections if they lose isn’t nearly as bad as, well, not accepting the results of elections, but it is still bad. In the case of the 2018 midterm elections, it also happened to be wrong. The New York Times columnist Paul Krugman wrote: “Remember, Donald Trump claimed—falsely, of course—that millions of immigrants voted illegally in an election he won. Imagine what he’ll say if he loses, and what his supporters will do in response.” Krugman went on, suggesting that those who voted for the other party were, in fact, voting for autocracy: “If we take one path, it will offer at least a chance for political redemption, for recovering America’s democratic values. If we take the other, we’ll be on the road to autocracy, with no obvious way to get off.”
[Read: America’s slide toward autocracy]
Claims such as these weren’t just overblown rhetoric from pundits in the heat of the electoral moment. They came with the imprimatur of some of the country’s most respected political scientists. Harvard University’s Steven Levitsky and Daniel Ziblatt published How Democracies Die in 2018, and the book became an alarmist bible (even though the book itself is more nuanced than its enthusiasts let on). In New York, Jonathan Chait wrote, “It is hard to read this fine book without coming away terribly concerned about the possibility Trump might inflict a mortal wound on the health of the republic.”
How could so many get it wrong? Underlying these various accounts of doom is a major analytical flaw. In some sense, the flaw is so obvious that I wasn’t entirely aware of it until I started thinking about this article. If we exclude cases of military conquest or occupation, as occurred during World War II, there is no clear case of a long-standing, established democracy becoming an autocracy. Democracies backslide—it is a spectrum, after all. But democracies, or at least certain kinds of democracies, do not “die.”
Germany is a touchstone for any conversation about the fragility of democracy. But Germany, when Adolf Hitler entered politics, was a young democracy, and the particular democratic configuration known as the Weimar Republic was even younger, having been established only in 1918. Young democracies are fragile. Moreover, Germany was suffering from historical afflictions that the United States—and, for that matter, most other countries—is not likely to experience again. In an essay for The American Interest, and also the subject of his forthcoming book Democratic Stability in an Age of Crisis, Jørgen Møller lays out the case in convincing detail. Germany, Austria, and Italy, he writes, were “bedeviled by the legacy of the World War,” which “created revanchist yearnings in all three countries, which could be harnessed by undemocratic forces on the Right that had, in the first place, been brutalized by four years of fighting in the trenches.”
It is always possible to extract generalizable lessons from historical events. But that is different from thinking that the 1930s were in any meaningful way comparable to our current political moment. Yet some leading academics are rather unapologetic in their analogizing. In the best-selling On Tyranny, written before Trump even took office, the Yale historian Timothy Snyder focuses on Hitler’s rise almost immediately, and he is explicit that Americans, in thinking about the future of their own country, have much to learn from the death of German democracy. “If we worry today that the American experiment is threatened by tyranny,” he argues, “we can follow the example of the Founding Fathers and contemplate the history of other democracies and republics. The good news is that we can draw on more recent and relevant examples than ancient Greece and Rome.”
But what exactly does the fall of Weimar Germany have to do with Donald Trump? If there had been a third world war in which hundreds of thousands of Americans had perished in humiliating defeat, then it might be more appropriate to bring up the Weimar Republic. Until then, the election of a president, Donald Trump, however uniquely bad, is simply not enough to justify rather dramatic chapter titles such as “Be Wary of Paramilitaries,” “Make Eye Contact and Small Talk,” “Be Reflective If You Must Be Armed,” and “Establish a Private Life.”
[Hillary Clinton: American democracy is in crisis]
Analogies are useful for understanding the people who use them to understand events, not necessarily for understanding the events themselves. As Richard Fontaine and Vance Serchuk of the Center for a New American Security note, “Parallels from the past too often are put forward less to focus debate and discussion than to shut them down. That’s exactly why the invocation of dates like 1938 or 2003 are such political catnip.” History, after all, does not repeat itself. Anything resembling World War I will not happen again, mostly because it can’t. Too many variables have changed. (The broader and, by now, somewhat banal lesson that “small, seemingly trivial events can have tremendous, catastrophic consequences” still applies, however.) The journalist Jonathan Chait acknowledges that “the concern of serious democracy scholars is not a totalitarian state that murders its opposition en masse. It is ‘democratic backsliding.’” If the concern is democratic backsliding, however, it is unclear why Hitler or 1933 would be a touchstone, since Hitler did, in fact, murder his opposition en masse.
To put it another way, that American politics feels existential (which the very use of the self-title “the Resistance” seems to imply) is different from saying that it actually is. Many, if not most, criticisms of Donald Trump revolve around norms and Trump’s propensity to break them or, more precisely, to act as if they never existed. Often the refrain is that Trump’s sins may not be illegal or unconstitutional, but that they violate the “normal” conduct of presidents and statesmen. They most certainly do, but this, by itself, isn’t necessarily anti-democratic. The legal scholar Jedediah Purdy puts it this way in his critique of the move toward norm fetishism:
One problem with identifying the protection of political norms with the defense of democracy is that such norms are intrinsically conservative (in a small-c sense) because they achieve stability by maintaining unspoken habits—which institutions you defer to, which policies you do not question, and so on.
That something happens to be a norm does not necessarily mean it is a good norm or that it is inherently democratic. Sometimes, writes the political scientist Corey Robin, “norm erosion is not antithetical to democracy but an ally of it.” If we think of democracies as constantly evolving—of needing to evolve at particular historical junctures—then rethinking the unspoken habits of political engagement and competition is simply a requirement of any truly progressive politics. All transformative figures are, by definition, norm breakers, whether that was the leaders of the civil-rights movement in the 1960s or abolitionists in the 1800s.
In a previous piece, I pointed to Representative Alexandria Ocasio-Cortez’s endorsement of a 70 percent marginal tax rate as an example of a “radical” proposal that, irrespective of its substantive policy content, is important because it expands the window of the politically possible and encourages politicians and voters alike to consider creative ideas outside the norm. This makes democracies more, not less, responsive to a broader range of ideas and proposals from voters and politicians alike, as democracies should be. The rise of right-wing populism in both the United States and nearly every major Western democracy is itself a product of the norm-centric and unimaginative center-left and center-right governing models that dominated in the 1990s and 2000s. A return to norms cannot be both the solution and the problem.
The strongest defense of alarmist politics and of fearing the worst—even in the absence of evidence that the worst is yet to come—is that it encourages the very constraints that prevent truly terrible outcomes. In this reading, the Russia investigation, even if it didn’t produce evidence of collusion, provided an important check on the Trump administration’s ability to do harm. Here, the fear of democracy dying motivates citizens to vote, to petition, and to organize.
[Read: How to build an autocracy]
This, though, is the job of activists and advocates who are, understandably, less interested in being accurate in their historical analogies and more interested in accomplishing specific political and partisan objectives. It is not the job of journalists, political scientists, or (especially) historians to take historical events and twist them beyond recognition. Even something as seemingly uncontroversial as the use of “the Resistance” to describe the anti-Trump opposition is odd when you think about it—unless, as the journalist Jamie Kirchick reminds us, you happen to be “burying weapons in the forests of Poland or hiding in the basements of French country houses.”
To claim the mantle of resistance is also to suggest that your opponents are something akin to fascists or, more modestly, that they are authoritarians. But, unlike in the 1930s, today’s right-wing populists do not generally condemn the idea of democracy. More likely, they salute it (or at least a majoritarian version of it). Rather than dispatching brownshirts in the streets, they call for referenda and plebiscites. As many observers have noted for years, “direct democracy” isn’t necessarily good, but direct democracy isn’t quite the first thing you think of when you think of Benito Mussolini or Adolf Hitler.
Being in a constant state of alarm, particularly when there’s little actual threat of being imprisoned for your beliefs, can be unusually thrilling. Carl Schmitt, the hugely influential jurist-philosopher who joined the Nazi Party in 1933, called this the romance of “the occasion.” Romantics, writes the political theorist David Runciman, “want something, anything, to happen, so that they can feel themselves to be at the heart of things.”
But more than two years after Trump assumed power, there is the risk that they may no longer have an enemy worthy of the title. Democrats control the House of Representatives. More than norms, institutions—the courts, the media, and the machinery of government—have constrained the Trump presidency. In policy terms, outside of immigration, the Republican Party has more co-opted the Trump administration than the other way around.
[Read: How Donald Trump is reviving American democracy]
The conclusion of the Mueller investigation, which enjoyed bipartisan support, is important on its own terms, but it also allows us to do away with the romantic belief that the worst is always yet to come, however much we might have wanted it to. Anything and everything is, of course, possible, but this doesn’t justify treating it as a particularly likely outcome. For this reason, the investigation, however much the Trump administration objected and attacked, was necessary.
It is unfortunate that a result of no collusion had to come after two years of the purposeful delegitimation of a legitimate democratic outcome. Trump’s very real badness has no bearing on the question of legitimacy.
But these objections did not figure into the breathless doomsday scenarios. Instead, academic research, even when it was sound, was used not in the service of “truth” but in the service of a particular political agenda. As Corey Robin memorably described it: “Brooding on the bloodlands of Europe, meditating on the dark night of the populist soul, anxious media professionals find academic confirmation for their sense that they are exiles in their own land.” Robin points to the pitfalls of “explainers” and articles billed as news analysis, which “unconstrained by the protocols of academe or journalism [draw] on the authority of the first for the sake of the second.”
Books, particularly books by academics, are usually more nuanced than the headlines they produce. So those focused on the unabashed anti-Trumpism in a book such as How Democracies Die might miss an argument the authors hint at in passing but explicitly state only in the final pages. “Even if Democrats were to succeed in weakening or removing President Trump via hardball tactics,” they write, “their victory would be pyrrhic.” After all, it would only mean Republicans returning the favor in kind, perhaps with even more vehemence, after a new Democratic president takes office. Every time one party won, the other would try to impeach its president, claiming that he or she was both illegitimate and a threat to the very foundations of the republic.
Many will still make such claims, holding on to the notion that they are fighting a world-historical struggle against a would-be dictator. They can believe that they are. But they are not, or at least they aren’t any longer.
"
Ocasio-Cortez Understands Politics Better Than Her Critics,1-29-2019,"Most Americans—myself included—probably don’t have a well-thought-out position on whether a 70 percent marginal tax rate is a good idea. But it probably doesn’t matter whether it is, or whether it would “work.” To argue that “workability” is secondary might sound odd to many Democrats, particularly party leaders and experts who have long prided themselves on being a party of pragmatic problem-solvers. This, though, could be the most important contribution so far of Representative Alexandria Ocasio-Cortez and the new crop of progressive politicians—the realization that the technical merits of a particular policy aren’t the most relevant consideration. For these new Democrats, the purpose of politics (and elections) is quite different.   
Commentators often note that, when it comes to policy, the differences between the Democratic Party’s left-wing and center-left are minimal. Referring to young progressives like Ocasio-Cortez who challenged establishment politicians, David Freedlander writes, “The policy differences … are microscopically small. Nearly all Democrats favor tackling income inequality, raising taxes on the wealthy and the minimum wage, and reforming the criminal justice system.”
This misses the point in a rather fundamental way. Few people actually vote based on policy. As I recently argued in American Affairs, even the better educated don’t primarily vote based on policy. In fact, higher levels of education can increase polarization. (In other contexts, such as the Middle East, the advent of universal education and higher college attendance fueled ideological divides.) As the political scientist Lilliana Mason notes, “Political knowledge tends to increase the effects of identity as more knowledgeable people have more informational ammunition to counter argue any stories they don’t like.”
[Derek Thompson: Alexandria Ocasio-Cortez has the better tax argument]
People’s politics tend to determine their policy preferences, and not the other way around. In one example from the 1960s, as Christopher Achens and Larry Bartels write in Democracy for Realists, even southerners who supported racial integration left the Democratic Party. Once they became Republican, they then adjusted their views on race and affirmative action to fit more comfortably with their new partisan identity. Put another way, if a person with no prior partisan attachments decides to become a Republican, he is likely to become pro-life. If that same person, with the same genetics and life experience, decides to become a Democrat, he is likely to become pro-choice.
Ocasio-Cortez and other progressives appear to understand instinctually what this growing body of research on voter preferences suggests. And its implications are potentially far-reaching. Once you accept that voters are rationally irrational, you can’t help but change how you understand political competition. Incidentally, this is one reason that right-wing populists across Europe (and India and the Philippines and many other places) have been surprisingly—or unsurprisingly—successful: They seem to have relatively little interest in what works. Instead they are concerned with altering the political and ideological imagination of ordinary voters and elites alike, to make what once seemed impossible, possible. In their case, it often involves normalizing Islamophobia and other forms of bigotry. They have managed to drag the center-right further rightward on issues such as immigration and how to integrate (or not integrate) Muslim minorities. But this same approach can be used by left-wing and center-left parties for more constructive ends.
This focus on shifting the contours of the national debate is sometimes referred to as expanding the “Overton window.” It is altogether possible that Ocasio-Cortez doesn’t think that a 70 percent marginal tax rate is realistic in our lifetime—she might not even think it’s the best option from a narrow, technocratic perspective of economic performance—but it doesn’t need to be. As the Open Markets Institute’s Matt Stoller notes, “One thing that [Ocasio-Cortez] has shown is that political leadership matters. Just proposing a 70 percent marginal tax rate has restructured a debate over taxes. Obama’s presidency was defined by self-imposed limits.”
[Read: How Alexandria Ocasio-Cortez’s plain black jacket became a controversy]
Today, in a way that hasn’t been true for decades, more Americans are at least aware of something that might otherwise have been ignored as either overly wonky or, well, crazy. The 70 percent figure proposed by Ocasio-Cortez was a subject of debate—and derision—at Davos. But by joking about it, billionaires and aspiring billionaires, in effect, helped legitimate it. After all, if the richest people in the world are worried about it, it might just be a good idea. (And Dell CEO Michael Dell unintentionally helped remind the audience that the United States had a 70 percent marginal rate as recently as the 1970s). The economist William Gale, my Brookings colleague, wrote a piece responding to Ocasio-Cortez’s proposal, taking issue with the 70 percent figure but agreeing with the underlying principle: “Ultimately, if we want more revenue from the rich, we should broaden the base and boost rates. Raising taxes on the rich is an idea whose time has come, receiving consistent support in polls over the last few decades.”
This new style of Democratic politics is a far cry from the technocratic “what works-ism” that has dominated in center-left parties since the 1990s. The incrementalist approach, by its very nature, preemptively accepts policy and ideological concessions in the name of prudence. It prioritizes being sensible and serious. But why is being sensible an end in itself? As Ocasio-Cortez’s chief of staff, the 32-year-old Saikat Chakrabarti, said regarding another seemingly unrealistic idea, the Green New Deal: “If it’s really not possible, then we can revisit. The idea is to set the most ambitious thing we can do and then make a plan for it. Why not try?”
I don’t feel strongly about a 70 percent marginal tax rate, but I don’t need to. I might even conclude that it simply “feels” too high. But that just means that if and when a Democratic candidate for president proposes a 50 percent tax rate on income that’s more than $10 million, I’ll be impressed with how “moderate,” reasonable, and sensible it sounds.
"
Resist the Lure of Theological Politics,12-22-2018,"There is something corrupting not just about the struggle for power through politics but about politics itself. Philosophers and pundits have long condemned the political as both profane and belittling, the near opposite of the pure and higher spiritual pursuits. In his valediction for the great, controversial scholar Edward Said, Christopher Hitchens wrote: “Indeed, if it had not been for the irruption of abrupt force into the life of his extended family and the ripping apart of the region by partition and subpartition, I can easily imagine Edward evolving as an almost apolitical person, devoted to the loftier pursuits of music and literature.”
Recently, Andrew Sullivan argued that in losing religion, Americans have more and more sought to satisfy their search for meaning publicly rather than privately. In his response, The Atlantic’s Graeme Wood wonders how we might desacralize politics and points to Japan as an alternative, if still flawed, model of lower-stakes competition. Countries that have experienced fascist rule or military defeat, or both, are more likely to accept normal politics, Wood suggests, although even in these places the rise of right-wing populist parties, such as the Alternative for Germany (AfD), points to the limits of historical remembrance.
But neither returning to the Christianity of previous generations nor desacralizing American politics is likely to fix a public sphere that is simply too invested with meaning for anyone’s safety. Instead, Americans need to construct a different sort of public faith—one that borrows from religious sensibilities to infuse debate with a spirit of humility, instead of theological certainty. The problem with America’s public life isn’t that it has too much religion, or too little—but rather, that it has the wrong kind.
[Graeme Wood: The gods that will fail ]
Both Sullivan and Wood draw a clear, almost idealized line between the private and public. It is certainly true that, in the Christian West, the line has always been there—in theory if not necessarily in practice—to a degree it never was in Muslim-majority contexts. As Sullivan writes: “Liberalism is a set of procedures, with an empty center, not a manifestation of truth, let alone a reconciliation to mortality. But, critically, it has long been complemented and supported in America by a religion distinctly separate from politics, a tamed Christianity that rests, in Jesus’ formulation, on a distinction between God and Caesar.” But this distinction between the religious and the political, which solidified itself with the rise of liberal, secular politics in the 19th and 20th centuries, has remained more fungible than we might like to admit, particularly among intellectuals and philosophers who proved unable to content themselves with being merely that.  
In The Reckless Mind, Mark Lilla looks at some of the most influential Western philosophers of the modern era to make sense of how men so brilliant could become so dangerous in political life. Martin Heidegger, who made common cause with the Nazis and remained a member of the party until the end of the war, told a German newspaper in the 1960s (after coming to see himself as a victim of the Nazis): “Only God can save us now.” Hannah Arendt, his lover for many years, tried to explain Heidegger’s Nazism by pointing to “a spiritual playfulness that stems in part from delusions of grandeur and in part from despair.” In Lilla’s reading, philosophical passion—or “intellectual sorcery,” as he also calls it—all too easily morphed into a kind of magical political thinking. Meanwhile, the hugely influential jurist-philosopher Carl Schmitt—who also joined the Nazis and helped provide legal justification for their ideas—wrote about the political as a form of divine struggle (for him, the political always seemed to be in a state of italicized agitation). Lilla calls Schmitt “a theologian marooned in the realm of the profane.”
In each of these cases, political fanaticism seems to draw from a sublimated religious impulse; God isn’t enough. But the notion that actual religion might temper worldly passions might sound odd to the modern ear. After all, among the more secular-minded, it is basically an article of faith that religious passion fuels extremism and intolerance (which it no doubt sometimes does). But there is also a private contentment, rooted in religious faith, that allows individuals to accept imperfection in this life in anticipation of the next.
[Alex Wagner: The church of Trump]
The question that both Sullivan and Wood are asking is how we might make politics more boring, after the interregnum of near-constant excitement known as Trump. Sullivan wants a return to a Christian cultural sensibility, if not a Christian religious faith, that allows us to live with a public politics that is more or less procedural. Wood asks that we consider how the Japanese have built in an expectation that politics isn’t and shouldn’t be especially interesting.
The difficulty with these proposals is that they ask something of people that, even in our secularizing age, is easier to achieve in principle than in practice: the separation of the personal and the political. The line will always be breached, particularly by the more passionate among us (a passion often amplified by technology). Sullivan is right to recognize that we are all religious even when we’re not members of any faith, that we desire not just meaning but ultimate meaning. For those who believe in God, this shouldn’t be surprising: If God exists, presumably he would instill such a desire into his creation. But perhaps the kind of religion that can be insulated from politics is itself becoming untenable, even within otherwise secularized Christian cultures.
In his masterwork City of God, Saint Augustine wrote that the city of man and the city of God, though they inevitably overlapped, were separate, and he sometimes even portrayed them as walled cities, standing in opposition to each other. The gap between them could not be erased, at least not entirely. This dualism in Christian theology sometimes led to a passivity and fatalism. This passivity is more difficult to sustain in an era of mass politics. Higher literacy rates, the spread of university education, and universal access to information (and the resulting sidelining of clerics as the protectors of knowledge) have been major drivers of ideological politics, in the form of socialism in the West and Islamism in the Muslim world.
[Read: Politics as the new religion for progressive Democrats]
The Dutch theologian Abraham Kuyper, who—unusually for a theologian—served as prime minister of the Netherlands from 1901 to 1905, is the major modern exponent of “Christian pluralism.” He believed that all ideas, when strongly held and believed, were effectively faith-based. According to his intellectual biographer, the American theologian Matthew Kaemingk, Kuyper thought that although one can find some individuals who wish to keep their belief private, “the absence of an ultimate point of loyalty, meaning, or purpose cannot persist for long.”
If this is the case, then it becomes a question of where individuals find their “ultimate point of loyalty.” Is it in a nation, rationalism, truth, God, or some mix of these things? The inherent risk of finding ultimate loyalty in a charismatic leader or a sovereign state is that they are of this world. To claim them, then, requires seeking victory in this world, because they are of this world and this world alone. As the writer Kyle Orton remarks, “Tolerance might not be possible from the secular world, tinged as it is with utopianism and a drive for final victories.” The fundamental question becomes how to clip such a drive.
Kuyper and Kaemingk offer one potential answer. Christian pluralism sees the city of man as inherently broken and fallen from sin, which, in turn, means that politics must be acknowledged as a site of uncertainty, rather than certainty. The solution, then, wouldn’t be walling off one’s Christianity from the domain of Caesar, but rather applying it in a more self-conscious manner.
There is a corollary to this line of thought in Islam that receives perhaps even less attention. One Koranic passage declares: “No one can know the soldiers of God except God.” The “soldiers” part of this tends to attract notice, some of it negative. But some religious scholars, such as the American Islamic legal theorist Khaled Abou El Fadl, interpret this as an endorsement of suspending judgment: No one can know, in this life, who is in fact God’s soldier. In a famous prophetic hadith, if a mujtahid (an authority in Islamic law) strives for God’s truth and is “correct,” then he receives two good deeds; if he is wrong, he still receives one bounty. If the mujtahids disagree with one another, then only God knows which one of them is correct.
If only God knows, then we cannot know. The key idea in these somewhat lost traditions is not the suspension of judgment, so much as the postponement of judgment. For the believer, the judgment presumably comes, but it comes later. For those who do not believe in God, it simply wouldn’t come at all.
Regardless of their faith (it would be a practical challenge to transform a critical mass of Americans into theological pluralists), a small but growing number of citizens can make the conscious decision to resist making the political wholly theological. They can choose to abstain on the question of whether a policy matter—an immigration quota or a Supreme Court nomination—represents an absolute, incontrovertible truth. In practice, this would mean that very few citizens of any nation are outside the fold or beyond the pale. For Americans, it means that, save for a relative few on the fringes, there are no “good” or “bad” Americans in any ultimate sense—or at least not in any ultimate sense that mere humans might be privy to. This is what an American public faith could theoretically look like, and the good thing is that anyone can start believing in it.  "
Saudi Arabia Is Taunting Trump,10-11-2018,"Donald Trump’s Middle East policy is many things, but it is not incoherent. At the core of the president’s approach has been a stark redrawing of the friend-enemy distinction: doubling down on support, often unquestioning, for allies like Saudi Arabia and Israel, while refocusing the near-entirety of American ire on Iran.
That Trump has bet big on the de facto leader of Saudi Arabia, Mohammed bin Salman, makes the Saudis’ disappearing and likely assassination of the dissident Jamal Khashoggi in their Istanbul consulate—“monstrous” on its own terms—a different sort of escalation. For Trump, this has been personal. His son-in-law and adviser, Jared Kushner, has worked to develop a close relationship with bin Salman, colloquially known as MbS, seeing the young crown prince as a strong partner in isolating Iran and softening Arab enmity toward Israel.
In Trump’s world, friends—particularly friends that are both Arab and authoritarian—are to be criticized as little as possible, especially on low priorities for the administration, like human rights. This hands-off approach has emboldened and empowered MbS to increasingly destructive effect over the past year and a half, offering a reminder that the prospect of U.S. pressure—if not actual U.S. pressure—serves as a constraint on allies that tend toward overreach.
What is both striking and telling is how halfhearted and generally uninterested the Saudis have been in countering evidence that they assassinated Khashoggi. (Take, for example, the Saudi ambassador’s suggestion to Senator Bob Corker that the consulate surveillance video only “live-streams.”) But this is precisely what makes Saudi Arabia’s behavior in this episode even more reckless than the ongoing crackdown on even its milder critics or its increasingly callous disregard for human life in the Yemen war. Trump has invested political capital and extended unprecedented goodwill to MbS, drawing considerable criticism in the process. In a sense, this has been Trump’s “big bet,” perhaps his biggest one in the Middle East. As Axios’s Jonathan Swan put it, “The Trump administration, led by Jared Kushner, made about as big a bet on MbS the visionary-reformer and the Saudis as it’s possible for a US admin to make.” The goodwill has not been reciprocated. Rather, MbS is, in effect, taunting Trump, gloating in his ability to get away with anything.
A supposedly close friend acting in such a manner could be—and perhaps should be—taken by Trump as a personal affront. This further and perhaps even conclusively invalidates Trump’s decision to orient America’s Middle East strategy around a new and changing Saudi Arabia. Trump’s recent comments were somewhat unclear, but he seemed bothered that he even had to talk about it: “I am concerned about that,” he said in response to a question about Khashoggi’s disappearance. “I don’t like hearing about it, and hopefully that will sort itself out. Right now, nobody knows anything about it. There’s some pretty bad stories about it. I do not like it.”
With Trump, however, it is always hard to tell where his passions may lead him. Trump may not care enough about the assassination of a prominent journalist, who was also a U.S. resident and a Washington Post columnist. But the events may also awaken the side of Trump that, first as a candidate and now as president, has suggested an impatience with Saudi Arabia and its military dependence on the United States. In an October 2 rally in Southaven, Mississippi, Trump riffed, saying something that received little attention at the time but in any other administration would have likely have been front-page news: “We protect Saudi Arabia—would you say they’re rich? And I love the king, King Salman, but I said, ‘King, we’re protecting you. You might not be there for two weeks without us. You have to pay for your military. You have to pay.’”
It is little surprise that Khashoggi’s disappearance has provoked not just frustration from U.S. politicians, but anger, including from Senator Lindsey Graham, who said there would be “hell to pay” if Khashoggi was assassinated. This is the danger of transactional relationships with countries and rulers that not only don’t share our values, but often don’t share our interests either. Outsourcing our Middle East policy to a reckless leader who appears to have such disrespect for the United States—and its support for his country—was always a mistake. Now it is also an embarrassment.
Even for those who care little about human rights in the Middle East, the disappearance of Khashoggi calls into question the reliability of an ally that has insisted on acting in such brazen fashion. If Trump’s foreign policy really is about “America first,” then allies who show blatant disregard for America, American values, and American interests should incur significant costs. What might those costs be? This is what the conversation over the future of the U.S.-Saudi relationship must turn to. Trump is at least partly correct about Saudi dependence on the United States. As my colleague Bruce Riedel writes, the Saudi air force “is entirely dependent on American and British support for its air fleet of F15 fighter jets, Apache helicopters, and Tornado aircraft. If either Washington or London halts the flow of logistics, the [air force] will be grounded.”
Bad allies, particularly in the Middle East, where they abound, have been a recurring problem for successive U.S. administrations. U.S. policy makers need—or think they need—them, even when those allies go out of their way to undermine their relationship with the United States. Those allies believe—mostly correctly—that the United States will express concern and complain, but ultimately do little. The worst offenses will be forgotten in the name of national-security interests, as they have been so many times before. It is time to call Saudi Arabia’s bluff."
Trump Made Socialism Great Again,8-10-2018,"The election of Trump—and the populist upsurge he helped encourage—has confirmed that politics is no longer the art of the possible, but the improbable. If Trump can win the highest office in the land, then why can’t the rest of us run for something, too? Why shouldn’t a 33-year old Egyptian-American named Abdul run for Michigan governor? Why shouldn’t a 28-year old, who was only a bartender a year ago, defeat a Democratic establishment stalwart? And why shouldn’t that person say, without shame or apology, that she’s a socialist?
Alexandria Ocasio-Cortez’s primary-election victory, coming on the heels of Bernie Sanders’s insurgent presidential campaign, has thrust “socialism” into the center of the American political conversation. Ideas once dismissed as radical are now gaining a hearing. Fights are raging within the Democratic Party, and on the political left. And that reinvigorated debate—and the other political conflicts Trump has inflamed—may be one of Trump’s more unlikely and ultimately positive contributions to American democracy.
[A shocking insurgent victory in New York]
Few people would say that conflict is a thing to be embraced. The usual assumption is that conflict and polarization undermine democracy. We hear paeans to civility, unity, and coming together as a nation. But conflict, or at least the threat of it, can be a powerful motivator.

If a government has no fear that the poor might one day revolt, then it will have few incentives to check the excesses of the rich. If elected leaders have no fear that they might lose the minority vote, they will have little reason to take racism as seriously as they should. If established parties have no fear that populist parties might take their place, they will have little reason to rethink their basic approach to politics. Without pressure from populist challengers, centrist parties will avoid addressing sensitive issues, instead postponing them until crisis hits. And crisis almost certainly does.
This confusion around the desirability of conflict makes it difficult to assess how well or poorly the world’s most established democracies are faring, now that nearly every one of them has been significantly affected (with Portugal being a notable exception). As some would have it, America, along with large chunks of Europe, is on the verge of dictatorship from which it may never recover.  
If you view the very election of Trump—to say nothing of what he’s actually done in office—as an “extinction-level event,” then alarmism is precisely what’s called for: the more, the better. But I, for one, do not believe that Trump is anything more than damaging and destructive—as bad as that is. Two or six years from now, America will emerge with considerable damage, but intact. And by then, the experience of having lived under Trump will produce other consequences, some of them positive. In fact, it’s already producing them.
Trumpism—or some variation of the populist-nationalism that has proved so compelling from Italy and Poland to Israel and India—will survive Trump. The ideas of this visceral but vague populism—obsessed with demographic change and trafficking in proposals that only 4 years ago would have been beyond the pale—are almost entirely unconcerned with the norms of what was, up until 2016, a somewhat narrow mainstream consensus.
Peter Pomerantsev’s book, Nothing Is True and Everything Is Possible, popularized a bleak aphorism that encompassed the surrealism and absurdity of living in Putin’s Russia. In the United States, though, that everything might be possible, when it wasn’t before, means that the range of acceptable opinions is being broadened, whether that means democratic socialism, unabashed Catholic integralism, post-liberalism, or even something as silly as the notion that billionaires are well-suited to run for office.
[Will Mark Zuckerberg run for president?]
As Ben Judah wrote recently, a door has been opened: “Because by embracing everything about Donald Trump, [the Right] has embraced the idea that something is terribly wrong with America, and that the country needs big, beautiful solutions for terrible, awful problems. When the Right becomes populist, embraces deficits, dunks on free trade, and rails against elites, it suddenly becomes a lot tougher for it to ridicule a populist Left that is credibly offering more.”
Where Trump told voters that he (and only he) would “make America great again,” Hillary Clinton countered by saying “America was already great.” America is already great, but the problem with making that the theme of a national campaign is that it promises only minor variations of the status quo. Clinton—and so many of the center-left and center-right candidates hoping to forestall populist challengers—offered voters stability in a time of instability. Experiencing Trump on a daily basis tends to help one appreciate the prospect of once again being bored by politics. But stability, particularly in the long run, is an overrated political good that can actually forestall the kinds of deep changes that every society needs from time to time.
Another way of viewing it, and probably the easier way, is to see Trump as an accident of history and not something to ponder too deeply. Since the results could have easily been otherwise—had, say, James Comey not issued his letter in those final, critical days—there is no particular reason to shift our view of politics or democracy. To view Trump’s election as an extinction-level event is to argue, in effect, that the solution to Trump is self-evident: his removal from office. Politics can then return to at least some degree of normalcy. If Trump, however, is a product of a political order that is fundamentally broken, then the need for radical, unusual, or at least out-of-the-mainstream proposals becomes just as necessary if and when Trump loses—or even if he hadn’t won in the first place.  
Civility and consensus are only possible in homogeneous societies with a strong, shared national identity, something that the United States and most European countries can no longer claim. In diverse societies, where citizens no long agree on the common good, conflict and polarization are unavoidable. Like conflict, the word radical is usually used pejoratively, signifying chaos and disorder. But like conflict, radicalism isn’t necessarily bad, particularly if it allows a larger number of citizens to feel they have a stake in their own society. It also leaves open the possibility that ideas that were once considered unacceptable can be accepted. Some unacceptable ideas are unacceptable for a reason. Some, though, are not.
Today, ideas that were once considered radical and even politically suicidal, like same-sex marriage, are now so culturally pervasive that it’s hard to remember that they were once only held by a small minority. (As recently as 2009, President Barack Obama, despite his seeming private openness to gay marriage, was unwilling to endorse it publicly). It’s precisely through radical voices that the bounds of what’s politically and socially possible expands. At one point in American history, for example, the abolition of slavery was seen as outside the bounds of what was possible or acceptable. Through Bernie Sanders’s presidential candidacy, the idea of single-payer universal health care became normalized, shifting the entire debate around health-care provision onto what many Americans would consider a more moral foundation. (Of course, many other Americans see it as an unacceptable intrusion on the part of the state.)
[Was Obama lying about opposing gay marriage?]
To find a silver lining to this disruption of political complacency is not to excuse Trump. The families torn apart at the border; those who have lost their healthcare; the communities that will be polluted by environmental disaster; or the millions of people abroad who have suffered from Trump’s unashamedly pro-dictator foreign policy would have been better off had he never run for office. But even without Trump, disruption and conflict were coming; he was merely the catalyst. This—whatever this is exactly—is a universal phenomenon, emerging in dozens of incredibly different national contexts, across varying cultures, regions, religions, and levels of economic development. It may be hard to define, but what we are seeing is nothing less (or perhaps nothing more) than a rebirth of politics, with all the conflict that that entails.
The point about radical ideas is that some of them may be good, but there’s no way to know, definitively, whether they are, until they’re debated openly and freely. And, today, that’s precisely what’s happening. That’s a good thing, and we may have Trump to (partly) thank for that."
Arab Democracy Depends on Normalizing Islamist Parties,7-3-2018,"The perennial question of whether democracy can work in the Middle East isn’t always easy to answer. Generally, it hasn’t worked. But amid civil war in Yemen, Libya, and Syria, authoritarian resurgence in Saudi Arabia and Egypt, and economic instability in Jordan, there are at least three cases that challenge the notion that it can’t happen here. Tunisia, which held its first post-revolution municipal elections in May, continues to be a (relative) bright spot. Then there are the more unlikely cases of Iraq as well as Lebanon—probably the world’s most successful failed state. All three share two related features: Largely without controversy, they include Islamist parties in their democratic processes; and, second, they feature some degree of power-sharing.
In Lebanon, these arrangements are deeply flawed, chaotic, and responsible for entrenching sectarianism. Parliamentary seats are still apportioned by religious affiliation. At the same time, as the Carnegie Endowment’s Joseph Bahout has noted: “There are typically no winners and no vanquished emerging from crises in Lebanon … Many Lebanese seem to believe their system is the least bad option compared with neighbors.” The Lebanese writer Michael Young has argued that while each sectarian grouping is illiberal and insular, by interacting, “they tend to cancel each other out, creating spaces that allow individuals to function with relative freedom.”
Iraq, like Lebanon, saw lower turnout in its recent election. But as the Brookings Institution’s Tamara Wittes testified to Congress, both polls offered an important lesson. “If Lebanon and Iraq can pull off free elections,” she wrote, “it’s harder for strongmen in other Arab states to argue that they can’t afford the risk to stability of allowing their own peoples a choice in who governs them.”
The very presence of Islamist parties can be inherently polarizing, particularly when they represent large, powerful, and conservative constituencies. Through successive administrations, the United States has regarded too much Islamist representation—or any Islamist representation—as a risky prospect. Yet it was the George W. Bush administration that, despite its discomfort with Islamism, ironically paved the way for Islamists to take power through democratic elections in Iraq—a first in the Arab world. After its January 2005 elections, Ibrahim al-Jaafari of the Shia Islamist Dawa party assumed the prime ministership. Interestingly, Iraqi Muslim Brotherhood members served in various cabinet positions, including as ministers of higher education and planning. In Lebanon, Hezbollah—however much the United States and Saudi Arabia oppose it—has become a fixture of coalition governments. The point here isn’t that these groups are good (Hezbollah is a designated terrorist organization as well as an active participant in the Syrian regime’s mass killing of civilians), but rather that Arab democracy, in practice, often coincides with the normalization of Islamist parties.
Even in Tunisia, where Islamists aren’t yet normalized since the democratic experience is still young, there are similar takeaways. The country’s transition since the ouster of Zine El Abidine Ben Ali in 2011 offers a reminder that democracy can not only survive but produce impressive results—but only if Islamist parties are incorporated into the process. From 2011 to 2014, the Islamist Ennahda-led government and constituent assembly, in partnership with two secular parties, ushered in what the Project on Middle East Democracy called “the most progressive and democratic legal framework for civil society in the Arab World.” These included some of the strongest associational freedoms and human-rights protections in the region. Surprisingly—or perhaps unsurprisingly, depending on your perspective—these gains are in danger of being undermined under the current secular-led government.
Some, like analyst Ibrahim al-Assil, might argue that Tunisia is exceptional because Ennahda is exceptional—an Islamist party that has diluted its Islamism, shed the “Islamist” label, and reconciled itself to a secular state. In my book Islamic Exceptionalism, I argued that these shifts are more the product of an imperative to survive, a fear of repression, and a determined pragmatism than they are the result of some deep ideological epiphany.
In the case of Tunisia, the irony is that Islamists’ willingness to play nice—something that would generally seem quite positive—has contributed to a troubling trend of democratic backsliding on things like police reform, an overly securitized counterterrorism strategy, and the lack of accountability for the crimes and corruption of old regime figures. As the largest party in parliament, Ennahda potentially has considerable power to challenge Prime Minister Youssef Chahed and President Beji Caid Essebsi Essebsi’s priorities. Instead, they have emphasized caution, consensus, and stability, fearing that doing otherwise might summon the old days of polarization and repression. Embracing their role as junior partner in the government, they have, in effect, gained protected status. But this also means that Tunisia is deprived of a cohesive bloc that could serve as an effective lobby for strengthening the democratic transition. The desire for compromise, unchecked, can come at a cost.
These darker undercurrents present real cause for concern. But the bottom line, at least for now, is that the lived practice of democracy can still provide a counterpoint to an authoritarian status quo that often seems unyielding and overwhelming. And in each of these cases, democracy would simply be inconceivable without Islamist participation. That, by itself, should give us pause, particularly at a time when Western democracies appear uninterested or even hostile to either democracy promotion or integrating Islamists, or perhaps even both.
"
"The Travel Ban, the Law, and What’s ‘Right’",6-28-2018,"In January 2017, when President Donald Trump’s so-called Muslim ban was first announced, I was passionately against it. It was one of the most frightening texts I’ve read from U.S. government officials in my lifetime. The Supreme Court just upheld the third iteration of the travel ban in Trump v. Hawaii, and I find myself in the odd position of opposing the court’s ruling on personal and moral grounds, while also thinking it was a legally plausible interpretation.
Like most political developments of the Trump era, there is a tension between having the “right” position and having the “correct” position. A pure anti-Trump position would entail opposing the court’s ruling regardless of its substantive content. This feels morally right—and it may even be the morally right—but that doesn’t necessarily make it correct. The Supreme Court, unlike Congress, is not tasked to make moral judgments about the law, at least not explicitly.
The first version of the travel ban, which, among other things, appears to have been intended to troll liberals, explicitly discriminated based on religion. The very fact of being Muslim was grounds for scrutiny. One clause, in particular, effectively imposed a religious test. Refugees facing religious persecution could be admitted but only if “the religion of the individual is a minority religion in the individual’s country of nationality.” The revised version, issued in September 2017, omits such language, and incorporates two non-Muslim countries, North Korea and Venezuela. Regarding Syrian refugees, this means that, in theory if not necessarily in practice, entry restrictions on Syrian refugees would apply equally to Muslims and Christians alike. Accordingly, Chief Justice John Roberts wrote that the president’s directive was “neutral on its face.”
Recommended Reading
An illustration of a classroom and Black Lives Matter sign.
‘The Narrative Is, “You Can’t Get Ahead”’
Conor Friedersdorf
Black and white photo of Matt Gaetz
Only Congress Could Give Us a Matt Gaetz
David A. Graham
An illustration of web browser windows spelling out ""lies.""
Scale Was the God That Failed
Josh Marshall
Of course, the president’s directive is probably not neutral in intent. Trump and many of his senior aides bear an avowed animus toward Muslims or Islam, or both. Trump himself said during the 2016 campaign that he thinks “Islam hates us.” How much should intent matter? Constitutional law scholars—and of course the Supreme Court itself—are divided. In her dissent, Justice Sonia Sotomayor cited Trump’s rather long paper (or tweet) trail to argue that “taking all the relevant evidence together, a reasonable observer would conclude that the Proclamation was driven primarily by anti-Muslim animus.” But the extent to which certain motivations figure more than others is always difficult to divine. It’s also possible that someone’s intent changes over time, and it’s not necessarily the easiest task to discern what Trump’s “primary” versus “secondary” motivations might be on any specific matter.  What we do know is that the discriminatory nature of the text of the order itself is no longer self-evident, so what might have initially been an unequivocally discriminatory “Muslim ban” is now something else.
I am still deeply uncomfortable with the Supreme Court’s ruling. It contributes to the legitimization and mainstreaming of anti-Muslim bigotry. That’s certainly how it will be interpreted by millions of Americans. But that doesn’t mean the ruling itself, in narrow terms, rises to the level of one of the great moral questions of our time. The decision does not turn American Muslims like myself into “second-class citizens,” and to insist that it does will make it impossible for us to claim that we have actually become second-class citizens, if such a thing ever happens. To claim that Jim Crow or the Holocaust were similarly “legal” diminishes the moral seriousness of crimes that nearly all Americans, today, agree were unequivocally wrong. (No such consensus exists on Trump v. Hawaii and to assume that it will exist at some point in the future is to assume that morality will always necessarily be progressive and retroactive.) To use a less incendiary comparison, it is also difficult to argue that Trump v. Hawaii is comparable to the 1944 Korematsu v. U.S. decision permitting the internment of Japanese Americans. Nation-states generally have wide latitude in determining which non-citizens can enter their borders, where Korematsu targeted U.S. citizens.
Voters should be able to debate which entry and immigration policies are most appropriate, effective, and, yes, moral as it relates to non-citizens outside of our borders. To insist that such questions should be decided outside the confines of normal democratic deliberation undermines democratic responsiveness and accountability. This is particularly a risk at a time when immigration, rightly or wrongly, has become a top concern of voters in most Western democracies. To think that such questions can be resolved by dismissing or bypassing the views of your fellow citizens is a “long term recipe for public disillusionment and alienation,” writes Tablet’s Yair Rosenberg. The courts may be great places to bend the arc of history toward justice, but they’re only great places for that when they agree with whatever we already think is just.
As The New York Times notes, those who feel uncomfortable (or disgusted) with recent Supreme Court decisions must “look somewhere else. That place is the ballot box.” Moral judgments on constitutionally and legally muddy debates can be rendered, but they’re best rendered by persuading as many of our fellow citizens that they should stop voting for anti-Muslim presidents.
"
What Democracies Can Learn From Malaysia,5-16-2018,"What is democracy for? This might seem like an obvious question. Yet disagreements over democracy’s ends are multiplying in the West, including in the oldest, most advanced democracies. Those disagreements include the question of whether democracy is an end unto itself or a means to something greater.
Is it possible that the United States and Europe might learn something from Malaysia, a country long seen as a flawed semi-democracy?
In this month’s elections, the ruling United Malays National Organization, as part of the National Front coalition, lost its hold on power for the first time since Malaysia won independence from the British in 1957—Mahatir Mohammed has replaced the long-serving Najib Razak as prime minister. In an unusual twist, though, the de facto leader of the opposition Alliance of Hope, Anwar Ibrahim, had been serving a five-year prison sentence on politically motivated sodomy charges. This week, he walked out a free man after receiving a full pardon. He may eventually become the country’s prime minister. These events were a reminder of a different kind of democratic euphoria, offering a stark contrast to the pessimism that citizens of Western countries have by now grown accustomed to. Elections do, in fact, have consequences.
In Western democracies, there’s often an unspoken assumption that democracy is supposed to produce better policy outcomes—well-paying jobs, better schools, or improved living standards, for example. Democracy’s legitimacy is tied to, and even depends on, its performance, something that’s also referred to as “performance legitimacy.” Our leaders also told us—as well as those living under dictatorship abroad—that democracy would make consensus, agreement, and a shared national vision more likely. But democracy isn’t fundamentally about these things, and Western politicians have erred in insisting that it is. This has raised expectations to levels that can’t be met. (Young democracies often show higher levels of polarization since the foundations of the state—and questions around identity, ethnicity, and religion—remain unresolved.) The gap between expectation and reality can grow precariously if promises of a better life and a great society are left unchecked.
Because there have been so few democratic successes in recent years, coupled with the demoralizing failures of the Arab Spring, it is easy to miss the more fundamental promise of even a flawed democratic process: that citizens—no matter how bad things get and how corrupt their leaders become—theoretically have recourse. They are not powerless. They can organize. They can constrain executive action. They can oppose.
Recourse is the last, and most important, refuge before a flawed democracy devolves into electoral authoritarianism. In regimes like Venezuela in Hugo Chavez’s last years, elections may still be competitive and even meaningful, but the opposition has no realistic chance of winning due to rampant gerrymandering, lack of access to media, and voter intimidation. Before these more recent election results in Malaysia, there was a fear that it would soon follow a similar course, especially after creative feats of gerrymandering rendered some constituencies more than four times as large as others. It was the classic move: Larger, urban areas that tended to vote for the opposition would have significantly less representation than the rural, traditionally pro-government parts of the country.
Prime Minister Najib Razak had become yet another example of the seemingly universal trend toward strongman politics. (Donald Trump once called him “my favorite prime minister.”) In addition to politicizing the courts and muzzling critical media, Najib was embroiled in a lurid corruption scandal in which hundreds of millions of dollars from the state’s investment fund allegedly appeared in his personal account, triggering a U.S Department of Justice investigation.
This could have been, in other words, a “last chance” election; instead it may very well mark the start of a new, deeper democratization process. Elections, even a single election, can have consequences as far-reaching as this. There is something remarkable, for instance, about the very notion—now taken for granted but once considered radical—that one party in power might voluntarily step down to be replaced by another. For much of human history, this idea was so ludicrous as to be beyond the imagination.
None of this, though, means that democracy itself is some panacea. Democracy is a long-term solution to the problem of how to manage conflict peacefully. It’s about giving citizens at least the option (one they may choose not to take) of replacing their representatives and experimenting with different candidates, parties, and even ideologies. It’s also about that feeling that you, as a citizen, can actually alter the course of your own country, and that your nation, at least in theory, believes that you matter enough to have that power. There is a joy in knowing this. As the Malaysian novelist Tash Aw described the scene outside his polling station: “The camaraderie was palpable. Volunteers handed out free food and water; strangers helped the old and weak to find seats in the shade during the long wait. Someone offered my mother a wheelchair (she politely declined). People lining up to cast their ballot joked about the heat, and about next seeing one another again in five years.”
These sentiments are important, perhaps the most important, but they do not necessarily translate into higher levels of economic growth. It is altogether possible—some might even say likely—that a more authoritarian government might perform better in a strictly technocratic sense, at least in the short term. The Chinese “model” provides strong evidence for this. As the scholars Dingxin Zhao and Hongxing Yang write, “the Chinese economy has developed quickly under an authoritarian regime with a strong capacity in manipulating economic activities.” Turning the notion of democratic responsiveness on its head, the political scientist Wenfang Tang argues that “leaders in authoritarian China do not have the luxury of electoral cycles.”
But there is little about the Chinese model, with its unique history of a developed bureaucracy and strong “stateness,” that seems replicable elsewhere. For every China there are five more disasters (including in China’s own tragic past). Zhao and Yang note that “history has presented ample examples that when an authoritarian regime possesses great autonomy, it is more likely to use the autonomy in detrimental ways.” Good authoritarians are sometimes great (particularly if you’re not a pro-democracy activist). The problem is that there is no way to guarantee “good” authoritarian outcomes. If, as is more likely, autocrats damage the economy and by extension your own livelihood, then there is relatively little you can do about it.
Malaysia offers a reminder that there is no substitute for this most essential of democratic functions: the chance, even if it often resides on a theoretical plane, that political outcomes are not permanent. There is that natural push and pull of democratic competition, with all the messiness that entails. But that messiness and uncertainty can be a good thing. A 92-year-old former premier, one who was known for a budding authoritarian sensibility, can switch sides and lead the opposition, joining forces with the very man he imprisoned. Mistakes need not be intertwined with the state’s own identity. They can be undone. And in Malaysia, at the ballot box, one of those outcomes was.
"
The Rise of Anti-Liberalism,2-20-2018,"A man named François is a professor in Paris. He is a scholar of Joris-Karl Huysmans, an obscure 19th-century author who, in his later years, converted to Catholicism in an epiphany. François is the hero, or rather anti-hero, of French novelist Michel Houellebecq’s Submission. François is listless—even his attitude toward sex is uninspired, as if it’s an activity like any other, perhaps like playing tennis on a Sunday, but probably with less excitement. There is too much freedom and too many choices, and sometimes he’d rather just die.
The world around him, though, is changing. It is 2022. After a charismatic Islamist wins the second round of the French presidential elections against the right-wing Marine Le Pen (after gaining the support of the Socialists), a Muslim professor, himself a convert, attempts to persuade François to make the declaration of faith. “It’s submission,” the professor tells him. “The shocking and simple idea, which had never been so forcefully expressed, that the summit of human happiness resides in the most absolute submission.”
The book was released on January 7, 2015, the day of the Charlie Hebdo attack, in which two masked gunmen carrying assault rifles and shouting “God is great” gunned down 12 staff members of the French satirical weekly. It became impossible to separate the novel from the event. Three years later—after more terror attacks, the rise of populists, heavy refugee flows, and a palpable anti-Muslim hysteria—the book appears, in retrospect, well ahead of its time.
Submission is still very clearly a dystopian novel—an increasingly popular genre these days—but, more than that, it is a meditation on the aimlessness of late-stage Western liberalism, where there is nothing much to be believe in, and nothing much to fight for, except the never-ending expansion of personal freedom. The controversy aside, Submission is strangely intriguing. Houellebecq is among a growing number of Western intellectuals flirting with anti-liberalism: Perhaps liberalism is not the unmitigated good most of us are raised to believe it is. In an odd way, though, liberalism’s critics end up saying more about the resilience of liberalism than its demise.
The emphasis on polygamy in Houellebecq’s depiction of Islam is often gratuitous. But there is also a sense of envy, that Islam retains a vitality, conviction, and self-assuredness that Western liberalism and Western Christianity lost long ago. (In his real life, Houellebecq, who once called Islam “the stupidest religion,” has since read the Quran and apparently developed an appreciation for Islam, contributing to his own epiphany of sorts. “When, in the light of what I know,” Houellebecq says, “I reexamine the question whether there is a creator, a cosmic order, that kind of thing, I realize that I don’t actually have an answer.”)
Related Stories

The Lessons of 'American War'
The Political Thrill of Having an Enemy
In fiction and nonfiction alike, liberalism—referring here not to the left of American politics, but to the political order that privileges non-negotiable rights, personal freedoms, and individual autonomy—has come in for a beating, or at least a challenge. Take, for instance, the work of Christian orthodox writer Rod Dreher. His highly influential book, The Benedict Option, calls on Christians to resist liberalism’s aimlessness and “moral chaos,” and instead form intentional communities of religious solidarity in a post-Christian America.
Few books challenge the core assumptions of modern liberalism as unapologetically as the suggestively titled Why Liberalism Failed by Patrick Deneen, a political theorist at the University of Notre Dame. Liberalism, in dismantling traditional structures, encouraging “privatism,” and empowering an ever-expanding state, has created an existential crisis, he argues. And insisting on yet more liberalism as a corrective has only made matters worse. “One of the liberal state’s main roles,” he writes, “becomes the active liberation of individuals from any limiting conditions.” Liberty, which he argues was once about freedom from “one’s own basest desires,” was redefined to encourage the ceaseless pursuit of those very same desires.
Some of this might sound like the standard anti-liberalism—a kind of Catholic nostalgia for the one true church, before the reformation unleashed a religious pluralism that would never be tempered again. As a liberal who is critical of liberalism, I sympathize with these arguments but am, at the same time, unwilling to follow them to their logical conclusion. I am fundamentally biased after all. For all of liberalism’s faults, I wouldn’t want to live under a non-liberal or even a less liberal system, and in the strongest parts of the book, Deneen suggests why that might be. Modern liberalism is designed for people like me. In David Goodhart’s parlance, I’m an “anywhere” rather than a “somewhere.”
Wherever I go and wherever I’ve lived, there are others, from all over the world, who I can easily connect with—“anywheres” of the center-left and center-right who share a similar disposition. They don’t really have a local community or “home” they feel particularly strongly about. They tend to have graduate degrees; be interested in politics; speak various languages; avoid sports-related conversations; and be vaguely privileged financially (it’s never entirely clear how privileged). Perhaps most importantly, they are suspicious of happy people but especially earnest people. No one’s particularly religious, but if they are, they’re probably members of a minority group, usually Muslims or Jews, which makes it okay. No one’s perfect, of course, but such are the people of my “tribe.”
The sheer diversity can be overwhelming—white Christian males can be hard to find—but the diversity, paradoxically, reinforces a kind of cultural homogeneity. As Deneen puts it: “The identities and diversity thus secured are globally homogenous, the precondition for a fungible global elite who readily identify other members capable of living in a cultureless and placeless world defined above all by liberal norms.” This is a new global aristocracy, one defined by liberal ideas of “rational” education and sensibility. Whether merit-based “aristocracies” are a good thing has long been debated. The historian Charles Wiltse, writing on Thomas Jefferson, pointed out the tension: “It is to the talented and the virtuous that the government is to be committed, a doctrine suggesting the Greek ideal of the wise man. The criticism of [John] Adams, that talents and virtue will, in the end, breed wealth and family, Jefferson seems to have ignored.”
Self-professed liberals often describe liberalism as indifferent to how we live our lives, so that liberalism effectively serves as a kind of referee or neutral bystander. But this does not necessarily entail ideological neutrality, since liberalism itself emerges from a set of ideological and philosophical assumptions regarding religion, human nature, and the state. Liberalism only offers neutrality within itself. (Political liberalism, as expounded by John Rawls, is based on the “veil of ignorance”—the notion that the founders of a new polity are free to construct their own society without any knowledge of their future position and without any distinctive set of preferences or values. But, as the philosopher Lenn Goodman writes, “Every one of Rawls’s choosers is trapped in a liberal society. … They are not free to construct a value system for themselves.”)
Once liberalism’s non-neutrality is acknowledged, its consequences on vast domains of public life become more obvious. Liberalism might be a better ideology (than whatever the alternatives might be) but it’s an ideology all the same. It’s a transformative project, as any belief system that views history as a progressive and bending arc must be. Liberalism believes its victory to be essentially a matter of time. History’s long, progressive, and bending arc will eventually win out.
All transformations, even largely good ones, come at a cost. Most Americans and Europeans, including those who benefit most from the liberal status quo, understand that something is not quite right. Take our unprecedented levels of inequality, which are only likely to grow. But the incentives for meritocratic elites to do anything serious about it—Deneen suggests a rather unappealing “household economics” model while social democrats like Matt Bruenig propose “social wealth funds”—are limited. Liberals are the new conservatives.
“Endless free choice,” as Deneen disparagingly calls it, is a dead end. Choice needs to be a means to something else, but to what? Legally based religious systems—which only Islam among the largest religions potentially offers—quite consciously seek to restrict choice in the name of virtue and salvation. It is no mistake that Houellebecq initially intended his book to be about a conversion to Christianity, but it’s telling that François—to some extent a stand-in for Houellebecq’s own fantasies—quickly grows bored after spending two days in a Benedectine abbey. As Mark Lilla writes, he “could not make Catholicism work for him.” Islam is what he finds tempting.
The fear of and opposition to Islam, deemed illiberal and retrograde, is, itself, one of the main drivers behind the rise of Western illiberalism and ethno-nationalism, particularly in Europe. In the United States, even where there are few Muslims, or none at all, anti-sharia legislation has become an odd phenomenon—a sort of illiberal counter-illiberalism. This is not quite what Deneen, or for that matter Houellebecq, had in mind in thinking beyond, or after, liberalism. In Europe, no populist party—and several, in Switzerland, Poland, and Hungary, have been in power—has managed to imagine something truly new. What liberalism’s critics appear unable, or unwilling, to address is whether a lack of meaning is a worse problem to have than a lack of freedom. Perhaps the most we can hope for—or worry about—is just somewhat more illiberal liberal democracies, variations on a continuum but still largely stuck in a liberal universe."
Iran's Protests and the Myth of Benign Silence,1-9-2019,"When protesters in the Middle East take to the streets against their regimes, the United States finds itself in a dilemma, particularly when those regimes are allies. The United States, as a statement of policy, is committed to supporting democracy abroad and standing with democracy activists and dissidents. But how does it do that if it’s also committed to the survival of governments that—also as a matter of policy—deny their citizens basic freedoms?
Certain dilemmas remain, though, even when the regimes in question aren’t friends, but rather enemies like Iran, which has witnessed its largest protests in years, spreading across more than 80 cities. The so-called “kiss of death,” where overt American support taints the very protestors the United States hopes to help, invariably comes up.
As Phil Gordon, President Obama’s White House coordinator for the Middle East, wrote days after the protests began: “We can be fairly certain that high-profile public support from the United States government will do more harm than good.” But can we? It’s certainly possible that Donald Trump is such a uniquely toxic figure that he, just by virtue of being himself, transforms the kiss of death into something real. But the premise, especially on the left, is held to apply to all American presidents; it was one of the rationales behind the Obama administration’s relative quiet in 2009 when Iranian protesters braved regime violence to protest a stolen election.
Recommended Reading

The Lessons of Iran's Protests
Krishnadev Calamur
Students attend a protest at Tehran University, where a smoke grenade was thrown by anti-riot Iranian police on December 30, 2017.
The Battle for Iran
Karim Sadjadpour
An illustration of red and blue mayafis
When America Couldn’t Bring Back Our Girls
Joe Parkinson and Drew Hinshaw
The “kiss of death” hypothesis is intuitive—after all, the United States is held under nearly universal suspicion in the Middle East, even among its proponents. So why give regimes fodder for conspiracy theories and claims of “foreign hands” instigating protests? But these claims will come regardless of what the U.S. does or doesn’t do. Iranian officials, just as they did in 2009, wasted little time blaming the United States, as well as Israel, Saudi Arabia, and even ISIS. (The CIA’s Michael D’Andrea—interestingly one of the most senior Muslims in the U.S. government—also received an honorable mention.)
But it is time to question this intuition, especially since Arabs and Iranians will no doubt be protesting in the years and decades to come. Since when do authoritarian regimes need evidence to assert foreign meddling? After all, if there’s no evidence, it only makes foreign interference that much more nefarious—its non-existence becoming the very proof of its existence.
As for protesters themselves and how they might perceive American encouragement, Iran is something of a unique case. Despite (or, rather, because of) a virulently anti-American regime, Iranians are generally less anti-American than other populations in the Middle East. One thing Iranians, whatever their politics, will be aware of is American involvement in the 1953 coup against the country’s democratically elected prime minister, Mohamed Mossadegh—an instance, in other words, of undermining democracy, rather than supporting it.
Even in countries with notoriously high levels of anti-Americanism, such as Egypt, U.S. support, even if it’s primarily rhetorical, can provide a much-needed boost—the knowledge, however intangible, that someone, somewhere, is watching and that your cause will not be forgotten. I was living in Jordan during the first Arab spring, in 2004 and 2005, and I remember how President George W. Bush’s “freedom agenda,” as half-hearted as it turned out to be, contributed to a sense of cautious optimism among activists across the region. The Egyptian publisher Hisham Kassem might have been exaggerating when he said that “eighty percent of political freedom in this country is the result of U.S. pressure,” but even if it was 20 percent, it mattered. And it’s little accident that Egypt in 2005 saw what was, until then, one of its largest mass mobilizations in decades.
And it wasn’t just liberals or secular activists. The members and leaders of the Muslim Brotherhood I was interviewing at the time would often (sometimes with a hint of irony) offer thanks to President Bush, privately but also publicly. They may have hated Bush on other things like the Iraq War or Israel, as they were keen to note, but there was generally a grudging respect for his willingness to elevate democratic reform in U.S. policy. As the Jordanian Islamist writer Jihad Abu Eis told me: “It’s the right of Islamists to take advantage of American pressure on reform.”
In the second Arab Spring, particularly in the early, optimistic years of 2011 and 2012, protesters across the region, whether in Egypt, Libya, Bahrain, or Syria, would turn their attention to the United States, pleading for help and protection. Syrian protesters, who were being gunned down daily, found themselves repeatedly disappointed by the Obama administration’s studied inaction, but that never stopped them from hoping that the United States might finally do something, anything at all, to stop the killing.
One question that the very existence of the Trump administration—and its rhetorical downgrading of democracy promotion—raises is whether America’s moral legitimacy and authority is a renewable resource. Of course, this doesn’t mean the United States was ever particularly able or willing to convert its pro-democracy rhetoric into policy. In fact, the record is mostly one of subverting democracy, rather than promoting it. But there was the pretense—and the rest of us, as Americans, could hold our government to those stated ideals. And, as bad as the United States may have been, it was usually better than the alternatives, whether various European countries, or China and Russia.
When it comes to autocratic allies, like Saudi Arabia or Egypt, the Trump administration has been indulgent. The idea, often unstated, that America should highlight democracy with its enemies but stay quiet with its allies is deeply problematic. But that is not Iranians’ concern, at least not the ones protesting, or the ones who will protest in the future. They need to know that the members of the international community, including America’s European allies, are paying close attention and not merely playing a delicate “both sides-ism” in the interest of an imaginary rapprochement with the Iranian regime. The conversation we need to prepare ourselves for—since this is more likely the beginning than the end—is what can be done to support the forces of reform in Iran, however limited America’s power and leverage might be. But, to prepare ourselves for that conversation, we need to do with away with convenient fictions—too often used as an excuse for inaction—that a better America is a quiet one."